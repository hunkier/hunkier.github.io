<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java并发-- AbstractQueuedSynchronizer 队列同步器]]></title>
    <url>%2FJava-Concurrent-AbstractQueuedSynchronizer%2F</url>
    <content type="text"><![CDATA[队列同步器AbstractQueuedSynchronizer（以下简称同步器），是用来构建锁或者其他同步组件的基础框架，它使用了一个int成员变量表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作，并发包的作者（Doug Lea）期望它能够成为实现大部分同步需求的基础。 同步器的主要使用方式是继承，子类通过继承同步器并实现它的抽象方法来管理同步状态，在抽象方法的实现过程中免不了要对同步状态进行更改，这时就需要使用同步器提供的3个方法（getState()、setState(int newState)和compareAndSetState(int expect,int update)）来进行操作，因为它们能够保证状态的改变是安全的。子类推荐被定义为自定义同步组件的静态内部类，同步器自身没有实现任何同步接口，它仅仅是定义了若干同步状态获取和释放的方法来供自定义同步组件使用，同步器既可以支持独占式地获取同步状态，也可以支持共享式地获取同步状态，这样就可以方便实现不同类型的同步组件（ReentrantLock、ReentrantReadWriteLock和CountDownLatch等）。 同步器是实现锁（也可以是任意同步组件）的关键，在锁的实现中聚合同步器，利用同步器实现锁的语义。可以这样理解二者之间的关系：锁是面向使用者的，它定义了使用者与锁交互的接口（比如可以允许两个线程并行访问），隐藏了实现细节；同步器面向的是锁的实现者，它简化了锁的实现方式，屏蔽了同步状态管理、线程的排队、等待与唤醒等底层操作。锁和同步器很好地隔离了使用者和实现者所需关注的领域。 队列同步器的接口与示例同步器的设计是基于模板方法模式的，也就是说，使用者需要继承同步器并重写指定的方法，随后将同步器组合在自定义同步组件的实现中，并调用同步器提供的模板方法，而这些模板方法将会调用使用者重写的方法。 重写同步器指定的方法时，需要使用同步器提供的如下3个方法来访问或修改同步状态。 getState()：获取当前同步状态。 setState(int newState)：设置当前同步状态。 compareAndSetState(int expect,int update)：使用CAS设置当前状态，该方法能够保证状态设置的原子性。 同步器可重写的方法与描述如表所示。 方法名称 描述 protected boolean tryAcquire(int arg) 独占式获取同步锁，实现该方法需要查询当前状态并判断同步状态是否符合预期，然后再进行 CAS 设置同步状态 protected tryRelease(int arg) 独占式释放同步状态，等待获取同步状态的线程将有机会获取同步状态 protected int tryAcquireShare(int arg) 共享式获取同步状态，返回大于等于 0 的值，表示获取成功，反之，获取失败 protected boolean tryReleaseShared(int arg) 共享式释放同步状态 protected boolean isHeldExclusively() 当前同步器释放在独占模式下被线程占用，一般该方法表示是否被当前线程所独占 实现自定义同步组件时，将会调用同步器提供的模板方法，这些（部分）模板方法与描述如下表所示。 方法名称 描述 void acquire(int arg) 独占式获取同步状态，如果当前线程获取同步状态成功，则由该方法返回，否则，将会进入同步队列等待，该方法将会调用重写的 tryAcquire(int arg) 方法 void acquireInterruptibly(int arg) 与 acquire(int arg) 相同，但是该方法响应中断，当前线程未获取到同步状态而进入同步队列中，如果当前线程被中断，则该方法会抛出 InterruptedException 并返回 boolean tryAcquireNanos(int arg, long nanos) 在 acquireInterruptibly(int arg) 基础上增加了超时限制，如果当前线程在超时时间内没有获取到同步状态，那么将会返回 false，如果获取到了返回 true void requireShared(int arg) 共享式的获取同步状态，如果当前线程未获取到同步状态，将会进入同步队列等待，与独占式获取的主要区别是在同一时刻可以有多个线程获取到同步状态 void acquireSharedInterruptibly(int arg) 与 accquireShared(int arg) 相同，该方法响应中断 boolean tryAcquireSharedNanos(int arg, long nonos) 在 acquireSharedInterruptibly(int arg) 基础上增加了超时限制 boolean release(int arg) 独占式的释放同步状态，该方法会在释放同步状态之后，将同步队列中第一个节点包含的线程唤醒 boolean releaseShared(int arg) 共享式的释放同步状态 Collection getQueuedThreads() 获取等待在同步队列上的线程集合 同步器提供的模板方法基本上分为3类：独占式获取与释放同步状态、共享式获取与释放同步状态和查询同步队列中的等待线程情况。自定义同步组件将使用同步器提供的模板方法来实现自己的同步语义。 只有掌握了同步器的工作原理才能更加深入地理解并发包中其他的并发组件，所以下面通过一个独占锁的示例来深入了解一下同步器的工作 顾名思义，独占锁就是在同一时刻只能有一个线程获取到锁，而其他获取锁的线程只能处于同步队列中等待，只有获取锁的线程释放了锁，后继的线程才能够获取锁，如代码清单所示。 代码清单 Mutex.java class Mutex implements Lock { // 静态内部类，自定义同步器 private static class Sync extends AbstractQueuedSynchronizer { // 是否处于占用状态 protected boolean isHeldExclusively() { return getState() == 1; } // 当状态为0的时候获取锁 public boolean tryAcquire(int acquires) { if (compareAndSetState(0, 1)) { setExclusiveOwnerThread(Thread.currentThread()); return true; } return false; } // 释放锁，将状态设置为0 protected boolean tryRelease(int releases) { if (getState() == 0) throw new IllegalMonitorStateException(); setExclusiveOwnerThread(null); setState(0); return true; } // 返回一个Condition，每个condition都包含了一个condition队列 Condition newCondition() { return new ConditionObject(); } } // 仅需要将操作代理到Sync上即可 private final Sync sync = new Sync(); public void lock() { sync.acquire(1); } public boolean tryLock() { return sync.tryAcquire(1); } public void unlock() { sync.release(1); } public Condition newCondition() { return sync.newCondition(); } public boolean isLocked() { return sync.isHeldExclusively(); } public boolean hasQueuedThreads() { return sync.hasQueuedThreads(); } public void lockInterruptibly() throws InterruptedException { sync.acquireInterruptibly(1); } public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException { return sync.tryAcquireNanos(1, unit.toNanos(timeout)); } } 上述示例中，独占锁Mutex是一个自定义同步组件，它在同一时刻只允许一个线程占有锁。Mutex中定义了一个静态内部类，该内部类继承了同步器并实现了独占式获取和释放同步状态。在tryAcquire(int acquires)方法中，如果经过CAS设置成功（同步状态设置为1），则代表获取了同步状态，而在tryRelease(int releases)方法中只是将同步状态重置为0。用户使用Mutex时并不会直接和内部同步器的实现打交道，而是调用Mutex提供的方法，在Mutex的实现中，以获取锁的lock()方法为例，只需要在方法实现中调用同步器的模板方法acquire(int args)即可，当前线程调用该方法获取同步状态失败后会被加入到同步队列中等待，这样就大大降低了实现一个可靠自定义同步组件的门槛。 队列同步器的实现分析接下来将从实现角度分析同步器是如何完成线程同步的，主要包括：同步队列、独占式同步状态获取与释放、共享式同步状态获取与释放以及超时获取同步状态等同步器的核心数据结构与模板方法。 1.同步队列 同步器依赖内部的同步队列（一个FIFO双向队列）来完成同步状态的管理，当前线程获取同步状态失败时，同步器会将当前线程以及等待状态等信息构造成为一个节点（Node）并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点中的线程唤醒，使其再次尝试获取同步状态。 同步队列中的节点（Node）用来保存获取同步状态失败的线程引用、等待状态以及前驱和后继节点，节点的属性类型与名称以及描述如下表所示。 属性类型与名称 描述 int waitStatus 等待状态。包含如下状态：① CANCELLED，值为1，由于在同步队列中等待的线程等待超时或者被中断了，需要从同步队列中取消等待，节点进入该状态将不会变化。② SIGNAL，值为 -1，后继节点的线程处于等待状态，而当前节点的线程如果释放了同步状态或者被取消，将会通知后继节点，使后继节点的线程得以运行。③ CONDITION，值为 -2，节点在等待队列总，节点线程等待在 Conditoin 上，当其他线程对 Condition 调用了 signal() 方法后，该节点将会从等待队列转移到同步队列中，加入到对同步状态的获取中。④ PROPAGATE，值为 -3，表示下一次共享式同步状态获取将会无条件地被传播下去。⑤ INITIAL，值为 0，初始状态。 Node prev 前驱节点，当节点加入同步队列时被设置 （尾部添加） Node next 后继节点 Node nextWaiter 等待队列中的后继节点。如果当前节点时共享的，那么这个字段将是一个 SHARED 常量，也就是说节点类型（独占和共享）和等待队列中的后继节点共同用一个字段 Thread thread 获取同步状态的线程 节点是构成同步队列（等待队列，在5.6节中将会介绍）的基础，同步器拥有首节点（head）和尾节点（tail），没有成功获取同步状态的线程将会成为节点加入该队列的尾部，同步队列的基本结构如图所示。 图同步队列的基本结构 在图5-1中，同步器包含了两个节点类型的引用，一个指向头节点，而另一个指向尾节点。试想一下，当一个线程成功地获取了同步状态（或者锁），其他线程将无法获取到同步状态，转而被构造成为节点并加入到同步队列中，而这个加入队列的过程必须要保证线程安全，因此同步器提供了一个基于CAS的设置尾节点的方法：compareAndSetTail(Node expect,Node update)，它需要传递当前线程“认为”的尾节点和当前节点，只有设置成功后，当前节点才正式与之前的尾节点建立关联。 同步器将节点加入到同步队列的过程如图所示。 图节点加入到同步队列 同步队列遵循FIFO，首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，将会唤醒后继节点，而后继节点将会在获取同步状态成功时将自己设置为首节点，该过程如图所示。 图首节点的设置 在图中，设置首节点是通过获取同步状态成功的线程来完成的，由于只有一个线程能够成功获取到同步状态，因此设置头节点的方法并不需要使用CAS来保证，它只需要将首节点设置成为原首节点的后继节点并断开原首节点的next引用即可。 2.独占式同步状态获取与释放 通过调用同步器的acquire(int arg)方法可以获取同步状态，该方法对中断不敏感，也就是由于线程获取同步状态失败后进入同步队列中，后续对线程进行中断操作时，线程不会从同步队列中移出，该方法代码如下代码清单所示。 同步器的acquire方法 public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } 上述代码主要完成了同步状态获取、节点构造、加入同步队列以及在同步队列中自旋等待的相关工作，其主要逻辑是：首先调用自定义同步器实现的tryAcquire(int arg)方法，该方法保证线程安全的获取同步状态，如果同步状态获取失败，则构造同步节点（独占式Node.EXCLUSIVE，同一时刻只能有一个线程成功获取同步状态）并通过addWaiter(Node node)方法将该节点加入到同步队列的尾部，最后调用acquireQueued(Node node,int arg)方法，使得该节点以“死循环”的方式获取同步状态。如果获取不到则阻塞节点中的线程，而被阻塞线程的唤醒主要依靠前驱节点的出队或阻塞线程被中断来实现。 下面分析一下相关工作。首先是节点的构造以及加入同步队列，如代码清单所示。 同步器的addWaiter和enq方法 private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // 快速尝试在尾部添加 Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } enq(node); return node; } private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // Must initialize if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } 上述代码通过使用compareAndSetTail(Node expect,Node update)方法来确保节点能够被线程安全添加。试想一下：如果使用一个普通的LinkedList来维护节点之间的关系，那么当一个线程获取了同步状态，而其他多个线程由于调用tryAcquire(int arg)方法获取同步状态失败而并发地被添加到LinkedList时，LinkedList将难以保证Node的正确添加，最终的结果可能是节点的数量有偏差，而且顺序也是混乱的。 在enq(final Node node)方法中，同步器通过“死循环”来保证节点的正确添加，在“死循环”中只有通过CAS将节点设置成为尾节点之后，当前线程才能从该方法返回，否则，当前线程不断地尝试设置。可以看出，enq(final Node node)方法将并发添加节点的请求通过CAS变得“串行化”了。 节点进入同步队列之后，就进入了一个自旋的过程，每个节点（或者说每个线程）都在自省地观察，当条件满足，获取到了同步状态，就可以从这个自旋过程中退出，否则依旧留在这个自旋过程中（并会阻塞节点的线程），如代码清单所示。 同步器的acquireQueued方法 final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } 在acquireQueued(final Node node,int arg)方法中，当前线程在“死循环”中尝试获取同步状态，而只有前驱节点是头节点才能够尝试获取同步状态，这是为什么？原因有两个，如下。 第一，头节点是成功获取到同步状态的节点，而头节点的线程释放了同步状态之后，将会唤醒其后继节点，后继节点的线程被唤醒后需要检查自己的前驱节点是否是头节点。 第二，维护同步队列的FIFO原则。该方法中，节点自旋获取同步状态的行为如图所示。 图 节点自旋获取同步状态 在图5-4中，由于非首节点线程前驱节点出队或者被中断而从等待状态返回，随后检查自己的前驱是否是头节点，如果是则尝试获取同步状态。可以看到节点和节点之间在循环检查的过程中基本不相互通信，而是简单地判断自己的前驱是否为头节点，这样就使得节点的释放规则符合FIFO，并且也便于对过早通知的处理（过早通知是指前驱节点不是头节点的线程由于中断而被唤醒）。 独占式同步状态获取流程，也就是acquire(int arg)方法调用流程，如图所示。 图 独占式同步状态获取流程 在图中，前驱节点为头节点且能够获取同步状态的判断条件和线程进入等待状态是获取同步状态的自旋过程。当同步状态获取成功之后，当前线程从acquire(int arg)方法返回，如果对于锁这种并发组件而言，代表着当前线程获取了锁。 当前线程获取同步状态并执行了相应逻辑之后，就需要释放同步状态，使得后续节点能够继续获取同步状态。通过调用同步器的release(int arg)方法可以释放同步状态，该方法在释放了同步状态之后，会唤醒其后继节点（进而使后继节点重新尝试获取同步状态）。该方法代码如代码清单所示。 同步器的release方法 public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } 该方法执行时，会唤醒头节点的后继节点线程，unparkSuccessor(Node node)方法使用LockSupport（在后面的章节会专门介绍）来唤醒处于等待状态的线程。 分析了独占式同步状态获取和释放过程后，适当做个总结：在获取同步状态时，同步器维护一个同步队列，获取状态失败的线程都会被加入到队列中并在队列中进行自旋；移出队列（或停止自旋）的条件是前驱节点为头节点且成功获取了同步状态。在释放同步状态时，同步器调用tryRelease(int arg)方法释放同步状态，然后唤醒头节点的后继节点。 3.共享式同步状态获取与释放 共享式获取与独占式获取最主要的区别在于同一时刻能否有多个线程同时获取到同步状态。以文件的读写为例，如果一个程序在对文件进行读操作，那么这一时刻对于该文件的写操作均被阻塞，而读操作能够同时进行。写操作要求对资源的独占式访问，而读操作可以是共享式访问，两种不同的访问模式在同一时刻对文件或资源的访问情况，如图所示。 图 共享式与独占式访问资源的对比 在图5-6中，左半部分，共享式访问资源时，其他共享式的访问均被允许，而独占式访问被阻塞，右半部分是独占式访问资源时，同一时刻其他访问均被阻塞。 通过调用同步器的acquireShared(int arg)方法可以共享式地获取同步状态，该方法代码如代码清单所示。 同步器的acquireShared和doAcquireShared方法 public final void acquireShared(int arg) { if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); } private void doAcquireShared(int arg) { final Node node = addWaiter(Node.SHARED); boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head) { int r = tryAcquireShared(arg); if (r &gt;= 0) { setHeadAndPropagate(node, r); p.next = null; if (interrupted) selfInterrupt(); failed = false; return; } } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } 在acquireShared(int arg)方法中，同步器调用tryAcquireShared(int arg)方法尝试获取同步状态，tryAcquireShared(int arg)方法返回值为int类型，当返回值大于等于0时，表示能够获取到同步状态。因此，在共享式获取的自旋过程中，成功获取到同步状态并退出自旋的条件就是tryAcquireShared(int arg)方法返回值大于等于0。可以看到，在doAcquireShared(int arg)方法的自旋过程中，如果当前节点的前驱为头节点时，尝试获取同步状态，如果返回值大于等于0，表示该次获取同步状态成功并从自旋过程中退出。 与独占式一样，共享式获取也需要释放同步状态，通过调用releaseShared(int arg)方法可以释放同步状态，该方法代码如代码清单所示。 同步器的releaseShared方法 public final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { doReleaseShared(); return true; } return false; } 该方法在释放同步状态之后，将会唤醒后续处于等待状态的节点。对于能够支持多个线程同时访问的并发组件（比如Semaphore），它和独占式主要区别在于tryReleaseShared(int arg)方法必须确保同步状态（或者资源数）线程安全释放，一般是通过循环和CAS来保证的，因为释放同步状态的操作会同时来自多个线程。 4.独占式超时获取同步状态 通过调用同步器的doAcquireNanos(int arg,long nanosTimeout)方法可以超时获取同步状态，即在指定的时间段内获取同步状态，如果获取到同步状态则返回true，否则，返回false。该方法提供了传统Java同步操作（比如synchronized关键字）所不具备的特性。 在分析该方法的实现前，先介绍一下响应中断的同步状态获取过程。在Java 5之前，当一个线程获取不到锁而被阻塞在synchronized之外时，对该线程进行中断操作，此时该线程的中断标志位会被修改，但线程依旧会阻塞在synchronized上，等待着获取锁。在Java 5中，同步器提供了acquireInterruptibly(int arg)方法，这个方法在等待获取同步状态时，如果当前线程被中断，会立刻返回，并抛出InterruptedException。 超时获取同步状态过程可以被视作响应中断获取同步状态过程的“增强版”，doAcquireNanos(int arg,long nanosTimeout)方法在支持响应中断的基础上，增加了超时获取的特性。针对超时获取，主要需要计算出需要睡眠的时间间隔nanosTimeout，为了防止过早通知，nanosTimeout计算公式为：nanosTimeout-=now-lastTime，其中now为当前唤醒时间，lastTime为上次唤醒时间，如果nanosTimeout大于0则表示超时时间未到，需要继续睡眠nanosTimeout纳秒，反之，表示已经超时，该方法代码如代码清单所示。 同步器的doAcquireNanos方法 private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException { long lastTime = System.nanoTime(); final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try { for (;;) { final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return true; } if (nanosTimeout &lt;= 0) return false; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); long now = System.nanoTime(); //计算时间，当前时间now减去睡眠之前的时间lastTime得到已经睡眠 //的时间delta，然后被原有超时时间nanosTimeout减去，得到了 //还应该睡眠的时间 nanosTimeout -= now - lastTime; lastTime = now; if (Thread.interrupted()) throw new InterruptedException(); } } finally { if (failed) cancelAcquire(node); } } 该方法在自旋过程中，当节点的前驱节点为头节点时尝试获取同步状态，如果获取成功则从该方法返回，这个过程和独占式同步获取的过程类似，但是在同步状态获取失败的处理上有所不同。如果当前线程获取同步状态失败，则判断是否超时（nanosTimeout小于等于0表示已经超时），如果没有超时，重新计算超时间隔nanosTimeout，然后使当前线程等待nanosTimeout纳秒（当已到设置的超时时间，该线程会从LockSupport.parkNanos(Object blocker,long nanos)方法返回）。 如果nanosTimeout小于等于spinForTimeoutThreshold（1000纳秒）时，将不会使该线程进行超时等待，而是进入快速的自旋过程。原因在于，非常短的超时等待无法做到十分精确，如果这时再进行超时等待，相反会让nanosTimeout的超时从整体上表现得反而不精确。因此，在超时非常短的场景下，同步器会进入无条件的快速自旋。 独占式超时获取同步态的流程如下图所示。 从图中可以看出，独占式超时获取同步状态doAcquireNanos(int arg,long nanosTimeout)和独占式获取同步状态acquire(int args)在流程上非常相似，其主要区别在于未获取到同步状态时的处理逻辑。acquire(int args)在未获取到同步状态时，将会使当前线程一直处于等待状态，而doAcquireNanos(int arg,long nanosTimeout)会使当前线程等待nanosTimeout纳秒，如果当前线程在nanosTimeout纳秒内没有获取到同步状态，将会从等待逻辑中自动返回。 图 独占式超时获取同步状态的流程 5.自定义同步组件——TwinsLock 在前面的章节中，对同步器AbstractQueuedSynchronizer进行了实现层面的分析，本节通过编写一个自定义同步组件来加深对同步器的理解。 设计一个同步工具：该工具在同一时刻，只允许至多两个线程同时访问，超过两个线程的访问将被阻塞，我们将这个同步工具命名为TwinsLock。 首先，确定访问模式。TwinsLock能够在同一时刻支持多个线程的访问，这显然是共享式访问，因此，需要使用同步器提供的acquireShared(int args)方法等和Shared相关的方法，这就要求TwinsLock必须重写tryAcquireShared(int args)方法和tryReleaseShared(int args)方法，这样才能保证同步器的共享式同步状态的获取与释放方法得以执行。 其次，定义资源数。TwinsLock在同一时刻允许至多两个线程的同时访问，表明同步资源数为2，这样可以设置初始状态status为2，当一个线程进行获取，status减1，该线程释放，则status加1，状态的合法范围为0、1和2，其中0表示当前已经有两个线程获取了同步资源，此时再有其他线程对同步状态进行获取，该线程只能被阻塞。在同步状态变更时，需要使用compareAndSet(int expect,int update)方法做原子性保障。 最后，组合自定义同步器。前面的章节提到，自定义同步组件通过组合自定义同步器来完成同步功能，一般情况下自定义同步器会被定义为自定义同步组件的内部类。 TwinsLock（部分）代码如代码清单所示。 TwinsLock.java public class TwinsLock implements Lock { private final Sync sync = new Sync(2); private static final class Sync extends AbstractQueuedSynchronizer { Sync(int count) { if (count &lt;= 0) { throw new IllegalArgumentException(&quot;count must large than zero.&quot;); } setState(count); } public int tryAcquireShared(int reduceCount) { for (;;) { int current = getState(); int newCount = current - reduceCount; if (newCount &lt; 0 || compareAndSetState(current, newCount)) { return newCount; } } } public boolean tryReleaseShared(int returnCount) { for (;;) { int current = getState(); int newCount = current + returnCount; if (compareAndSetState(current, newCount)) { return true; } } } } public void lock() { sync.acquireShared(1); } public void unlock() { sync.releaseShared(1); } // 其他接口方法略 } 在上述示例中，TwinsLock实现了Lock接口，提供了面向使用者的接口，使用者调用lock()方法获取锁，随后调用unlock()方法释放锁，而同一时刻只能有两个线程同时获取到锁。TwinsLock同时包含了一个自定义同步器Sync，而该同步器面向线程访问和同步状态控制。以共享式获取同步状态为例：同步器会先计算出获取后的同步状态，然后通过CAS确保状态的正确设置，当tryAcquireShared(int reduceCount)方法返回值大于等于0时，当前线程才获取同步状态，对于上层的TwinsLock而言，则表示当前线程获得了锁。 同步器作为一个桥梁，连接线程访问以及同步状态控制等底层技术与不同并发组件（比如Lock、CountDownLatch等）的接口语义。 下面编写一个测试来验证TwinsLock是否能按照预期工作。在测试用例中，定义了工作者线程Worker，该线程在执行过程中获取锁，当获取锁之后使当前线程睡眠1秒（并不释放锁），随后打印当前线程名称，最后再次睡眠1秒并释放锁，测试用例如代码清单所示。 TwinsLockTest.java public class TwinsLockTest { @Test public void test() { final Lock lock = new TwinsLock(); class Worker extends Thread { public void run() { while (true) { lock.lock(); try { SleepUtils.second(1); System.out.println(Thread.currentThread().getName()); SleepUtils.second(1); } finally { lock.unlock(); } } } } // 启动10个线程 for (int i = 0; i &lt; 10; i++) { Worker w = new Worker(); w.setDaemon(true); w.start(); } // 每隔1秒换行 for (int i = 0; i &lt; 10; i++) { SleepUtils.second(1); System.out.println(); } } } 运行该测试用例，可以看到线程名称成对输出，也就是在同一时刻只有两个线程能够获取到锁，这表明TwinsLock可以按照预期正确工作。 参考: 方腾飞,魏鹏,程晓明 著. 《Java并发编程的艺术 》(Java核心技术系列)]]></content>
      <categories>
        <category>java</category>
        <category>concurrent</category>
        <category>AbstractQueuedSynchronizer</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>java</tag>
        <tag>concurrent</tag>
        <tag>AbstractQueuedSynchronizer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发-- Lock 接口]]></title>
    <url>%2FJava-Concurrent-Lock-Interface%2F</url>
    <content type="text"><![CDATA[​ 锁是用来控制多个线程访问共享资源的方式，一般来说，一个锁能够防止多个线程同时访问共享资源（但是有些锁是可以允许多个线程并发的访问共享资源，比如读写锁）。在 Lock 接口出现之前，Java 程序是靠 synchronized 关键字实现锁的功能的，而 JavaSE 5 之后，并发包中新增了 Lock 接口（以及相关类），只是在使用时需要显式地获取和释放锁。虽然它缺少了 （通过 synchronized 块或者方法所提供的）隐式获取和释放锁的便捷性，但是却拥有了锁获取与释放的可操作性、可中断的获取锁以及超时获取锁等多种 synchronized 关键字所不具备的同步特性。 ​ 使用 synchronized 关键字将会隐式地获取锁，但是它将锁的获取和释放固化了，也就是先获取再释放。当然，这种方法简化了同步的管理，可是扩展性没有显式的锁获取和释放来的好。例如，针对一个场景，手把手进行锁获取和释放，先获得锁 A，然后再获取锁 B，当锁 B 获得后释放锁 A 同时获取锁 C，当锁 C 获得后再释放锁 B同时获取锁 D，以此类推。这种场景下，synchronized 关键字就不那么容易实现了，而使用 Lock 却容易许多。 ​ Lock 的使用也很简单，以下代码是 Lock 的使用方式。 Lock lock = new ReentrantLock(); lock.lock(); try{ }finally{ lock.unlock(); } ​ 在 finally 块中释放锁，目的是保证在获取到锁之后，最终能够被释放。 ​ 不要将获取锁的过程写在 try 块中，因为如果在获取锁（自定义锁的实现）时发生了异常，异常抛出的同时，也会导致锁无故释放。 ​ Lock 接口提供的 synchronized 关键字所不具备的主要特性如下表。 特性 描述 尝试非阻塞地获取锁 当前线程尝试获取锁，如果这一时刻锁没有被其他线程获取到，则成功获取并持有锁 能被中断地获取锁 与 synchronized 不同，获取锁的线程能够响应中断，当获取到锁的线程被中断时，中断异常将会被抛出，同时释放锁 超时获取锁 在指定的截止时间之前获取锁，如果截止时间到了仍旧无法获取锁，则返回 ​ Lock 是一个接口，它定义了锁获取和释放的基本操作，Lock 的 API 如下表所示。 方法名称 描述 void lock() 获取锁，调用该方法当前线程将获取锁，当锁获得后，从该方法返回 void lockInterruptibly() 可中断地获取锁，和 lock() 方法的不同之处在于该方法会响应中断，即在锁的获取中可以中断当前线程 boolean tryLock() 尝试非阻塞的获取锁，调用该方法后立刻返回，如果能够获取则返回 true，否则返回 flase boolean tryLock(long time, TimeUnit unit) throws InterruptedException 超时的获取锁，当前线程在以下3中情况下会返回：①当前线程在超时时间内获得了锁 ②当前线程在超时时间内被中断 ③超时时间结束，返回 false void unlock() 释放锁 Condition newCondition() 获取等待通知组件，该组件和当前的锁绑定，当前线程只有获得了锁，才能调用该组件的 wait() 方法，而调用后，当前线程将释放锁 ​ 这里先简单介绍一下 Lock 接口的 API，随后的章节会详细介绍同步器 AbstractQueuedSynchronizer 以及常用 Lock 接口的实现 ReentrantLock。Lock 接口的实现基本都是通过聚合一个同步器的子类来完成线程访问控制的。 参考: 方腾飞,魏鹏,程晓明 著. 《Java并发编程的艺术 》(Java核心技术系列)]]></content>
      <categories>
        <category>java</category>
        <category>concurrent</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>lock</tag>
        <tag>java</tag>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发--原子操作的实现原理]]></title>
    <url>%2FJava-Concurrent-realization-principle-of-atomic-operation%2F</url>
    <content type="text"><![CDATA[原子（atomic）本意是“不能被进一步分割的最小粒子”，而原子操作（atomic operation）意为“不可被中断的一个或一系列操作”。在多处理器上实现原子操作就变得有点复杂。让我们一起来聊一聊在Intel处理器和Java里是如何实现原子操作的。 1.术语定义 在了解原子操作的实现原理前，先要了解一下相关的术语，如表所示。 术语名称 英文 解释 缓存行 Cache line 缓存的最小操作单位 比较并交换 Compare and Swap CAS 操作需要输入两个值，一个旧值（期望操作前的值）和一个新值，在操作期间先比较旧值有没有发生变化，如果没有发生变化，才交换成新值，发生了变化则不变换 CPU 流水线 CPU pipeline CPU 流水线的工作方式就像工业生产上装配流水线，在 CPU 中由 5~6 个不同功能的电路单元组成一条指令处理流水线，然后将一条 X86 指令分成 5~6 步后再由这些电路单元分别执行，这样就能实现一个 CPU 时钟周期完成一条指令，因此提高 CPU 的运算速度 内存顺序冲突 Memory order violation 内存顺序冲突一般是由假共享引起的，假共享是指多个 CPU 同时修改同一个缓存行的不同部分而引起其中一个 CPU 的操作无效，当出现这个内存顺序冲突时，CPU 必须清空流水线 2.处理器如何实现原子操作 32位IA-32处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。Pentium 6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的，但是复杂的内存操作处理器是不能自动保证其原子性的，比如跨总线宽度、跨多个缓存行和跨页表的访问。但是，处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。 （1）使用总线锁保证原子性 第一个机制是通过总线锁保证原子性 。如果多个处理器同时对共享变量进行读改写操作（i++就是经典的读改写操作），那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致。举个例子，如果i=1，我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2，如图2-3所示。 图2-3 结果对比 原因可能是多个处理器同时从各自的缓存中读取变量i，分别进行加1操作，然后分别写入系统内存中。那么，想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。 处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。 （2）使用缓存锁保证原子性 第二个机制是通过缓存锁定来保证原子性 。在同一时刻，我们只需保证对某个内存地址的操作是原子性即可，但总线锁定把CPU和内存之间的通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，目前处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。 频繁使用的内存会缓存在处理器的L1、L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁，在Pentium 6和目前的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。所谓“缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效，在如图2-3所示的例子中，当CPU1修改缓存行中的i时使用了缓存锁定，那么CPU2就不能同时缓存i的缓存行。 但是有两种情况下处理器不会使用缓存锁定。 第一种情况是：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line）时，则处理器会调用总线锁定。 第二种情况是：有些处理器不支持缓存锁定。对于Intel 486和Pentium处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。 针对以上两个机制，我们通过Intel处理器提供了很多Lock前缀的指令来实现。例如，位测试和修改指令：BTS、BTR、BTC；交换指令XADD、CMPXCHG，以及其他一些操作数和逻辑指令（如ADD、OR）等，被这些指令操作的内存区域就会加锁，导致其他处理器不能同时访问它。 3.Java如何实现原子操作 在Java中可以通过锁和循环CAS的方式来实现原子操作。 （1）使用循环CAS实现原子操作 JVM中的CAS操作正是利用了处理器提供的CMPXCHG指令实现的。自旋CAS实现的基本思路就是循环进行CAS操作直到成功为止，以下代码实现了一个基于CAS线程安全的计数器方法safeCount和一个非线程安全的计数器count。 private AtomicInteger atomicI = new AtomicInteger(0); private int i = 0; public static void main(String[] args) { final Counter cas = new Counter(); List&lt;Thread&gt; ts = new ArrayList&lt;Thread&gt;(600); long start = System.currentTimeMillis(); for (int j = 0; j &lt; 100; j++) { Thread t = new Thread(new Runnable() { @Override public void run() { for (int i = 0; i &lt; 10000; i++) { cas.count(); cas.safeCount(); } } }); ts.add(t); } for (Thread t : ts) { t.start(); } // 等待所有线程执行完成 for (Thread t : ts) { try { t.join(); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.println(cas.i); System.out.println(cas.atomicI.get()); System.out.println(System.currentTimeMillis() - start); } /** * 使用CAS实现线程安全计数器 */ private void safeCount() { for (;;) { int i = atomicI.get(); boolean suc = atomicI.compareAndSet(i, ++i); if (suc) { break; } } } /** * 非线程安全计数器 */ private void count() { i++; } } 从Java 1.5开始，JDK的并发包里提供了一些类来支持原子操作，如AtomicBoolean（用原子方式更新的boolean值）、AtomicInteger（用原子方式更新的int值）和AtomicLong（用原子方式更新的long值）。这些原子包装类还提供了有用的工具方法，比如以原子的方式将当前值自增1和自减1。 （2）CAS实现原子操作的三大问题 在Java并发包中有一些并发框架也使用了自旋CAS的方式来实现原子操作，比如LinkedTransferQueue类的Xfer方法。CAS虽然很高效地解决了原子操作，但是CAS仍然存在三大问题。ABA问题，循环时间长开销大，以及只能保证一个共享变量的原子操作。 1）ABA问题 。因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A→B→A就会变成1A→2B→3A。从Java 1.5开始，JDK的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法的作用是首先检查当前引用是否等于预期引用，并且检查当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 public boolean compareAndSet( V expectedReference, // 预期引用 V newReference, // 更新后的引用 int expectedStamp, // 预期标志 int newStamp // 更新后的标志 ) 2）循环时间长开销大 。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令，那么效率会有一定的提升。pause指令有两个作用：第一，它可以延迟流水线执行指令（de-pipeline），使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零；第二，它可以避免在退出循环的时候因内存顺序冲突（Memory Order Violation）而引起CPU流水线被清空（CPU Pipeline Flush），从而提高CPU的执行效率。 3）只能保证一个共享变量的原子操作 。当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。还有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如，有两个共享变量i＝2，j=a，合并一下ij=2a，然后用CAS来操作ij。从Java 1.5开始，JDK提供了AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里来进行CAS操作。 （3）使用锁机制实现原子操作 锁机制保证了只有获得锁的线程才能够操作锁定的内存区域。JVM内部实现了很多种锁机制，有偏向锁、轻量级锁和互斥锁。有意思的是除了偏向锁，JVM实现锁的方式都用了循环CAS，即当一个线程想进入同步块的时候使用循环CAS的方式来获取锁，当它退出同步块的时候使用循环CAS释放锁。 参考: 方腾飞,魏鹏,程晓明 著. 《Java并发编程的艺术 》(Java核心技术系列)]]></content>
      <categories>
        <category>java</category>
        <category>concurrent</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>java</tag>
        <tag>concurrent</tag>
        <tag>atomic</tag>
        <tag>CAS</tag>
        <tag>LOCK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发--锁的升级与对比]]></title>
    <url>%2FJava-Concurrent-lock-escalation-comparison%2F</url>
    <content type="text"><![CDATA[Java SE 1.6为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”，在Java SE 1.6中，锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率，下文会详细分析。 1.偏向锁 HotSpot 的作者经过研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。 （1）偏向锁的撤销 偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有正在执行的字节码）。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态；如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。图2-1中的线程1演示了偏向锁初始化的流程，线程2演示了偏向锁撤销的流程。 图2-1 偏向锁初始化的流程 （2）关闭偏向锁 偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟：-XX:BiasedLockingStartupDelay=0。如果你确定应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，那么程序默认会进入轻量级锁状态。 2.轻量级锁 （1）轻量级锁加锁 线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。 （2）轻量级锁解锁 轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。图2-2是两个线程同时争夺锁，导致锁膨胀的流程图。 图2-2 争夺锁导致的锁膨胀流程图 因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。 3.锁的优缺点对比 锁 优点 缺点 适用场景 偏向锁 加锁和解锁不需要额外的消耗，和执行非同步方法相比仅存在纳秒的差距 如果线程间存在竞争，会带来额外的锁撤销的消耗 适用于只有一个线程访问同步块场景 轻量级锁 竞争的线程不会阻塞，提高了程序的响应速度 如果始终得不到锁竞争的线程，使用自旋会消耗 CPU 追求响应时间，同步块执行速度非常快 重量级锁 线程中不使用自旋，不会消耗 CPU 线程阻塞，响应时间缓慢 追求吞吐量，同步块执行速度慢、时间长 参考: 方腾飞,魏鹏,程晓明 著. 《Java并发编程的艺术 》(Java核心技术系列)]]></content>
      <categories>
        <category>java</category>
        <category>concurrent</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>java</tag>
        <tag>concurrent</tag>
        <tag>lock escalation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 并发--Java对象头]]></title>
    <url>%2FJava-Concurrent-java-object-header%2F</url>
    <content type="text"><![CDATA[synchronized用的锁是存在Java对象头里的。如果对象是数组类型，则虚拟机用3个字宽（Word）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。在32位虚拟机中，1字宽等于4字节，即32bit，如表所示。 长度 内容 说明 32/64bit Mark Word 存储对象的 hashCode 或锁信息等 32/64bit Class Metadata Address 存储到对象类型数据的指针 32/64bit Array length 数组的长度 （如果当前对象是数组） Java对象头里的Mark Word里默认存储对象的HashCode、分代年龄和锁标记位。32位JVM的Mark Word的默认存储结构如表所示。 锁状态 25bit 4bit 1bit 是否偏向锁 2bit 锁标志位 无锁状态 对象的 hashCode 对象分代年龄 0 01 在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下4种数据，如表所示。 锁状态 25bit 4bit 1bit 2bit 23bit 2bit 是否偏向锁 锁标志位 轻量级锁 指向栈中锁记录的指针 00 重量级锁 指向互斥（重量级锁）的指针 10 GC 标记 空 11 偏向锁 线程 ID Epoch 对象分代年龄 1 01 在64位虚拟机下，Mark Word是64bit大小的，其存储结构如表所示。 锁状态 25bit 31bit 1bit 4bit 1bit 2bit cms_free 分代年龄 偏向锁 锁标志位 无锁 unused hashcode 0 01 偏向锁 TheadId(54bit) Epoch(2bit) 1 01 参考: 方腾飞,魏鹏,程晓明 著. 《Java并发编程的艺术 》(Java核心技术系列)]]></content>
      <categories>
        <category>java</category>
        <category>concurrent</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>java</tag>
        <tag>concurrent</tag>
        <tag>object header</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 并发--synchronized 的实现原理与应用]]></title>
    <url>%2FJava-Concurrent-synchronized%2F</url>
    <content type="text"><![CDATA[在多线程并发编程中 synchronized 一直是元老级角色，很多人都会称呼它为重量级锁。但是，随着 Java SE 1.6 对 synchronized 进行了各种优化之后，有些情况下它就并不那么重了。本文详细介绍 Java SE 1.6 中为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁，以及锁的存储结构和升级过程。 先来看下利用 synchronized 实现同步的基础：Java中的每一个对象都可以作为锁。具体表现为以下3种形式。 ·对于普通同步方法，锁是当前实例对象。 ·对于静态同步方法，锁是当前类的 Class 对象。 ·对于同步方法块，锁是 Synchonized 括号里配置的对象。 当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。那么锁到底存在哪里呢？锁里面会存储什么信息呢？ 从 JVM 规范中可以看到 Synchonized 在 JVM 里的实现原理，JVM 基于进入和退出 Monitor 对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用 monitorenter 和 monitorexit 指令实现的，而方法同步是使用另外一种方式实现的，细节在 JVM 规范里并没有详细说明。但是，方法的同步同样可以使用这两个指令来实现。 monitorenter 指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。 参考: 方腾飞,魏鹏,程晓明 著. 《Java并发编程的艺术 》(Java核心技术系列)]]></content>
      <categories>
        <category>java</category>
        <category>concurrent</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>java</tag>
        <tag>concurrent</tag>
        <tag>Synchronized</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发--volatile 的应用]]></title>
    <url>%2FJava-Concurrent-volatile%2F</url>
    <content type="text"><![CDATA[1 volatile的应用在多线程并发编程中synchronized和volatile都扮演着重要的角色，volatile是轻量级的synchronized，它在多处理器开发中保证了共享变量的“可见性”。可见性的意思是当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。如果volatile变量修饰符使用恰当的话，它比synchronized的使用和执行成本更低，因为它不会引起线程上下文的切换和调度。本文将深入分析在硬件层面上Intel处理器是如何实现volatile的，通过深入分析帮助我们正确地使用volatile变量。 我们先从了解volatile的定义开始。 1.volatile的定义与实现原理 Java语言规范第3版中对volatile的定义如下：Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。Java语言提供了volatile，在某些情况下比锁要更加方便。如果一个字段被声明成volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的。 在了解volatile实现原理之前，我们先来看下与其实现原理相关的CPU术语与说明。下面的表是CPU术语的定义。 术语 英文单词 术语描述 内存屏障 memory barriers 是一组处理器指令，用于实现对内存参照顺序限制 缓冲行 cache line 缓存中可以分配的最小单位。处理器填写缓存线时会加载整个缓存线，需要使用多个内存读周期 原子操作 atomic operations 不可中断的一个或一系列操作 缓存填充 cache line fill 当处理器识别到从内存中读取操作数是可缓存的，处理器读取整个缓存行到适当的缓存（L1，L2，L3 或所有的） 缓存命中 cache hit 如果进行高速缓存行填充操作的内存位置仍然是下次处理器访问的地址时，处理器从缓存中读取操作数，而不是从内存读取 写命中 write hit 当处理器将操作数写回到一个内存缓存的区域时，它首先会检查这个缓存的内存地址是否在缓存行中，如果存在一个有效的缓存行，则处理器将这个操作数写回到缓存，而不是写到内存，这个操作被称为写命中 写缺失 write misses the cache 一个有效的缓存行被写入到不存在的内存区域 volatile是如何来保证可见性的呢？让我们在X86处理器下通过工具获取JIT编译器生成的汇编指令来查看对volatile进行写操作时，CPU会做什么事情。 Java代码如下。 instance = new Singleton(); // instance是volatile变量 转变成汇编代码，如下。 0x01a3de1d: movb $0×0,0×1104800(%esi);0x01a3de24: lock addl $0×0,(%esp); 有volatile变量修饰的共享变量进行写操作的时候会多出第二行汇编代码，通过查IA-32架构软件开发者手册可知，Lock前缀的指令在多核处理器下会引发了两件事情 。 1）将当前处理器缓存行的数据写回到系统内存。 2）这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。 为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存（L1，L2或其他）后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。 下面来具体讲解volatile的两条实现原则。 1）Lock前缀指令会引起处理器缓存回写到内存 。Lock前缀指令导致在执行指令期间，声言处理器的LOCK#信号。在多处理器环境中，LOCK#信号确保在声言该信号期间，处理器可以独占任何共享内存 。但是，在最近的处理器里，LOCK＃信号一般不锁总线，而是锁缓存，毕竟锁总线开销的比较大。在8.1.4节有详细说明锁定操作对处理器缓存的影响，对于Intel486和Pentium处理器，在锁操作时，总是在总线上声言LOCK#信号。但在P6和目前的处理器中，如果访问的内存区域已经缓存在处理器内部，则不会声言LOCK#信号。相反，它会锁定这块内存区域的缓存并回写到内存，并使用缓存一致性机制来确保修改的原子性，此操作被称为“缓存锁定”，缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据。 2）一个处理器的缓存回写到内存会导致其他处理器的缓存无效 。IA-32处理器和Intel 64处理器使用MESI（修改、独占、共享、无效）控制协议去维护内部缓存和其他处理器缓存的一致性。在多核处理器系统中进行操作的时候，IA-32和Intel 64处理器能嗅探其他处理器访问系统内存和它们的内部缓存。处理器使用嗅探技术保证它的内部缓存、系统内存和其他处理器的缓存的数据在总线上保持一致。例如，在Pentium和P6 family处理器中，如果通过嗅探一个处理器来检测其他处理器打算写内存地址，而这个地址当前处于共享状态，那么正在嗅探的处理器将使它的缓存行无效，在下次访问相同内存地址时，强制执行缓存行填充。 2.volatile的使用优化 著名的Java并发编程大师Doug lea在JDK 7的并发包里新增一个队列集合类LinkedTransferQueue，它在使用volatile变量时，用一种追加字节的方式来优化队列出队和入队的性能。LinkedTransferQueue的代码如下。 /** 队列中的头部节点 */ private transient f?inal PaddedAtomicReference&lt;QNode&gt; head; /** 队列中的尾部节点 */ private transient f?inal PaddedAtomicReference&lt;QNode&gt; tail; static f?inal class PaddedAtomicReference &lt;T&gt; extends AtomicReference T&gt; { // 使用很多4个字节的引用追加到64个字节 Object p0, p1, p2, p3, p4, p5, p6, p7, p8, p9, pa, pb, pc, pd, pe; PaddedAtomicReference(T r) { super(r); } } public class AtomicReference &lt;V&gt; implements java.io.Serializable { private volatile V value; // 省略其他代码 ｝ 追加字节能优化性能 ？这种方式看起来很神奇，但如果深入理解处理器架构就能理解其中的奥秘。让我们先来看看LinkedTransferQueue这个类，它使用一个内部类类型来定义队列的头节点（head）和尾节点（tail），而这个内部类PaddedAtomicReference相对于父类AtomicReference只做了一件事情，就是将共享变量追加到64字节。我们可以来计算下，一个对象的引用占4个字节，它追加了15个变量（共占60个字节），再加上父类的value变量，一共64个字节。 为什么追加64字节能够提高并发编程的效率呢 ？因为对于英特尔酷睿i7、酷睿、Atom和NetBurst，以及Core Solo和Pentium M处理器的L1、L2或L3缓存的高速缓存行是64个字节宽，不支持部分填充缓存行，这意味着，如果队列的头节点和尾节点都不足64字节的话，处理器会将它们都读到同一个高速缓存行中，在多处理器下每个处理器都会缓存同样的头、尾节点，当一个处理器试图修改头节点时，会将整个缓存行锁定，那么在缓存一致性机制的作用下，会导致其他处理器不能访问自己高速缓存中的尾节点，而队列的入队和出队操作则需要不停修改头节点和尾节点，所以在多处理器的情况下将会严重影响到队列的入队和出队效率。Doug lea使用追加到64字节的方式来填满高速缓冲区的缓存行，避免头节点和尾节点加载到同一个缓存行，使头、尾节点在修改时不会互相锁定。 那么是不是在使用volatile变量时都应该追加到64字节呢 ？不是的。在两种场景下不应该使用这种方式。 ·缓存行非64字节宽的处理器 。如P6系列和奔腾处理器，它们的L1和L2高速缓存行是32个字节宽。 ·共享变量不会被频繁地写 。因为使用追加字节的方式需要处理器读取更多的字节到高速缓冲区，这本身就会带来一定的性能消耗，如果共享变量不被频繁写的话，锁的几率也非常小，就没必要通过追加字节的方式来避免相互锁定。 不过这种追加字节的方式在Java 7下可能不生效，因为Java 7变得更加智慧，它会淘汰或重新排列无用字段，需要使用其他追加字节的方式。除了volatile，Java并发编程中应用较多的是synchronized。 参考: 方腾飞,魏鹏,程晓明 著. 《Java并发编程的艺术 》(Java核心技术系列)]]></content>
      <categories>
        <category>java</category>
        <category>concurrent</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>java</tag>
        <tag>concurrent</tag>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装 google chrome]]></title>
    <url>%2FCentOS-7-install-google-chrome%2F</url>
    <content type="text"><![CDATA[第一步： 执行如下命令： cd /etc/yum.repos.d/ 第二步：命令如下： 创建一个repo文档 vi google-chrome.repo 第三步：命令如下： 把下列代码粘贴即可 [google-chrome] name=google-chrome baseurl=http://dl.google.com/linux/chrome/rpm/stable/x86_64 enabled=1 gpgcheck=1 gpgkey=https://dl.google.com/linux/linux_signing_key.pub 第四步：命令如下： yum -y install google-chrome-stable 由于墙的存在，有可能执行不成功，请使用如下命令替换上述命令： yum -y install google-chrome-stable --nogpgcheck 上述安装方式，是目前安装 Chrome最为快捷的方式，避免了下载 Chrome安装包的麻烦。]]></content>
      <categories>
        <category>centos</category>
        <category>chrome</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>chrome</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式七大原则]]></title>
    <url>%2FDesign-patter-7-principle%2F</url>
    <content type="text"><![CDATA[一、设计模式的目的​ 编写软件过程中，程序员面临着来自耦合性、内聚性以及可维护性，可扩展性，重用性，灵活性等多方面的挑战，设计模式是为了让程序(软件)，具有更好的 1） 代码重用性 （即：相同功能的代码，不用多次编写） 2）可读性（即：编程规范性，便于其他程序员的阅读和理解） 3）可扩展性（即：当我们要增加新的功能时，非常的方便，称为可维护） 4）可靠性（即：当我们增加新的功能后，对原来的功能没有影响） 5）使程序呈现高内聚，低耦合的特性 设计模式包含了面向对象的精髓，“懂了设计模式，你就懂了面向对象分析和设计（OOA/D）的精要” 二、设计模式七大原则​ 设计模式原则，其实就是程序员在编程时，应当遵守的原则，也是各种设计模式的基础（即：设计模式为什么这样设计的依据） 设计模式常用的七大原则有： 1）单一职责原则 2）接口隔离原则 3）依赖倒转（倒置）原则 4）里氏替换原则 5）开闭原则 6）迪米特法则 7）合成复用原则 三、单一职责原则3.1. 基本介绍​ 对类来说，即一个类应该只负责一项职责。如果类 A 负责两个不同的职责：职责 1，职责 2 。当职责 1 需要变更改变 A 时，可能造成职责 2 执行错误，所以需要将类 A 的粒度分解为 A1，A2 。 3.2. 应用实例​ 以交通工具案例讲解 1）方案 1 【分析说明】package cn.hunkier.principle.singleresponsibility; public class SingleResponsibility1 { public static void main(String[] args) { Vehicle vehicle = new Vehicle(); vehicle.run(&quot;摩托车&quot;); vehicle.run(&quot;汽车&quot;); vehicle.run(&quot;飞机&quot;); } } // 交通工具类 // 方式 1 // 1. 在方式 1 的 run 方法中，违反了单一职责原则 // 2. 解决的方案非常的简单，根据交通工具运行方法不同，分解成不同类即可 class Vehicle { public void run(String vehicle) { System.out.println(vehicle + &quot;在公路上运行...&quot;); } } 2) 方案 2 【分析说明】package cn.hunkier.principle.singleresponsibility; public class SingleResponsibility2 { public static void main(String[] args) { RoadVehicle roadVehicle = new RoadVehicle(); roadVehicle.run(&quot;摩托车&quot;); roadVehicle.run(&quot;汽车&quot;); AirVehicle airVehicle = new AirVehicle(); airVehicle.run(&quot;飞机&quot;); } } // 方案 2 的分析 // 1. 遵守单一职责原则 // 2. 但是这样做的改动很大，即将类分解，同时修改客户端 // 3. 改进：直接修改 Vehicle 类，改动的代码会比较少 =&gt; 方案3 class RoadVehicle { public void run(String vehicle) { System.out.println(vehicle + &quot;公路运行&quot;); } } class AirVehicle { public void run(String vehicle) { System.out.println(vehicle + &quot;天空运行&quot;); } } class WaterVehicle { public void run(String vehicle){ System.out.println(vehicle + &quot;水中运行&quot;); } } 3) 方案 3 【分析说明】package cn.hunkier.principle.singleresponsibility; public class SingleResponsibility3 { public static void main(String[] args) { Vehicle2 vehicle2 = new Vehicle2(); vehicle2.run(&quot;汽车&quot;); vehicle2.runWater(&quot;轮船&quot;); vehicle2.runAir(&quot;飞机&quot;); } } // 方案 3 的分析 // 1. 这种修改方法没有对原来的类做大的修改，只是增加方法 // 2. 这里虽然没有在类这个级别上遵守单一职责原则，但是在方法级别上，仍然是遵守单一职责 class Vehicle2 { public void run(String vehicle) { // 处理 System.out.println(vehicle + &quot; 在公路上运行...&quot;); } public void runAir(String vehicle) { // 处理 System.out.println(vehicle + &quot; 在天空上运行...&quot;); } public void runWater(String vehicle) { // 处理 System.out.println(vehicle + &quot; 在水中运行...&quot;); } } 3.3. 单一职责原则注意事项和细节 降低类的复杂度，一个类只负责一项职责。 提高类的可读性，可维护性 降低变更引起的风险 通常情况下，我们应该遵守单一职责原则，只有逻辑足够简单，才可以在代码级别违反单一职责原则：只有类中方法数量足够少，可以在方法级别保持单一职责原则 四、 接口隔离原则4.1. 基本介绍1）客户端不应该依赖它不需要的接口，即一个类对另一个类的依赖应该建立在最小的接口上 2）类 A 通过接口 Interface1 依赖类 B，类 C 通过接口 Interface1 依赖类 D，如果接口 Interface1 对于类 A 和类 C 来说不是最小接口，那么类 B 和类 D 必须去实现他们不需要的方法。 3）按隔离原则应当这样处理： 将接口 Interface1 拆分为独立的几个接口（这里我们拆分为 3 个接口），类 A 和 类 C 分别与他们需要的接口建立依赖关系。也就是采用接口隔离原则 4.2. 应用实例1）类 A 通过接口 Interface1 依赖类 B，类 C 通过接口 Interface1 依赖类 D，请编写代码完成此应用实例。 2）没有使用接口隔离原则代码 package cn.hunkier.principle.segregation; public class Segregation1 { public static void main(String[] args){ } } // 接口 Interface Interface1{ void operation1(); void operation2(); void operation3(); void operation4(); void operation5(); } class B implements Interface1 { public void operation1() { System.out.println(&quot;B 实现了 operation1&quot;); } public void operation2() { System.out.println(&quot;B 实现了 operation2 &quot;); } public void operation3() { System.out.println(&quot;B 实现了 operation3 &quot;); } public void operation4() { System.out.println(&quot;B 实现了 operation4 &quot;); } public void operation5() { System.out.println(&quot;B 实现了 operation5 &quot;); } } class D implements Interface1 { public void operation1() { System.out.println(&quot;D 实现了 operation1&quot;); } public void operation2() { System.out.println(&quot;D 实现了 operation2 &quot;); } public void operation3() { System.out.println(&quot;D 实现了 operation3 &quot;); } public void operation4() { System.out.println(&quot;D 实现了 operation4 &quot;); } public void operation5() { System.out.println(&quot;D 实现了 operation5 &quot;); } } class A{ // A 类通过接口 Interface1 依赖（使用）B 类，但是只会用到 1，2，3 方法 public void depend1(Interface1 i){ i.operation1(); } public void depend2(Interface1 i){ i.operation2(); } public void depend3(Interface1 i){ i.operation3(); } } class C { // C 类通过接口 Interface1 依赖（使用）D 类，但是只会用到 1，4，5 方法 public void depend1(Interface1 i){ i.operation1(); } public void depend4(Interface1 i){ i.operation5(); } public void depend5(Interface1 i){ i.operation5(); } } 4.3. 使用传统方法的问题和使用接口隔离原则改进1）类 A 通过接口 Ingerface1 依赖类 B，类 C 通过接口 Interface1 依赖类 D，如果接口 Interface1 对于类 A 和 类 C来说不是最小接口，那么类 B 和类 D 必须去实现他们不需要的方法 2）将接口 Interface1 拆分为独立的几个接口，类 A 和类 C 分别与他们需要的接口建立依赖关系。也就是采用接口隔离原则 3）接口 Interface1 中出现的方法，根据实际情况拆分为三个接口：接口 Interface1 包含方法 operation1，Interface2 包含方法 operation2、operation3，接口 Interface3 包含方法 operation4、operation5 4）代码实现 package cn.hunkier.principle.segregation.improve; public class Segregation1 { public static void main(String[] args){ // 使用 A a = new A(); a.depend1(new B()); // A 类通过接口去依赖 B 类 a.depend2(new B()); a.depend3(new B()); C c = new C(); c.depend1(new D()); // C 类通过接口去依赖（使用）D 类 c.depend4(new D()); c.depend5(new D()); } } // 接口 1 interface Interface1 { void operation1(); } // 接口 2 interface Interface2 { void operation2(); void operation3(); } // 接口 3 interface Interface3 { void operation4(); void operation5(); } class B implements Interface1, Interface2 { public void operation1() { System.out.println(&quot;B 实现了 operation1 &quot;); } public void operation2(){ System.out.println(&quot;B 实现了 operation2 &quot;); } public void operation3(){ System.out.println(&quot;B 实现了 operation3 &quot;); } } class D implements Interface1, Interface2 { public void operation1() { System.out.println(&quot;D 实现了 operation1 &quot;); } public void operation4(){ System.out.println(&quot;D 实现了 operation4 &quot;); } public void operation5(){ System.out.println(&quot;D 实现了 operation5 &quot;); } } class A { // A 类通过接口 Interface1、Interface2 依赖（使用）B 类，但是只会用到 1，2，3 方法 public void depend1(Interface1 i){ i.operation1(); } public void depend2(Interface2 i){ i.operation2(); } public void depend3(Interface2 i){ i.operation3(); } } class C { // C 类通过接口 Interface1，Interface3 依赖（使用）D 类，但是只会用到方法 1，4，5 public void depend1(Interface1 i){ i.operation1(); } public void depend4(Interface3 i){ i.operation4(); } public void depend5(Interface3 i){ i.operation5(); } } 5. 依赖倒转原则5.1. 基本介绍依赖倒转原则（Dependence Inversion Principle）是指： 1）高层模块不应该依赖底层模块，二者都应该依赖器抽象 2）抽象不应该依赖细节，细节应该依赖抽象 3）依赖倒转（倒置）的中心思想是面向接口编程 4）依赖倒转原则是基于这样的设计理念：相对于细节的多变性，抽象的东西要稳定的多。以抽象为基础搭建的架构比以细节为基础的架构要稳定的多。在 Java 中，抽象指的是接口或者抽象类，细节就是具体的实现类 5）使用接口或者抽象类的目的是制定好规范，而不涉及任何具体的操作，把展现细节的任务交给实现类去完成 5.2. 应用实例请编程完成 Person 接收消息的功能。 1）实现方案 1 + 分析说明 package cn.hunkier.principle.inversion; public class DependecyInversion { public stativ void main(String[] args) { Person person = new Person(); person.receive(new Email()); } } class Email { public String getInfo(){ return &quot;电子邮件信息：hello，world&quot;; } } // 完成 Person 接收消息的功能 // 方式 1 分析 // 1. 简单，比较容易想到 // 2. 如果我们获取的对象是 微信、短信 等，则新增类，同时 Person 也要增加相应的接收方法 // 3. 解决思路：引入一个抽象的接口 IReceiver，表示接收者，这样 Person 类与接口 IReceiver 发生依赖 // 因为 Emaill，WeiXin 等属于接收的范围，他们各自实现 IReceiver 接口就 ok，这样我们就符合依赖倒转原则 class Person { public void receive(Email email) { System.out.println(email.getInfo()); } } 2) 实现方案 2 （依赖倒转）+ 分析说明 package cn.hunkier.principle.inversion.improve; public class DependecyInversion { public static void main(String[] args){ // 客户端无需改变 Person person = new Person(); person.receive(new Email()); person.receive(new Weixin()); } } // 定义接口 interface IReceiver { public String getInfo(); } class Email implements IReceiver { public String getInfo() { return &quot;电子邮件信息：hello，world&quot;; } } // 增加微信 class Weixin implements IReceiver { public String getInfo(){ return &quot;微信消息：hello，ok&quot;; } } // 方式 2 class Person { // 这里我们是对接口的依赖 public void receive(IReceiver receiver){ System.out.println(receiver.getInfo()); } } 5.3. 依赖关系传递的三种方式和应用案例1）接口传递 ​ 应用案例代码 2）构造方法传递 ​ 应用案例代码 3） setter 方式传递 ​ 应用案例代码 4）代码演示 package cn.hunkier.principle.inversion.improve; public class DependencyPass { public static void main(String[] args) { ChangHong changhong = new ChangHong(); // 接口传递 // OpenAndClose openAndClose = new OpenAndClose(); // openAndClose.open(changHong); // 通过构造器进行依赖传递 // OpenAndClose openAndClose = new OpenAndClose(changHong); // openAndClose.open(); // 通过 setter 方法进行依赖传递 OpenAndClose openAndClose = new OpenAndClose(); openAndClose.setTv(changHong); openAndClose.open(); } } // 方式 1：通过接口传递实现依赖 // 开关的接口 // interface IOpenAndClose { // public void open(ITV tv);// 抽象方法，接收接口 //} // interface ITV { // ITV 接口 // public void play(); //} // class ChongHong implements ITV { // @Override // public void play() { // System.out.println(&quot;长虹电视机，打开&quot;); // } // } // 实现接口 // class OpenAndClose implements IOpenAndClose { // public void open(ITV tv){ // tv.play(); // } // } // 方式 2：通过构造方法依赖传递 // interface IOpenAndClose { // public void open(); // 抽象方法 // } // interface ITV { // ITV 接口 // public void play(); // } // class OpenAndClose Implements IOpenAndClose { // public ITV iv; // 成员 // public OpenAndClose(ITV tv) { // this.tv = tv ; // } // public void open() { // this.tv.play(); // } // } // 方法 3，通过 setter 方法传递 interface IOpenAndClose { }]]></content>
      <categories>
        <category>设计模式</category>
        <category>七大原则</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>七大原则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 https 协议部署博客]]></title>
    <url>%2Fdeploy-blog-with-https%2F</url>
    <content type="text"><![CDATA[前言https 成为互联网标配，自然得跟上，给自己的博客用加密版的传输协议 https。 首先需要一个域名和一台拥有固定外网 ip 的服务器，使域名可以解析到该服务器上。caddy 可以自动能够向 Let’s Encrypt 申请和续期免费证书，有效期为 3 个月， 到期后自动续期。 博客源码托管在 GitHub，因此需要先安装 git yum install -y git 安装 caddy curl https://getcaddy.com | bash -s personal http.git,http.cors,http.forwardproxy,http.authz,hook.service,dns 添加 caddy 到系统服务 vi /etc/init.d/caddy 写入内容 #!/bin/bash ### BEGIN INIT INFO # Provides: Caddy # Required-Start: $network $local_fs $remote_fs # Required-Stop: $network $local_fs $remote_fs # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: The HTTP/2 web server with automatic HTTPS # Description: Start or stop the Caddy server ### END INIT INFO NAME=&quot;Caddy&quot; NAME_BIN=&quot;caddy&quot; BIN=&quot;/usr/local/bin/caddy&quot; if [ -f &quot;/usr/local/caddy/Caddyfile&quot; ]; then CONF=&quot;/usr/local/caddy/Caddyfile&quot; elif [ -f &quot;/etc/caddy/Caddyfile&quot; ]; then CONF=&quot;/etc/caddy/Caddyfile&quot; fi Info_font_prefix=&quot;\033[32m&quot; &amp;&amp; Error_font_prefix=&quot;\033[31m&quot; &amp;&amp; Info_background_prefix=&quot;\033[42;37m&quot; &amp;&amp; Error_background_prefix=&quot;\033[41;37m&quot; &amp;&amp; Font_suffix=&quot;\033[0m&quot; RETVAL=0 check_running(){ PID=`ps -ef |grep &quot;${NAME_BIN}&quot; |grep -v &quot;grep&quot; |grep -v &quot;init.d&quot; |grep -v &quot;service&quot; |awk &#39;{print $2}&#39;` if [[ ! -z ${PID} ]]; then return 0 else return 1 fi } do_start(){ check_running if [[ $? -eq 0 ]]; then echo -e &quot;${Info_font_prefix}[信息]${Font_suffix} $NAME (PID ${PID}) 正在运行...&quot; &amp;&amp; exit 0 else ulimit -n 51200 nohup &quot;$BIN&quot; --conf=&quot;$CONF&quot; -agree &gt;&gt; /tmp/caddy.log 2&gt;&amp;1 &amp; sleep 2s check_running if [[ $? -eq 0 ]]; then echo -e &quot;${Info_font_prefix}[信息]${Font_suffix} $NAME 启动成功 !&quot; else echo -e &quot;${Error_font_prefix}[错误]${Font_suffix} $NAME 启动失败 !&quot; fi fi } do_stop(){ check_running if [[ $? -eq 0 ]]; then kill -9 ${PID} RETVAL=$? if [[ $RETVAL -eq 0 ]]; then echo -e &quot;${Info_font_prefix}[信息]${Font_suffix} $NAME 停止成功 !&quot; else echo -e &quot;${Error_font_prefix}[错误]${Font_suffix}$NAME 停止失败 !&quot; fi else echo -e &quot;${Info_font_prefix}[信息]${Font_suffix} $NAME 未运行 !&quot; RETVAL=1 fi } do_status(){ check_running if [[ $? -eq 0 ]]; then echo -e &quot;${Info_font_prefix}[信息]${Font_suffix} $NAME (PID ${PID}) 正在运行...&quot; else echo -e &quot;${Info_font_prefix}[信息]${Font_suffix} $NAME 未运行 !&quot; RETVAL=1 fi } do_tail(){ tail -100f /tmp/caddy.log } do_restart(){ do_stop do_start } do_console(){ do_start do_tail } case &quot;$1&quot; in start|stop|restart|status|console|tail) do_$1 ;; *) echo &quot;使用方法: $0 { start | stop | restart | status | console | tail }&quot; RETVAL=1 ;; esac exit $RETVAL 更改权限，加入开机自启动 chmod 755 /etc/init.d/caddy chkconfig caddy on 编辑配置文件 mkdir -p /etc/caddy/vhosts vi /etc/caddy/Caddyfile caddyfile 文件内容 # 配置文件分开存放 import vhosts/*.conf 具体配置文件 vi /etc/caddy/vhosts/hunkier.cn.conf 这里的代码仓库是开放的，若是私有项目，请自行查阅相关资料。 文件内容 hunkier.cn www.hunkier.cn { # web 页面存放路径 root /var/www/hunkier/ # 配置错误页面，所有错误都显示 404.html 页面 errors { * 404.html } # 启用压缩 gzip # 用来申请及更新 https 证书的邮箱，前提是 hunkier.cn 的域名能解析到 本机 tls huangkuier@gmail.com git github.com/hunkier/hunkier.github.io { # git clone 的目标路径 path /var/www/hunkier # 使用 webhook 触发自动部署， # GitHub 项目的 setting -&gt; Webhooks 页 Add webhook # Payload URL 为 https://hunkier.cn/webhook # Content type 为 application/json # Cecret 为 GitHubSecretKey hook /webhook GitHubSecretKey hook_type github clone_args --recursive pull_args --recurse-submodules } } 创建目录 mkdir -p /var/www/hunkier 解除链接文件限制 ulimit -n 8192 也可以使用 caddy 用作代理服务器用来科学上网（你懂得^_^） vi /etc/caddy/vhost/xxx.hunkier.cn.conf 文件 xxx.hunkier.cn.conf 内容如下： xxx.hunkier.cn { # 伪装成正常的网站 root /var/www/hunkier/ # 配置错误页面，所有错误都显示 404.html 页面 errors { * 404.html } # 开启压缩 gzip # 使用邮箱申请和续期证书 tls huangkuier@gmail.com # http 代理设置 forwardproxy { hide_ip hide_via # 使用 basic 认证 basicauth user1 passwd1 basicauth user2 passwd2 basicauth user3 passwd3 } } 此时 caddy 被用作 web 服务器和代理服务器，协议转换推荐使用gost 。 caddy 服务 启动/停止/重启/检查状态 service caddy start/stop/restart/status 启动成功后可以在浏览器里面正常访问 https://hunkier.cn 若启动失败，查看日志 tail -100f /tmp/caddy.log]]></content>
      <categories>
        <category>https</category>
        <category>blog</category>
        <category>caddy</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>https</tag>
        <tag>caddy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 修改时区、设置时间]]></title>
    <url>%2FCentOS-chanage-date-zone%2F</url>
    <content type="text"><![CDATA[一、修改时区： 方法1: cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 方法2： 列出时区： timedatectl list-timezones 设置时区： timedatectl set-timezone Asia/Shanghai 方法3：使用 tzselect 查看是否修改成功： date Fri Dec 14 10:48:05 CST 2018 如果显示CST则说明时区设置成功 CST：中国标准时间（China Standard Time），这个解释可能是针对RedHat Linux。 UTC：协调世界时，又称世界标准时间，简称UTC，从英文国际时间/法文协调时间”Universal Time/Temps Cordonn&eacute;”而来。中国大陆、香港、澳门、台湾、蒙古国、新加坡、马来西亚、菲律宾、澳洲西部的时间与UTC的时差均为+8，也就是UTC+8。 GMT：格林尼治标准时间（旧译格林威治平均时间或格林威治标准时间；英语：Greenwich Mean Time，GMT）是指位于英国伦敦郊区的皇家格林尼治天文台的标准时间，因为本初子午线被定义在通过那里的经线。 设置完系统时间后,还需要同步到硬件时钟上 二、查看和修改时间 1.显示时间 ： date 2.修改时间 date -s 时间 如：设置当前时间为：2018年12月10点50分 date -s ‘2018-12-14 10:50:00’ 3.根据网络同步时间 使用ntp同步标准时间，ntp：网络时间协议（network time protol） 安装：yum install ntp 同步：ntpdate pool.ntp.org]]></content>
      <categories>
        <category>centos</category>
        <category>date</category>
        <category>timezone</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>date</tag>
        <tag>timezone</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 安装 cockpit 管理系统]]></title>
    <url>%2FCentOS-install-mamager-cockpit%2F</url>
    <content type="text"><![CDATA[Cockpit 是一个基于 Web 界面的应用，它提供了对系统的图形化管理。 拥有如下功能： 监控系统活动（CPU、内存、磁盘 IO 和网络流量） —— 系统 查看系统日志条目 —— 日志 查看磁盘分区的容量 —— 存储 查看网络活动（发送和接收） —— 网络 查看用户帐户 —— 帐户 检查系统服务的状态 —— 服务 提取已安装应用的信息 —— 应用 查看和安装可用更新（如果以 root 身份登录）并在需要时重新启动系统 —— 软件更新 打开并使用终端窗口 —— 终端 安装cockpit yum -y install cockpit yum install cockpit* -y #所有cockpit模块安装 修改默认端口9090 vi /usr/lib/systemd/system/cockpit.socket 启动cockpit systemctl start cockpit 开机自启动 vi /usr/lib/systemd/system/cockpit.service # 在最后加上下面两行 [Install] WantedBy=multi-user.target # 退出编辑，加入系统启动 systemctl enable cockpit 防火墙配置 firewall-cmd --add-port=9090/tcp --permanent firewall-cmd --reload 登录在任意浏览器输入IP地址+端口号（https://ip:9090）]]></content>
      <categories>
        <category>Linux</category>
        <category>cockpit</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>cockpit</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计数排序]]></title>
    <url>%2Falgorithm-radix-sort%2F</url>
    <content type="text"><![CDATA[将所有待比较数值 （正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后，数列就变成一个有序序列。 public class RadixSort { int[] a ={49,38,65,97,76,13,27,49,78,34,12,64,5,4,62,99,98,54,101,56,17,18,23,34,15,35,25,53,51}; public void radixSort(){ sort(a); for(int i=0; i&lt;a.length; i++){ System.out.println(a[i]); } } public void sort(int[] array){ // 首先确定排序的趟数； int max = array[0]; for(int i=1; i&lt;array.length; i++){ if(array[i]&gt;max){ max = array[i]; } } int time = 0; // 判断位数； while(max &gt;0){ max/=10; time++; } // 建立 10 个队列 List&lt;ArrayList&gt; queue = new ArrayList&lt;ArrayList&gt;(); for(int i = 0 ; i &lt; 10 ; i++){ ArrayList&lt;Integer&gt; queue1 = new ArrayList&lt;Integer&gt;(); queue.add(queue1); } // 进行 time 次分配和收集 for(int i =0; i&lt; time; i++){ // 分配数组元素 for(int j=0; j&lt;array.length; j++){ // 得到数字的第 time+1 位数 int x = array[j]%(int)Math.pow(10,i+1)/(int)Math.pow(10,i); ArrayList&lt;Integer&gt; queue2 = queue.get(x); queue2.add(array[j]); queue.set(x,queue2); } } // 元素计数器； int count = 0 ; for(int k = 0; k &lt; 10; k++){ while(queue.get(k).size()&gt;0){ ArrayList&lt;Integer&gt; queue3 = queue.get(k); array[count] = queue3.get(0); queue3.remove(0); count++; } } } }]]></content>
      <categories>
        <category>java</category>
        <category>algorithm</category>
        <category>radix sort</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>algorithm</tag>
        <tag>radix sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[桶排序]]></title>
    <url>%2Falgorithm-bucket-sort%2F</url>
    <content type="text"><![CDATA[桶排序的基本思想是：把数组 arr 划分为 n 个大小相同子区间 (桶), 每个子区间各自排序，最后合并。计数排序是桶排序的一种特殊情况，可以把计数排序当成每个桶里面只有一个元素的情况。 找出待排序数组中的最大值 max、最小值 min 我们使用 动态数组 ArrayList 作为桶，桶里放的元素也用 ArrayList 存储。桶的数量为 (max-min)/arr.length+1 遍历数组 arr，计算每个元素 arr[i] 放的桶 每个桶各自排序 public static void bucketSort(int[] arr){ int max = Interger.MIN_VALUE; int min = Integer.MAX_VALUE; for(int i = 0; i&lt;arr.length; i++){ max = Math.max(max,arr[i]); min = Math.min(min,arr[i]); } // 创建桶 int bucketNum = (max-min)/arr.length +1; ArrayList&lt;ArrayList&lt;Interger&gt;&gt; bucketArr = new ArrayList&lt;&gt;(bucketNum); for(int i = 0 ;i &lt; bucketNum; i++){ bucketArr.add(new ArrayList&lt;Integer&gt;()); } // 将每个元素放入桶 for(int i = 0 ; i&lt;arr.length; i++){ int num = (arr[i] - min) / (arr.length); bucketArr.get(num).add(arr[i]); } // 对每个桶进行排序 for(int i = 0 ; i&lt;bucketArr.size(); i++){ Collections.sort(bucketArr.get(i)); } }]]></content>
      <categories>
        <category>java</category>
        <category>algorithm</category>
        <category>bucket sort</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>algorithm</tag>
        <tag>bucket sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 下使用 Percona XtraBackup 备份和恢复 MySQL5.7]]></title>
    <url>%2FPercona-XtraBackup-MySQL5-7%2F</url>
    <content type="text"><![CDATA[一、概述XtraBackup 是 Percona 开源的免费数据库热备份软件，它能对InnoDB数据库和XtraDB存储引擎的数据库非阻塞地备份（对于MyISAM的备份同样需要加表锁）；mysqldump备份方式是采用的逻辑备份，其最大的缺陷是备份和恢复速度较慢，如果数据库大于50G，mysqldump备份就不太适合。 mysqldump优缺点优点使用场景：10G以下的数据库操作简单 缺点数据量范围：30G –&gt; TB级别 的时候备份、恢复操作很慢，效率低 xtrabackup备份软件使用场景：1、数据量大，变换量小2、数据量小，变化量大 Xtrabackup安装完成后有4个可执行文件，其中2个比较重要的备份工具是innobackupex、xtrabackup 1）xtrabackup 是专门用来备份InnoDB表的，和mysql server没有交互；2）innobackupex 是一个封装xtrabackup的Perl脚本，支持同时备份innodb和myisam，但在对myisam备份时需要加一个全局的读锁。3）xbcrypt 加密解密备份工具4）xbstream 流传打包传输工具，类似tar5）物理备份工具，在同级数据量基础上，都要比逻辑备份性能好的多，特别是在数据量较大的时候，体现的更加明显。 Xtrabackup优点1）备份速度快，物理备份可靠 2）备份过程不会打断正在执行的事务（无需锁表） 3）能够基于压缩等功能节约磁盘空间和流量 4）自动备份校验 5）还原速度快 6）可以流传将备份传输到另外一台机器上 7）在不增加服务器负载的情况备份数据 8）物理备份工具，在同级数据量基础上，都要比逻辑备份性能要好的多。几十G到不超过TB级别的条件下。但在同数据量级别，物理备份恢复数据上有一定优势。 备份原理拷贝数据文件、拷贝数据页 对于innodb表可以实现热备。 (1) 在数据库还有修改操作的时刻，直接将数据文件备走，此时，备份走的数据对于当前mysql来讲是不一致的。(2) 将备份过程中的redo和undo一并备走。(3) 为了恢复的时候，只要保证备份出来的数据页lsn能和redo lsn匹配，将来恢复的就是一致的数据。redo应用和undo应用。 对于myisam表实现自动锁表拷贝文件。 备份开始时首先会开启一个后台检测进程，实时检测mysql redo的变化，一旦发现有新的日志写入，立刻将日志记入后台日志文件xtrabackup_log中，之后复制innodb的数据文件一系统表空间文件ibdatax，复制结束后，将执行flush tables with readlock,然后复制.frm MYI MYD等文件，最后执行unlock tables,最终停止xtrabackup_log 二、背景最近公司上线一个新项目，使用用 DELL 单片机和磁盘阵列，配置如下 名称 配置 操作系统 CentOS 7.7 x64 主机地址 172.20.8.132 主机名称 localhost MySQL 版本 5.7.28 XtraBack 版本 2.4.16 三、安装按照官网文档，通用 yum 在线方式安装，步骤如下： 安装 Percona 的 yum 仓库，使用 root 账号执行下面命令：[root@localhost ~]# yum install https://repo.percona.com/yum/percona-release-latest.noarch.rpm Loaded plugins: fastestmirror, langpacks percona-release-latest.noarch.rpm | 17 kB 00:00:00 Examining /var/tmp/yum-root-1mopyU/percona-release-latest.noarch.rpm: percona-release-1.0-13.noarch Marking /var/tmp/yum-root-1mopyU/percona-release-latest.noarch.rpm to be installed Resolving Dependencies --&gt; Running transaction check ---&gt; Package percona-release.noarch 0:1.0-13 will be installed --&gt; Finished Dependency Resolution Dependencies Resolved ================================================================================================================================================ Package Arch Version Repository Size ================================================================================================================================================ Installing: percona-release noarch 1.0-13 /percona-release-latest.noarch 20 k Transaction Summary ================================================================================================================================================ Install 1 Package Total size: 20 k Installed size: 20 k Is this ok [y/d/N]: y Downloading packages: Running transaction check Running transaction test Transaction test succeeded Running transaction Installing : percona-release-1.0-13.noarch 1/1 * Enabling the Percona Original repository &lt;*&gt; All done! The percona-release package now contains a percona-release script that can enable additional repositories for our newer products. For example, to enable the Percona Server 8.0 repository use: percona-release setup ps80 Note: To avoid conflicts with older product versions, the percona-release setup command may disable our original repository for some products. For more information, please visit: https://www.percona.com/doc/percona-repo-config/percona-release.html Verifying : percona-release-1.0-13.noarch 1/1 Installed: percona-release.noarch 0:1.0-13 Complete! 启用 Percona 的 yum 仓库 [root@localhost ~]# percona-release enable-only tools release * Disabling all Percona Repositories * Enabling the Percona Tools repository &lt;*&gt; All done! 安装 Percona XtraBackup`shell[root@localhost databases]# yum list | grep perconapercona-release.noarch 1.0-13 @/percona-release-latest.noarchpercona-backup-mongodb.x86_64 1.0.0-1.el7 tools-release-x86_64percona-mysql-shell.x86_64 8.0.15-1.el7 tools-release-x86_64percona-mysql-shell-debuginfo.x86_64 8.0.15-1.el7 tools-release-x86_64percona-toolkit.x86_64 3.1.0-2.el7 tools-release-x86_64percona-toolkit-debuginfo.x86_64 3.0.13-1.el7 tools-release-x86_64percona-xtrabackup-24.x86_64 2.4.16-1.el7 tools-release-x86_64percona-xtrabackup-24-debuginfo.x86_64 2.4.16-1.el7 tools-release-x86_64percona-xtrabackup-80.x86_64 8.0.8-1.el7 tools-release-x86_64percona-xtrabackup-80-debuginfo.x86_64 8.0.8-1.el7 tools-release-x86_64percona-xtrabackup-test-24.x86_64 2.4.16-1.el7 tools-release-x86_64percona-xtrabackup-test-80.x86_64 8.0.8-1.el7 tools-release-x86_64 [root@localhost databases]# yum install -y percona-xtrabackup-24.x86_64 Loaded plugins: fastestmirror, langpacks Loading mirror speeds from cached hostfile * base: mirrors.tuna.tsinghua.edu.cn * extras: mirrors.cqu.edu.cn * updates: mirrors.cqu.edu.cn Resolving Dependencies –&gt; Running transaction check —&gt; Package percona-xtrabackup-24.x86_64 0:2.4.16-1.el7 will be installed –&gt; Finished Dependency Resolution Dependencies Resolved ================================================================================================================================================ Package Arch Version Repository Size ================================================================================================================================================ Installing: percona-xtrabackup-24 x86_64 2.4.16-1.el7 tools-release-x86_64 7.6 M Transaction Summary Install 1 Package Total download size: 7.6 M Installed size: 7.6 M Downloading packages: percona-xtrabackup-24-2.4.16-1.el7.x86_64.rpm | 7.6 MB 00:01:49 Running transaction check Running transaction test Transaction test succeeded Running transaction Installing : percona-xtrabackup-24-2.4.16-1.el7.x86_64 1/1 Verifying : percona-xtrabackup-24-2.4.16-1.el7.x86_64 1/1 Installed: percona-xtrabackup-24.x86_64 0:2.4.16-1.el7 Complete! 4. ## 若要删除 Percona XtraBackup ，使用 root 账号或者 sudo 执行： ```shell [root@localhost databases]# rpm -qa|grep percona percona-xtrabackup-80-8.0.8-1.el7.x86_64 percona-release-1.0-13.noarch [root@localhost databases]# yum remove percona-xtrabackup-80-8.0.8-1.el7.x86_64 Loaded plugins: fastestmirror, langpacks Resolving Dependencies --&gt; Running transaction check ---&gt; Package percona-xtrabackup-80.x86_64 0:8.0.8-1.el7 will be erased --&gt; Finished Dependency Resolution Dependencies Resolved ================================================================================================================================================ Package Arch Version Repository Size ================================================================================================================================================ Removing: percona-xtrabackup-80 x86_64 8.0.8-1.el7 @tools-release-x86_64 54 M Transaction Summary ================================================================================================================================================ Remove 1 Package Installed size: 54 M Is this ok [y/N]: y Downloading packages: Running transaction check Running transaction test Transaction test succeeded Running transaction Erasing : percona-xtrabackup-80-8.0.8-1.el7.x86_64 1/1 Verifying : percona-xtrabackup-80-8.0.8-1.el7.x86_64 1/1 Removed: percona-xtrabackup-80.x86_64 0:8.0.8-1.el7 Complete! 检查是否成功安装 Percona XtraBackup[root@localhost databases]# xtrabackup -v xtrabackup: recognized server arguments: --datadir=/data1/databases/mysql/data xtrabackup version 2.4.16 based on MySQL server 5.7.26 Linux (x86_64) (revision id: c807cfa) xtrabackup实践操作全量备份 innobackupex --defaults-file=/etc/my.cnf --host=127.0.0.1 --user=root --password=123456 /data1/databases/backup/xfull/ 查看备份 [root@localhost databases]# ls /data1/databases/backup/xfull/ -lh total 4.0K drwxr-x---. 5 root root 4.0K Nov 28 22:08 2019-11-28_22-02-20 恢复 service mysql stop innobackupex --apply-log /data1/databases/backup/xfull/2019-11-28_22-02-20/ rm /data1/databases/mysql/data -rf innobackupex --defaults-file=/etc/my.cnf --copy-back --rsync /data1/databases/backup/xfull/2019-11-28_22-02-20/ chown -R mysql.mysql /data1/databases/mysql/ service mysql start 增量备份与恢复innobackupex增量备份过程中的”增量”处理，其实主要是相对innodb而言，对myisam和其他存储引擎而言，它仍然是全拷贝(全备份)增量备份从哪增量？基于上一次的备份进行增量。redo默认情况下是一组两个文件，并且有固定大小。其使用的文件是一种轮询使用方式，他不是永久的，文件随时可能被覆盖。 注意：千万不要在业务繁忙时做备份。 备份什么内容？ 1、可以使用binlog作为增量 2、自带的增量备份，基于上次备份后的变化的数据页，还要备份在备份过程中的undo、redo变化 操作1、先进行第一次全备 innobackupex --defaults-file=/etc/my.cnf --host=127.0.0.1 --user=root --password=123456 /data1/databases/backup/xfull/ 2、再进行增量备份。这个是在全备的基础上做的，需要指定全量备份的目录：/data1/databases/backup/xfull/ ；增量备份到 /data1/databases/backup//xinc1 innobackupex --defaults-file=/etc/my.cnf --host=127.0.0.1 --user=root --password=123456 --incremental --incremental-basedir=/data1/databases/backup/xfull/2019-11-28_22-02-20/ /data1/databases/backup/xinc1 恢复1、先应用全备日志 innobackupex --apply-log --redo-only /data1/databases/backup/xfull/2019-11-28_22-02-20/ 2、合并增量到全备中（一致性的合并） innobackupex --apply-log -redo-only --incremental-dir=/data1/databases/backup/xinc1/2019-11-28_22-22-57/ /data1/databases/backup/xfull/2019-11-28_22-02-20/ innobackupex --apply-log --incremental-dir=/data1/databases/backup/xinc1/2019-11-28_22-23-11/ /data1/databases/backup/xfull/2019-11-28_22-02-20/ innobackupex --apply-log /data1/databases/backup/xfull/2019-11-28_22-02-20/ 3、合并完成进行恢复使用innobackupex命令进行恢复(推荐) innobackupex --defaults-file=/etc/my.cnf --copy-back --rsync /data1/databases/backup/xfull/2019-11-28_22-02-20/ chown -R mysql.mysql /data1/databases/mysql/ 数据库备份策略每周的周日进行一次全备；周一到周六每天做上一天增量，每周轮询一次。备份方案： xtrabackup全备+增量 备份策略（crontab）： crontab -e # 每周一的凌晨3点执行完全备份 0 3 * * 1 /data1/databases/shell/allbak.sh &gt;/dev/null vim /root/allbak.sh #!/bin/bash tmpPath=/data1/databases/backup/xfull compressPath=/data1/databases/backup/compress/$(date &#39;+%Y/%m/&#39;) # 定义日期是时间 day=`date +%F` user=root pass=123456 host=127.0.0.1 # 新建个文件夹临时存放备份文件的 [ ! -e &quot;${tmpPath}/${day}-full&quot; ]&amp;&amp; mkdir -p &quot;${tmpPath}/${day}-full&quot; [ ! -e ${compressPath} ]&amp;&amp; mkdir -p ${compressPath} # 删除历史备份临时文件 [ -e ${tmpPath} ]&amp;&amp; rm -rf &quot;${tmpPath}/*&quot; # 用innobackupex做完全备份 innobackupex --host=$host --user=$user --password=$pass &quot;${tmpPath}/${day}-full&quot; --no-timestamp cd &quot;${tmpPath}&quot; echo &quot;$(date &#39;+%Y-%m-%d %H:%M:%S&#39;)&quot; &gt; &quot;${day}-full/time.txt&quot; echo &quot;本次全量备份时间： $(date &#39;+%Y-%m-%d %H:%M:%S&#39;)&quot; &gt;&gt; &quot;${day}-full/full.txt&quot; tar -czvf &quot;${compressPath}/$(date &#39;+%Y-%m-%d_%H_%M_%S&#39;)-full.tar.gz&quot; &quot;${day}-full&quot; # 启用binlog日志，每次完全备份之后，每周刷新一遍binlog日志 mysql -h$host -u$user -p$pass -e &quot;flush logs&quot; # 每周二到周日的凌晨4点执行增量备份 0 4 * * 2-7 /data1/databases/shell/newbak.sh &gt;/dev/null # 周一全备，如果是周二执行，判断dir1 存在，则增量备份，如果不存在，则判断昨天的增量，存在则执行周三的增量，如果都没有，则全备执行一次吧 vi /data1/databases/shell/newbak.sh #!/bin/bash # 定义时间，用日期来区分 d1=`date +%F` # 找到昨天的日期，好指明上一次备份的备份文件 d2=`date +%F -d &quot;-1 days&quot; ` # 昨天做的完全备份文件 dir1=&quot;/data1/databases/backup/xfull/${d2}-full&quot; #昨天做的增量备份文件 dir2=&quot;/data1/databases/backup/xincrement/${d2}-increment&quot; # 备份压缩文件存储路径 compressPath=/data1/databases/backup/compress/$(date &#39;+%Y/%m/&#39;) host=127.0.0.1 user=root pass=123456 # 如果文件不存在，则创建文件夹 [ ! -e $(dirname $dir1 ) ]&amp;&amp; mkdir -p $(dirname $dir1 ) [ ! -e $(dirname $dir2 ) ]&amp;&amp; mkdir -p $(dirname $dir2 ) [ ! -e ${compressPath} ]&amp;&amp; mkdir -p &quot;${compressPath}&quot; # 判断昨天做的是增量备份 if [ -e ${dir2} ];then # 指定昨天备份的增量备份文件 innobackupex --host=$host --user=$user --password=$pass --incremental &quot;$(dirname $dir2)/${d1}-increment&quot; --incremental-basedir=&quot;${dir2}&quot; --no-timestamp cd &quot;$(dirname $dir2)&quot; echo &quot;$(date &#39;+%Y-%m-%d %H:%M:%S&#39;)&quot; &gt; &quot;${d1}-increment/time.txt&quot; echo &quot;本次增量量备份时间： $(date &#39;+%Y-%m-%d %H:%M:%S&#39;)&quot; &gt; &quot;${d1}-increment/increment.txt&quot; echo &quot;基于上次增量备份时间： $(cat $dir2/time.txt)&quot; &gt;&gt; &quot;${d1}-increment/increment.txt&quot; tar -czvf &quot;${compressPath}/$(date &#39;+%Y-%m-%d_%H_%M_%S&#39;)-increment.tar.gz&quot; &quot;${d1}-increment&quot; echo &quot; 指定昨天备份的增量备份文件&quot; # 删除上次的增量备份的临时文件 [ -e &quot;${dir2}&quot; ]&amp;&amp; rm -rf &quot;${dir2}&quot; # 判断昨天做的是全量备份 elif [ -e ${dir1} ];then # 删除上次的增量备份的临时文件 [ -e &quot;$(dirname $dir2)&quot; ]&amp;&amp; rm -rf &quot;$(dirname $dir2)/*&quot; # 指定昨天备份的完全备份文件 innobackupex --host=$host --user=$user --password=$pass --incremental &quot;$(dirname $dir2)/${d1}-increment&quot; --incremental-basedir=${dir1} --no-timestamp cd &quot;$(dirname $dir2)&quot; echo &quot;$(date &#39;+%Y-%m-%d %H:%M:%S&#39;)&quot; &gt; &quot;${d1}-increment/time.txt&quot; echo &quot;本次增量量备份时间： $(date &#39;+%Y-%m-%d %H:%M:%S&#39;)&quot; &gt; &quot;${d1}-increment/increment.txt&quot; echo &quot;基于上次全量备份时间： $(cat $dir1/time.txt)&quot; &gt;&gt; &quot;${d1}-increment/increment.txt&quot; tar -czvf &quot;${compressPath}/$(date &#39;+%Y-%m-%d_%H_%M_%S&#39;)-increment.tar.gz&quot; &quot;${d1}-increment&quot; echo &quot; 指定昨天备份的完全备份文件 &quot; else # 昨天既没有做增量备份，又没有做完全备份，则做一次完全备份。 # 删除上次的全量备份的临时文件 [ -e &quot;$(dirname $dir1)&quot; ]&amp;&amp; rm -rf &quot;$(dirname $dir1)/*&quot; # 做一次完全备份。 innobackupex --host=$host --user=$user --password=$pass &quot;$(dirname $dir1)/${d1}-full&quot; --no-timestamp cd &quot;$(dirname $dir1)&quot; echo &quot;$(date &#39;+%Y-%m-%d %H:%M:%S&#39;)&quot; &gt; &quot;${d1}-full/time.txt&quot; echo &quot;本次全量备份时间： $(date &#39;+%Y-%m-%d %H:%M:%S&#39;)&quot; &gt; &quot;${d1}-full/full.txt&quot; tar -czvf &quot;${compressPath}/$(date &#39;+%Y-%m-%d_%H_%M_%S&#39;)-full.tar.gz&quot; &quot;${d1}-full&quot; echo &quot; 做一次完全备份&quot; fi echo &quot; ${dir1} ${dir2} ${compressPath}&quot; 实际应用 binlog日志 默认大小：1G左右，设置 ，配置文件里加一个 max_binlog_size = ？ 数据创建阶段 1、创建备份需要的目录 mkdir full inc1 inc2 2、周日全备 innobackupex --user=root --password=123 --no-timestamp /backup/xbackup/full/ 3、模拟数据变化 use oldboy create table test(id int,name char(20),age int); insert into test values(8,&#39;outman&#39;,99); insert into test values(9,&#39;outgirl&#39;,100); commit; 4、周一增量备份 innobackupex --user=root --password=123 --incremental --no-timestamp --incremental-basedir=/backup/xbackup/full/ /backup/xbackup/inc1 5、模拟数据变化 use oldboy insert into test values(8,&#39;outman1&#39;,119); insert into test values(9,&#39;outgirl1&#39;,120); commit; 6、周二的增量备份 innobackupex --user=root --password=123 --incremental --no-timestamp --incremental-basedir=/backup/xbackup/inc1 /backup/xbackup/inc2 再插入新的行操作 use oldboy insert into test values(10,&#39;outman2&#39;,19); insert into test values(11,&#39;outgirl2&#39;,10); commit; 模拟误操作事故 模拟场景，周二下午2点误删除test表 use oldboy; drop table test; 准备恢复数据 1.准备xtrabackup备份，合并备份 innobackupex --apply-log --redo-only /backup/xbackup/full innobackupex --apply-log --redo-only --incremental-dir=/backup/xbackup/inc1 /backup/xbackup/full innobackupex --apply-log --incremental-dir=/backup/xbackup/inc2 /backup/xbackup/full innobackupex --apply-log /backup/xbackup/full 2．确认binlog起点，准备截取binlog。 cd /backup/xbackup/inc2/ cat xtrabackup_binlog_info mysql-bin.000001 1121 3.截取到drop操作之前的binlog mysqlbinlog --start-position=1121 /tmp/mysql-bin.000003 找到drop之前的event和postion号做日志截取，假如 1437 这个可以用 mysqlbinlog master-bin.000032|less mysqlbinlog --start-position=1121 --stop-position=1437 /tmp/mysql-bin.000003 &gt;/tmp/incbinlog.sql 4．关闭数据库、备份二进制日志 /etc/init.d/mysqld stop cd /application/mysql/data/ cp mysql-bin.000001 /tmp 5.删除MySQL所有数据 cd /application/mysql/data/ rm -rf * 恢复数据 1．将全量备份的数据恢复到数据目录下 innobackupex --defaults-file=/etc/my.cnf --copy-back --rsync /backup/xbackup/full/ chown -R mysql.mysql /application/mysql/data/ /etc/init.d/mysqld start 2.恢复binlog记录 set sql_log_bin=0 source /tmp/incbinlog.sql]]></content>
      <categories>
        <category>centos</category>
        <category>mysql</category>
        <category>Percona XtraBackup</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>mysql</tag>
        <tag>Percona XtraBackup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[归并排序]]></title>
    <url>%2Falgorithm-merge-sort%2F</url>
    <content type="text"><![CDATA[归并 （Merge） 排序法是将两个 （或两个以上）有序表合并成一个新的有序表，即把待排序序列分为多干个子序列，每个子序列是有序的。然后再把有序子序列合并为整体有序序列。 public class MergeSortTest { public static void main(String[] args){ int[] data = new int[]{5, 3, 6, 2, 1, 9, 4, 8, 7}; print(data); mergeSort(data); System.out.println(&quot;排序后的数组&quot;); print(data); } public static void mergeSort(int[] data){ sort(data,0,data.length-1); } public void sort(int[] data, int left, int right){ if(left&gt;=right){ return; } // 找出中间索引 int center = (left + right)/2; // 对左边数组进行递归 sort(data,left,center); // 对右边数组进行递归 sort(data, center+1, right); // 合并 merge(data, left, center, right); print(data); } /** * 将两个数组进行归并，归并前面 2 个数组已经有序，归并后依然有序 * * @param data * 数组对象 * @param left * 左数组的第一个元素的索引 * @param center * 左数组的最后一个元素的索引，center+1 是右数组第一个元素的索引 * @param right * 右数组最后一个元素的索引 */ public static void merge(int[] data, int left, int center, int right) { // 临时数组 int[] tmpArr = new int[data.length]; // 右数组第一个元素索引 int mid = center + 1; // third 记录临时数组的索引 int third = left; // 缓存数组第一个元素的索引 int tmp = left; while(left &lt;= center &amp;&amp; mid &lt;= right){ // 从两个数组中取出最小的放入临时数组 if(data[left] &lt;= data[mid]){ tmpArr[third++] = data[left++]; }else { tempArr[third++] = data[mid++]; } } // 剩余部分依次放入临时数组 （实际上两个 while 只会执行其中一个） while(mid &lt;=right){ tmpArr[third++] = data[mid++]; } while(left &lt;= center){ temArr[third++] = data[left++]; } // 将临时数组中的内容拷贝会原数组中 // （原 left-right 范围的内容被复制回原数组） while(tmp &lt;= right){ data[tmp] = tempArr[tmp++]; } } public static void print(int[] data){ for(int i = 0 ; i &lt; data.length; i++){ System.out.print(data[i] + &quot;\t&quot;); } System.out.println(); } }]]></content>
      <categories>
        <category>java</category>
        <category>algorithm</category>
        <category>merge sort</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>algorithm</tag>
        <tag>merge sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[希尔排序]]></title>
    <url>%2Falgorithm-shell-sort%2F</url>
    <content type="text"><![CDATA[基本思想：先将整个待排序的记录分割成若干子序列分别进行插入排序，待整个序列中的记录 ”基本有序“ 时，再对全体记录进行依次直接插入排序。 1.操作方法： ​ 选择一个增量序列 t1, t2, …, tk, 其中 ti&gt;tj, tk=1; 2.按增量序列个数 k，对序列进行 k 趟排序； 3.每趟排序，根据对应的增量 ti，将待排序列分割成若干长度为 m 的子序列，分别对各字表进行直接插入排序。仅增量因子为 1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 private void shellSort(int[] a){ int dk = a.length/2; while(dk&gt;1){ ShellInSertSort(a,dk); dk /= 2; } } private void ShellInsertSort(int[] a,int dk){ // 类似插入排序，只是插入排序增量是1，这里增量是 dk，把 1 换成 dk 就可以了 for(int i=dk; i&lt;a.length; i++){ if(a[i]&lt;a[i-dk]){ int j ; int x = a[i]; // X 为待插入元素 a[i] = a[i-dk]; for(j=i-dk; j&gt;=0 &amp;&amp; x&lt;a[j]; j=j-dk){ // 通过循环，逐个后移一位找到要插入的位置。 a[j+dk] = a[j]; } a[j+dk]=x; // 插入 } } }]]></content>
      <categories>
        <category>java</category>
        <category>algorithm</category>
        <category>shell sort</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>algorithm</tag>
        <tag>shell sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速排序]]></title>
    <url>%2Falgorithm-quick-sort%2F</url>
    <content type="text"><![CDATA[快速排序的原理：选择一个关键值作为基准值。比较基准值小的都放在左边序列(一般是无序的), 比基准值大的都在右边(一般是无序的)。一般选择序列的第一个元素。 一次循环：从后往前比较，用基准值和最后一个值比较，如果比基准值小的交换位置，如果没有继续比较下一个，知道找到第一个比基准值小的值才交换。找到这个值之后，又从前往后开始比较，如果有比基准值大的，交换位置，如果没有继续比较下一个，直到找到第一个比基准值大的值才交换。直到从前往后的比较索引&gt;从后往前比较的索引，结束第一次比较的索引，结束第一次循环，此时，对于基准值来说，左右两边就是有序的了。 public void sort(int[] a, int low, int high){ int start = low; int end = high; int key = a[low]; while(end&gt;start){ // 从后往前比较 while(end&gt;start &amp;&amp; a[end]&gt;=key){ // 如果没有比关键值小的，比较下一个，直到有比关键值小的交换位置，然后又从前往后比较 end--; if(a[end]&lt;=key){ int tem = a[end]; a[end] = a[start]; } // 从前往后比较 while(end&gt;start &amp;&amp; a[start]&lt;=key){ start++; } if(a[start]&gt;=key){ int temp = a[start]; a[start] = a[end]; a[end] = temp; } // 此时第一次循环比较结束，关键值的位置已经确定了。左边的值都比关键值小，右边的值都比关键值大，但是两边的顺序还有可能是不一样的，进行下面的递归调用 } // 递归 if(start&gt;low){ // 左边序列。第一个索引位置到关键值索引-1 sort(a,low,start-1); } if(end&lt;hight){ // 右边序列。从关键值索引+1 到最后一个 sort(a,end+1,high); } } }]]></content>
      <categories>
        <category>java</category>
        <category>algorithm</category>
        <category>quick sort</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>algorithm</tag>
        <tag>quick sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[插入排序]]></title>
    <url>%2Falgorithm-insert-sort%2F</url>
    <content type="text"><![CDATA[通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应的位置并插入。插入排序非常类似于整扑克。在开始摸牌时，左手是空的，牌面朝下放在桌面。接着，一次从桌上磨起一张牌，并将它插入到左手一把牌中的正确位置上。为了找到这张牌的正确位置，要将它与手中已有的牌从左到右地进行比较。无论什么时候，左手中的牌都是排好序的。 如果输入数组已经是排好序的话，插入排序出现最佳情况，其运行时间是输入规模的一个线性函数。如果输入数组是逆序排列的，将出现最坏情况。平均情况与最坏情况一样，其时间代价是($$n^2$$)。 public void sort(int arr[]){ for(int i = 1; i&lt;arr.length; i++){ // 插入的数 int insertVal = arr[i]; // 被插入的位置(准备和前一个数比较) int index = i-1; // 如果插入的数比被插入的数小 while(index&gt;=0 &amp;&amp; insertVal&lt;arr[index]){ // 将把 arr[index] 向后移动 arr[index+1] = arr[index]; // 让 index 向前移动 index--; } // 把插入的数放入合适位置 arr[index+1]=insertVal; } }]]></content>
      <categories>
        <category>java</category>
        <category>algorithm</category>
        <category>insert sort</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>algorithm</tag>
        <tag>insert sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[冒泡排序]]></title>
    <url>%2Falgorithm-bubble-sort%2F</url>
    <content type="text"><![CDATA[(1) 比较前后相邻的二个数据，如果前面数据大于后面的数据，就将这二个数据交换。 (2) 这样对数组的第 0 个数据到 N-1 个数据进行一次遍历后，最大的一个数据就 ”沉“ 到数组di N-1 个位置。 (3) N=N-1，如果 N 不为 0 就重复前面二步，否则排序完成。 public static void bubbleSort(int [] a){ int n = a.length; int i,j; for(i=0; i&lt;n; i++){ // 表示 n 次排序过程 for(j=1; j&lt;n-i; j++){ if(a[j-1] &gt; a[j]){ // 前面的数字大于后面的数字就交换 // 交换 a[j-i] 和 a[j] int temp ; temp = a[j-1]; a[j-1] = a[j]; a[j] = temp; } } } }]]></content>
      <categories>
        <category>java</category>
        <category>algorithm</category>
        <category>bubble sort</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[二分查找]]></title>
    <url>%2Falgorithm-bi-search%2F</url>
    <content type="text"><![CDATA[又叫折半查找，要求待查找的序列有序。每次取中间位置与待查关键字比较，如果中间位置的值比待查关键字大，则在前半部分循环这个查找的过程，如果中间位置的值比待查关键字小，则在后半部分循环这个查找的过程。直到查找到了为止。否则序列中没有待查的关键字。 Java 代码实现如下 public static int biSearch(int []array, int a){ int lo = 0; int hi = array.length - 1; int mid; while(lo&lt;=hi){ mid=(lo+li)/2; // 中间位置 if(array[mid]==a){ return mid + 1; }else if(array[mid]&lt;a){ // 向右查找 lo = mid + 1; }else { // 向左查找 hi = mid - 1; } } return -1; }]]></content>
      <categories>
        <category>java</category>
        <category>algorithm</category>
        <category>biSearch</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>algorithm</tag>
        <tag>biSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kibana 认证登录]]></title>
    <url>%2Fkibana-auth%2F</url>
    <content type="text"><![CDATA[Kibana从5.5开始不提供认证功能，用官方的认证X-Pack，则需购买授权许可。 为了安全访问，我们可以使用Nginx的代理功能来认证登录 安装Nginx安装Apache密码生产工具 yum install httpd-tools 生成密码文件 mkdir -p /etc/nginx/passwd htpasswd -c -b /etc/nginx/passwd/kibana.passwd admin 123456 配置Nginx vim /usr/local/nginx/nginx.conf server { listen 172.20.8.113:5601; auth_basic &quot;Kibana Auth&quot;; auth_basic_user_file /etc/nginx/passwd/kibana.passwd; location / { proxy_pass http://127.0.0.1:5601; proxy_redirect off; } } 修改Kibana配置文件 vim /usr/local/kibana/config/kibana.yml # The host to bind the server to. server.host: &quot;localhost&quot; 重启Kibana服务，配置文件生效 systemctl restart kibana 重载Nginx配置 nginx -s reload 登录KibanaURL: http://172.20.8.113:5601]]></content>
      <categories>
        <category>kibana</category>
        <category>nginx</category>
        <category>htpasswd</category>
        <category>auth</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>kibana</tag>
        <tag>htpasswd</tag>
        <tag>auth</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[wget参数使用参考]]></title>
    <url>%2Fwget-use%2F</url>
    <content type="text"><![CDATA[wget是一个从网络上自动下载文件的自由工具。它支持HTTP，HTTPS和FTP协议，可以使用HTTP代理. 所谓的自动下载是指，wget可以在用户退出系统的之后在后台执行。这意味这你可以登录系统，启动一个wget下载任务，然后退出系统，wget将在后台执行直到任务完成，相对于其它大部分浏览器在下载大量数据时需要用户一直的参与，这省去了极大的麻烦。 ​ wget 可以跟踪HTML页面上的链接依次下载来创建远程服务器的本地版本，完全重建原始站点的目录结构。这又常被称作”递归下载”。在递归下载的时候，wget 遵循Robot Exclusion标准(/robots.txt)。wget可以在下载的同时，将链接转换成指向本地文件，以方便离线浏览。 ​ wget 非常稳定,它在带宽很窄的情况下和不稳定网络中有很强的适应性.如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。如果是服务 器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。 wget的常见用法： wget不但功能强大，而且使用起来比较简单 基本的语法是：wget [参数列表] &quot;URL&quot; 用””引起来可以避免因URL中有特殊字符造成的下载出错。 下面就结合具体的例子来说明一下wget的用法。 ​ 1、下载整个http或者ftp站点。 wget http://place.your.url/here 这个命令可以将http://place.your.url/here首页下载下来。使用-x会强制建立服务器上一模一样的目录，如果使用-nd参数，那么服务器上下载的所有内容都会加到本地当前目录。 wget -r http://place.your.url/here ​ 这个命令会按照递归的方法，下载服务器上所有的目录和文件，实质就是下载整个网站。这个命令一定要小心使用，因为在下载的时候，被下载网站指向的所有地址 同样会被下载，因此，如果这个网站引用了其他网站，那么被引用的网站也会被下载下来！基于这个原因，这个参数不常用。可以用-l number参数来指定下载的层次。例如只下载两层，那么使用-l 2。 ​ 要是您想制作镜像站点，那么可以使用－m参数，例如： wget -m http://place.your.url/here ​ 这时wget会自动判断合适的参数来制作镜像站点。此时，wget会登录到服务器上，读入robots.txt并按robots.txt的规定来执行。 ​ 2、断点续传。​ 当文件特别大或者网络特别慢的时候，往往一个文件还没有下载完，连接就已经被切断，此时就需要断点续传。wget的断点续传是自动的，只需要使用-c参数，例如：​ wget -c http://the.url.of/incomplete/file ​ 使用断点续传要求服务器支持断点续传。-t参数表示重试次数，例如需要重试100次，那么就写-t 100，如果设成-t 0，那么表示无穷次重试，直到连接成功。-T参数表示超时等待时间，例如-T 120，表示等待120秒连接不上就算超时。 ​ 3、批量下载。​ 如果有多个文件需要下载，那么可以生成一个文件，把每个文件的URL写一行，例如生成文件download.txt，然后用命令：wget -i download.txt这样就会把download.txt里面列出的每个URL都下载下来。（如果列的是文件就下载文件，如果列的是网站，那么下载首页） ​ 4、选择性的下载。​ 可以指定让wget只下载一类文件，或者不下载什么文件。例如： wget -m --reject=gif http://target.web.site/subdirectory ​ 表示下载http://target.web.site/subdirectory，但是忽略gif文件。--accept=LIST可以接受的文件类型，--reject=LIST拒绝接受的文件类型。 ​ 表示下载http://target.web.site/subdirectory，但是忽略gif文件。–accept=LIST 可以接受的文件类型，–reject=LIST拒绝接受的文件类型。 ​ 5、密码和认证。​ wget只能处理利用用户名/密码方式限制访问的网站，可以利用两个参数：​ --http-user=USER设置HTTP用户​ --http-passwd=PASS设置HTTP密码​ 对于需要证书做认证的网站，就只能利用其他下载工具了，例如curl。 ​ 6、利用代理服务器进行下载。​ 如果用户的网络需要经过代理服务器，那么可以让wget通过代理服务器进行文件的下载。此时需要在当前用户的目录下创建一个.wgetrc文件。文件中可以设置代理服务器： http-proxy = 111.111.111.111:8080 ftp-proxy = 111.111.111.111:8080 ​ 分别表示http的代理服务器和ftp的代理服务器。如果代理服务器需要密码则使用：​ --proxy-user=USER设置代理用户​ --proxy-passwd=PASS设置代理密码​ 这两个参数。​ 使用参数--proxy=on/off 使用或者关闭代理。​ wget还有很多有用的功能，需要用户去挖掘。 ​ 分别表示http的代理服务器和ftp的代理服务器。如果代理服务器需要密码则使用：​ --proxy-user=USER设置代理用户​ --proxy-passwd=PASS设置代理密码​ 这两个参数。​ 使用参数–proxy=on/off 使用或者关闭代理。​ wget还有很多有用的功能，需要用户去挖掘。 wget的使用格式 Usage: wget [OPTION]... [URL]... 用wget做站点镜像: wget -r -p -np -k http://dsec.pku.edu.cn/~usr_name/ # 或者 wget -m http://dsec.pku.edu.cn/~usr_name/ # 在不稳定的网络上下载一个部分下载的文件，以及在空闲时段下载 wget -t 0 -w 31 -c http://dsec.pku.edu.cn/BBC.avi -o down.log &amp; # 或者从filelist读入要下载的文件列表 wget -t 0 -w 31 -c -B ftp://dsec.pku.edu.cn/linuxsoft -i filelist.txt -o down.log &amp; 上面的代码还可以用来在网络比较空闲的时段进行下载。我的用法是:在mozilla中将不方便当时下载的URL链接拷贝到内存中然后粘贴到文件filelist.txt中，在晚上要出去系统前执行上面代码的第二条。 # 使用代理下载 wget -Y on -p -k https://sourceforge.net/projects/wvware/ 代理可以在环境变量或wgetrc文件中设定 # 在环境变量中设定代理 export PROXY=http://211.90.168.94:8080/ # 在~/.wgetrc中设定代理 http_proxy = http://proxy.yoyodyne.com:18023/ ftp_proxy = http://proxy.yoyodyne.com:18023/ wget各种选项分类列表 启动 -V, --version 显示wget的版本后退出 -h, --help 打印语法帮助 -b, --background 启动后转入后台执行 -e, --execute=COMMAND 执行.wgetrc’格式的命令，wgetrc格式参见/etc/wgetrc或~/.wgetrc` 记录和输入文件 -o, --output-file=FILE 把记录写到FILE文件中 -a, --append-output=FILE 把记录追加到FILE文件中 -d, --debug 打印调试输出 -q, --quiet 安静模式(没有输出) -v, --verbose 冗长模式(这是缺省设置) -nv, --non-verbose 关掉冗长模式，但不是安静模式 -i, --input-file=FILE 下载在FILE文件中出现的URLs -F, --force-html 把输入文件当作HTML格式文件对待 -B, --base=URL 将URL作为在-F -i参数指定的文件中出现的相对链接的前缀 --sslcertfile=FILE 可选客户端证书 --sslcertkey=KEYFILE 可选客户端证书的KEYFILE --egd-file=FILE 指定EGD socket的文件名 下载 --bind-address=ADDRESS 指定本地使用地址(主机名或IP，当本地有多个IP或名字时使用) -t, --tries=NUMBER 设定最大尝试链接次数(0 表示无限制). -O --output-document=FILE 把文档写到FILE文件中 -nc, --no-clobber 不要覆盖存在的文件或使用.#前缀 -c, --continue 接着下载没下载完的文件 --progress=TYPE 设定进程条标记 -N, --timestamping 不要重新下载文件除非比本地文件新 -S, --server-response 打印服务器的回应 --spider 不下载任何东西 -T, --timeout=SECONDS 设定响应超时的秒数 -w, --wait=SECONDS 两次尝试之间间隔SECONDS秒--waitretry=SECONDS 在重新链接之间等待1…SECONDS秒 --random-wait 在下载之间等待0…2*WAIT秒 -Y, --proxy=on/off 打开或关闭代理 -Q, --quota=NUMBER 设置下载的容量限制 --limit-rate=RATE 限定下载输率 目录 -nd --no-directories 不创建目录 -x, --force-directories 强制创建目录 -nH, --no-host-directories 不创建主机目录 -P, --directory-prefix=PREFIX 将文件保存到目录 PREFIX/… --cut-dirs=NUMBER 忽略 NUMBER层远程目录 HTTP 选项 --http-user=USER 设定HTTP用户名为 USER. --http-passwd=PASS 设定http密码为 PASS. -C, --cache=on/off 允许/不允许服务器端的数据缓存 (一般情况下允许). -E, --html-extension 将所有text/html文档以.html扩展名保存 --ignore-length 忽略Content-Length头域 --header=STRING 在headers中插入字符串 STRING --proxy-user=USER 设定代理的用户名为USER --proxy-passwd=PASS 设定代理的密码为PASS --referer=URL 在HTTP请求中包含Referer: URL头 -s, --save-headers 保存HTTP头到文件 -U, --user-agent=AGENT 设定代理的名称为AGENT而不是Wget/VERSION. --no-http-keep-alive 关闭HTTP活动链接 (永远链接). --cookies=off 不使用cookies. --load-cookies=FILE 在开始会话前从文件FILE中加载cookie --save-cookies=FILE 在会话结束后将 cookies保存到 FILE文件中 FTP 选项 -nr, --dont-remove-listing 不移走.listing’`文件 -g, --glob=on/off 打开或关闭文件名的globbing机制 --passive-ftp 使用被动传输模式 (缺省值). --active-ftp 使用主动传输模式 --retr-symlinks 在递归的时候，将链接指向文件(而不是目录) 递归下载 -r, --recursive 递归下载－－慎用! -l, --level=NUMBER 最大递归深度 (inf 或 0 代表无穷). --delete-after 在现在完毕后局部删除文件 -k, --convert-links 转换非相对链接为相对链接 -K, --backup-converted 在转换文件X之前，将之备份为X.orig -m, --mirror 等价于-r -N -l inf -nr. -p, --page-requisites 下载显示HTML文件的所有图片 递归下载中的包含和不包含(accept/reject) -A, --accept=LIST 分号分隔的被接受扩展名的列表 -R, --reject=LIST 分号分隔的不被接受的扩展名的列表 -D, --domains=LIST 分号分隔的被接受域的列表 --exclude-domains=LIST 分号分隔的不被接受的域的列表 --follow-ftp 跟踪HTML文档中的FTP链接 --follow-tags=LIST 分号分隔的被跟踪的HTML标签的列表 -G, --ignore-tags=LIST 分号分隔的被忽略的HTML标签的列表 -H, --span-hosts 当递归时转到外部主机 -L, --relative 仅仅跟踪相对链接 -I, --include-directories=LIST 允许目录的列表 -X, --exclude-directories=LIST 不被包含目录的列表 -np, --no-parent 不要追溯到父目录 wget -S --spider url 不下载只显示过程]]></content>
      <categories>
        <category>wget</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>wget</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[javascript正则表达式验证数字]]></title>
    <url>%2Fjs-reg-exp%2F</url>
    <content type="text"><![CDATA[javascript 验证输入的是否为正确的数组 function validate(){ var reg = new RegExp(&quot;^[0-9]*$&quot;); var obj = document.getElementById(&quot;name&quot;); if(!reg.test(obj.value)){ alert(&quot;请输入数字!&quot;); } if(!/^[0-9]*$/.test(obj.value)){ alert(&quot;请输入数字!&quot;); } } 验证数字的正则表达式集 验证数字：^[0-9]*$ 验证n位的数字：^\d{n}$ 验证至少n位数字：^\d{n,}$ 验证m-n位的数字：^\d{m,n}$ 验证零和非零开头的数字：^(0|[1-9][0-9]*)$ 验证有两位小数的正实数：^[0-9]+(.[0-9]{2})?$ 验证有1-3位小数的正实数：^[0-9]+(.[0-9]{1,3})?$ 验证非零的正整数：^\+?[1-9][0-9]*$ 验证非零的负整数：^\-[1-9][0-9]*$ 验证非负整数（正整数 + 0） ^\d+$ 验证非正整数（负整数 + 0） ^((-\d+)|(0+))$ 验证长度为3的字符：^.{3}$ 验证由26个英文字母组成的字符串：^[A-Za-z]+$ 验证由26个大写英文字母组成的字符串：^[A-Z]+$ 验证由26个小写英文字母组成的字符串：^[a-z]+$ 验证由数字和26个英文字母组成的字符串：^[A-Za-z0-9]+$ 验证由数字、26个英文字母或者下划线组成的字符串：^\w+$ 验证用户密码:^[a-zA-Z]\w{5,17}$ 正确格式为：以字母开头，长度在6-18之间，只能包含字符、数字和下划线。 验证是否含有 ^%&amp;&#39;,;=?$\&quot; 等字符：[^%&amp;&#39;,;=?$\x22]+ 验证汉字：^[\u4e00-\u9fa5],{0,}$ 验证Email地址：^\w+[-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)*$ 验证InternetURL：^http://([\w-]+\.)+[\w-]+(/[\w-./?%&amp;=]*)?$ ；^[a-zA-z]+://(w+(-w+)*)(.(w+(-w+)*))*(?S*)?$ 验证电话号码：^(\(\d{3,4}\)|\d{3,4}-)?\d{7,8}$ 正确格式为：XXXX-XXXXXXX，XXXX-XXXXXXXX，XXX-XXXXXXX，XXX-XXXXXXXX，XXXXXXX，XXXXXXXX。 验证身份证号（15位或18位数字）：^\d{15}|\d{}18$验证一年的12个月：^(0?[1-9]|1[0-2])$正确格式为：“01”-“09”和“1”“12”验证一个月的31天：^((0?[1-9])|((1|2)[0-9])|30|31)$正确格式为：01、09和1、31。整数：^-?\d+$非负浮点数（正浮点数 + 0）：^\d+(\.\d+)?$正浮点数^(([0-9]+\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\.[0-9]+)|([0-9]*[1-9][0-9]*))$非正浮点数（负浮点数 + 0）^((-\d+(\.\d+)?)|(0+(\.0+)?))$负浮点数 ^(-(([0-9]+\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\.[0-9]+)|([0-9]*[1-9][0-9]*)))$浮点数^(-?\d+)(\.\d+)?$]]></content>
      <categories>
        <category>正则</category>
      </categories>
      <tags>
        <tag>正则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS firewall添加开放端口]]></title>
    <url>%2FCentOS-7-firewall%2F</url>
    <content type="text"><![CDATA[添加 firewall-cmd --zone=public --add-port=80/tcp --permanent （ –permanent 永久生效，没有此参数重启后失效） 查看 firewall-cmd --zone=public --query-port=80/tcp 删除 firewall-cmd --zone=public --remove-port=80/tcp --permanent 重新载入 firewall-cmd --reload 1、firewalld的基本使用 启动： systemctl start firewalld 查看状态： systemctl status firewalld 停止： systemctl disable firewalld 禁用： systemctl stop firewalld 2.systemctl是 CentOS 7 的服务管理工具中主要的工具，它融合之前 service 和 chkconfig 的功能于一体。 启动一个服务：systemctl start firewalld.service关闭一个服务：systemctl stop firewalld.service重启一个服务：systemctl restart firewalld.service显示一个服务的状态：systemctl status firewalld.service在开机时启用一个服务：systemctl enable firewalld.service在开机时禁用一个服务：systemctl disable firewalld.service查看服务是否开机启动：systemctl is-enabled firewalld.service查看已启动的服务列表：systemctl list-unit-files|grep enabled查看启动失败的服务列表：systemctl --failed 3.配置firewalld-cmd 查看版本： firewall-cmd --version 查看帮助： firewall-cmd --help 显示状态： firewall-cmd --state 查看所有打开的端口： firewall-cmd --zone=public --list-ports 更新防火墙规则： firewall-cmd --reload 查看区域信息: firewall-cmd --get-active-zones 查看指定接口所属区域： firewall-cmd --get-zone-of-interface=eth0 拒绝所有包：firewall-cmd --panic-on 取消拒绝状态： firewall-cmd --panic-off 查看是否拒绝： firewall-cmd --query-panic 那怎么开启一个端口呢接下来通过以下命令开放http 80 端口： sudo firewall-cmd --add-service=http --permanent sudo firewall-cmd --add-port=80/tcp --permanent 命令末尾的 —permanent 表示用久有效，不加这句的话重启后刚才开放的端口就又失效了。 然后重启防火墙： sudo firewall-cmd --reload 再次查看端口的开放情况： sudo firewall-cmd --list-all 查看 firewall-cmd --zone=public --query-service=http firewall-cmd --zone=public --query-port=80/tcp 删除 firewall-cmd --zone=public --remove-service=http --permanent firewall-cmd --zone=public --remove-port=80/tcp --permanent]]></content>
      <categories>
        <category>centos firewall</category>
      </categories>
      <tags>
        <tag>centos firewall</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 修改ssh 端口]]></title>
    <url>%2FCentOS-7-Modify-sshd-port%2F</url>
    <content type="text"><![CDATA[修改/etc/ssh/sshd_configvi /etc/ssh/sshd_config Port 22 //这行去掉#号，防止配置不好以后不能远程登录，还得去机房修改，等修改以后的端口能使用以后在注释掉 Port 33378 //下面添加这一行 修改firewall配置firewall添加想要修改的ssh端口： 添加到防火墙： firewall-cmd --zone=public --add-port=33378/tcp --permanent (permanent是保存配置，不然下次重启以后这次修改无效) 重启： firewall-cmd --reload 查看添加端口是否成功，如果添加成功则会显示yes，否则no firewall-cmd --zone=public --query-port=33378/tcp 修改SELinux使用以下命令查看当前SElinux 允许的ssh端口： semanage port -l | grep ssh 添加33378端口到 SELinux semanage port -a -t ssh_port_t -p tcp 33378 然后确认一下是否添加进去 semanage port -l | grep ssh 如果成功会输出 ssh_port_t tcp 33378, 22 重启ssh systemctl restart sshd.service 测试新端口的ssh连接测试修改端口以后的ssh连接，如果成功则将step1里面的port 22 重新注释掉 测试新端口的ssh连接测试修改端口以后的ssh连接，如果成功则将step1里面的port 22 重新注释掉 解决CentOS7 下 SSH登录慢的问题登陆SSH时 输入完用户名后要等一会才能输入密码，经总结下面方案可解决此问题。 修改sshd_config以下两处，重启ssh即可。 # vi /etc/ssh/sshd_config GSSAPIAuthentication no UseDNS no 重启 ssh # systemctl restart sshd]]></content>
      <categories>
        <category>centos</category>
        <category>sshd</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>sshd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7上部署vnc服务器并实现远程桌面]]></title>
    <url>%2FCentOS-VNCserver%2F</url>
    <content type="text"><![CDATA[一、安装X Window System注：若已经安装GUI则可跳过 1、切换到root用户，执行 yum groupinstall &quot;X Window System&quot;2、执行 yum install gnome-classic-session gnome-terminal nautilus-open-terminal control-center liberation-mono-fonts dejavu-lgc-sans-fonts -y 安装相关组件3、设置默认启动图形界面 yum groupinstall -y &quot;Fonts&quot; 4、设置默认启动图形界面 # unlink /etc/systemd/system/default.target # ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target 5、重启系统生效 # reboot 二、安装vnc服务1、执行yum install tigervnc-server -y安装VNC服务器软件# yum install tigervnc-server -y Loaded plugins: fastestmirror, langpacks Loading mirror speeds from cached hostfile * base: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirror.lzu.edu.cn base | 3.6 kB 00:00:00 extras | 3.4 kB 00:00:00 updates | 3.4 kB 00:00:00 Resolving Dependencies --&gt; Running transaction check ---&gt; Package tigervnc-server.x86_64 0:1.8.0-13.el7 will be installed --&gt; Finished Dependency Resolution Dependencies Resolved =================================================================================================================================================================================================================== Package Arch Version Repository Size =================================================================================================================================================================================================================== Installing: tigervnc-server x86_64 1.8.0-13.el7 base 215 k Transaction Summary =================================================================================================================================================================================================================== Install 1 Package Total download size: 215 k Installed size: 509 k Downloading packages: tigervnc-server-1.8.0-13.el7.x86_64.rpm | 215 kB 00:00:00 Running transaction check Running transaction test Transaction test succeeded Running transaction Installing : tigervnc-server-1.8.0-13.el7.x86_64 1/1 Verifying : tigervnc-server-1.8.0-13.el7.x86_64 1/1 Installed: tigervnc-server.x86_64 0:1.8.0-13.el7 Complete! 2、配置VNC在/etc/systemd/system目录里创建一个配置文件（可以将/lib/systemd/system/vncserver@.service拷贝一份配置文件范例过来） cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service 使用文本编辑器打开 /etc/systemd/system/vncserver@:1.service ，找到下面这几行，用自己的用户名替换掉 &lt;USER&gt; User=&lt;USER&gt; PIDFile=/home/&lt;USER&gt;/.vnc/%H%i.pid 替换成 User=root PIDFile=/home/root/.vnc/%H%i.pid 重启systemd systemctl daemon-reload vncpasswd设置VNC登录密码 vncpasswd 执行vncserver开启一个VNC窗口 # vncserver You will require a password to access your desktops. Password: Verify: Would you like to enter a view-only password (y/n)? n A view-only password is not used xauth: file /root/.Xauthority does not exist New &#39;server:1 (root)&#39; desktop is server:1 Creating default startup script /root/.vnc/xstartup Creating default config /root/.vnc/config Starting applications specified in /root/.vnc/xstartup Log file is /root/.vnc/server:1.log 开启远程端口 # vncserver :1 A VNC server is already running as :1 New &#39;server:2 (root)&#39; desktop is server:2 Starting applications specified in /root/.vnc/xstartup Log file is /root/.vnc/server:2.log 设置防火墙规则，允许访问VNC-SERVER的流量通过，并重启firewall服务使之生效 # firewall-cmd --permanent --add-service vnc-server # systemctl restart firewalld.service 三、客户端连接 VNC server客户端可以使用官方，直接去 官网 下载，推荐使用 MobaXterm，集成常用 ssh，sftp 等功能。 地址栏填写：ip::5901。例如：172.20.8.31::5901 我们开启的是vncserver :1，而 vncserver 默认从5900开始，所以我们使用 5900+1 = 5901，注意需要两个 :: 接下来输入服务端设置的 vncserver 的密码就可以了。 注意关闭防火墙和selinux 其他设置参考：https://blog.csdn.net/yxc2959/article/details/79100724]]></content>
      <categories>
        <category>centos vnc</category>
      </categories>
      <tags>
        <tag>centos vnc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装 go-fastdfs]]></title>
    <url>%2FCentOS-7-install-GoFastdfs%2F</url>
    <content type="text"><![CDATA[CentOS 7 安装go-fastdfs文件服务 参照官网描述（https://github.com/sjqzhang/go-fastdfs），linux下go-fastdfs安装步骤如下： 下载文件下载相关文件并赋予执行权限$ wget https://github.com/sjqzhang/go-fastdfs/releases/download/v1.3.0/fileserver $ wget https://raw.githubusercontent.com/sjqzhang/go-fastdfs/master/control $ chmod 755 fileserver $ chmod 755 control 常用命令启动/停止/重启/查看状态/查看日志 ./control start|stop|restart|status|tail $ ./control start fileserver started..., pid=20599 $ ./control status fileserver now is running, pid=1080 $ ./control stop fileserver stoped... $ ./control tail Listen on :28088 测试上传启动后可以使用命令体验上传curl -F file=@http-index-fs http://10.1.xx.60:8080/upload web上传使用浏览器打开http://yourserver ip:8080/upload.html，注意不要使用127.0.0.1上传 修改配置在fileserver同目录下会自动生成配置文件，存放在 conf/cfg.json，需要修改几个参数，其他参数按需求修改。 &quot;绑定端号&quot;: &quot;端口&quot;, &quot;addr&quot;: &quot;:28088&quot;, &quot;本主机地址&quot;: &quot;本机http地址,默认自动生成(注意端口必须与addr中的端口一致），必段为内网，自动生成不为内网请自行修改，下同&quot;, &quot;host&quot;: &quot;http://172.20.8.31:28088&quot;, &quot;集群&quot;: &quot;集群列表,注意为了高可用，IP必须不能是同一个,同一不会自动备份，且不能为127.0.0.1,且必须为内网IP，默认自动生成&quot;, &quot;peers&quot;: [&quot;http://172.20.8.31:28088&quot;], &quot;是否自动重命名&quot;: &quot;默认不自动重命名,使用原文件名&quot;, &quot;rename_file&quot;: true, &quot;下载域名&quot;: &quot;用于外网下载文件的域名,不包含http://&quot;, &quot;download_domain&quot;: &quot;172.20.8.31:28088&quot;, 修改完后需要重启服务 $ ./control restart fileserver stoped... fileserver started..., pid=21038 测试文件上传 $ curl -F file=@test.jpeg http://172.20.8.31:28088/upload http://172.20.8.31:28088/group1/default/20190604/16/22/6/7d6ef01d71af04dc61cb388955478121.jpeg# 加入系统服务新建文件gofastdfs vi /etc/rc.d/init.d/gofastdfs 文件内容为 #!/bin/sh # chkconfig: 2345 80 90 # # Simple go-fastdfs init.d script conceived to work on Linux systems # as it does use of the /proc filesystem. ### BEGIN INIT INFO # Provides: gofastdfs_28088 # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: go-fastdfs file server # Description: go-fastdfs file server. See https://github.com/sjqzhang/go-fastdfs ### END INIT INFO # WORKSPACE=$(cd $(dirname $0)/; pwd) WORKSPACE=/data1/webserver/gofastdfs/ cd $WORKSPACE mkdir -p log conf module= app=fileserver conf=conf/cfg.json pidfile=conf/app.pid logfile=log/app.log function check_pid() { if [ -f $pidfile ];then pid=`cat $pidfile` if [ -n $pid ]; then running=`ps -p $pid|grep -v &quot;PID TTY&quot; |wc -l` return $running fi fi return 0 } function start() { check_pid running=$? if [ $running -gt 0 ];then echo -n &quot;$app now is running already, pid=&quot; cat $pidfile return 1 fi nohup ./$app &amp;&gt; $logfile &amp; echo $! &gt; $pidfile echo &quot;$app started..., pid=$!&quot; } function stop() { pid=`cat $pidfile` kill $pid echo &quot;$app stoped...&quot; } function restart() { stop sleep 1 start } function status() { check_pid running=$? if [ $running -gt 0 ];then echo -n &quot;$app now is running, pid=&quot; cat $pidfile else echo &quot;$app is stoped&quot; fi } function tailf() { tail -f $logfile } function build() { go build if [ $? -ne 0 ]; then exit $? fi mv $module $app ./$app -v | grep -v &quot;config&quot; } function pack() { build git log -1 --pretty=%h &gt; gitversion version=`./$app -v|grep -v config` file_list=&quot;control cfg.example.json $app&quot; tar zcf $app-$version.tar.gz gitversion $file_list } function packbin() { build git log -1 --pretty=%h &gt; gitversion version=`./$app -v|grep -v config` tar zcvf $app-bin-$version.tar.gz $app gitversion } function help() { echo &quot;$0 start|stop|restart|status|tail&quot; } if [ &quot;$1&quot; == &quot;&quot; ]; then help elif [ &quot;$1&quot; == &quot;stop&quot; ];then stop elif [ &quot;$1&quot; == &quot;start&quot; ];then start elif [ &quot;$1&quot; == &quot;restart&quot; ];then restart elif [ &quot;$1&quot; == &quot;status&quot; ];then status elif [ &quot;$1&quot; == &quot;tail&quot; ];then tailf else help fi 修改文件权限 chmod 755 /etc/rc.d/init.d/gofastdfs 设置开机启动 chkconfig gofastdfs on 启动、停止、重启、查看状态等命令 service gofastdfs start/stop/restart/status/tail]]></content>
      <categories>
        <category>centos</category>
        <category>go-fastdfs</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>go-fastdfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 用户相关操作]]></title>
    <url>%2FCentOS-Users%2F</url>
    <content type="text"><![CDATA[Centos 用户相关操作 查看centos中的用户和用户组1、用户列表文件：/etc/passwd/ 2、用户组列表文件：/etc/group 3、查看系统中有哪些用户： cut -d : -f 1 /etc/passwd 4、查看可以登录系统的用户： cat /etc/passwd | grep -v /sbin/nologin | cut -d : -f 1 5、查看用户操作：w命令(需要root权限) 6、查看某一用户：w 用户名 7、查看登录用户：who 8、查看用户登录历史记录：last 9、修改root用户密码： passwd 10、root用户修改其他用户密码： passwd &lt;user_name&gt; 11、查看系统版本：cat /etc/redhat-release 12、删除用户 userdel 用户名 13、查看组 cat /etc/group 14、删除组 groupdel 组名]]></content>
      <tags>
        <tag>CentOS Linux Users</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装 Redis]]></title>
    <url>%2FCentOS-7-install-Redis%2F</url>
    <content type="text"><![CDATA[CentOS 7 安装Redis 参照官网描述（https://redis.io/download），linux下redis安装步骤如下： 所有工具和依赖一起安装 yum install -y tcl gcc-c++ $ wget http://download.redis.io/releases/redis-5.0.5.tar.gz $ tar -zxvf redis-5.0.5.tar.gz $ cd redis-5.0.5 $ mkdir -p /data1/databases/redis $ make &amp;&amp; make install PREFIX=/data1/databases/redis 上述流程依次代表，下载redis –&gt; 解压 –&gt; 进入解压目录 –&gt; 编译源码 多数情况下，执行make时，可能会出现如下错误： 异常一： make[2]: cc: Command not found 异常原因：没有安装gcc 解决方案：yum install gcc-c++ 异常二： zmalloc.h:51:31: error: jemalloc/jemalloc.h: No such file or directory 异常原因：一些编译依赖或原来编译遗留出现的问题 解决方案：make distclean。清理一下，然后再make。 在make成功以后，需要make test。在make test出现异常。 异常一： couldn&#39;t execute &quot;tclsh8.5&quot;: no such file or directory 异常原因：没有安装tcl 解决方案：yum install -y tcl。 到此，redis安装完成。 若是通过：make install PREFIX=安装目录， 完成安装的，会在安装目录下生成一个bin目录，bin目录下包含如下可执行文件： redis-benchmark ： 用于测试redis的性能。 redis-check-aof : 当aof备份文件被损坏，可通过该工具对aof文件进行修复，使用方式：redis-check-aof --fix 要修复的aof文件。 redis-check-rdb : 修复损坏的rdb备份文件。 redis-cli : redis客户端，用于连接服务端。 redis-server ： redis服务器端，用于启动redis服务器。 redis-sentinel : 哨兵模式（实际使用较多） 在master-slave模式下（slave默认不支持写），当master出现异常时，自动在slave中选择一台作为master。 连接上redis服务器后，可通过指令“info”查看redis服务器信息，也可查看服务器知道内容信息，例如：info replication 查看主从相关信息 下面介绍几个redis常用配置项（redis.cnf配置文件中配置）1、bind 127.0.0.1 配置redis服务器接受链接的网卡（非客户端ip，而是服务器端ip，服务器可能包含多个网卡） 2、protected-mode yes redis以保护模式运行，只接受本地链接，不能外网访问 3、port 6379 redis接受链接端口 4、daemonize no redis是否后台运行，若为yes，客户端窗口将被锁定重要配置项5、maxmemory redis最大使用内存6、maxmemory-policy 内存达到最大值时的驱逐策略 redis数据持久化支持两种模式：RDB和AOFRDB：rdb方式的持久化是通过快照完成的，当符合一定条件时redis会自动将内存中的所有数据执行快照操作并存储到硬盘上。默认存储在redis根目录的dump.rdb文件中。(文件名在配置文件中dbfilename) redis进行快照的时机（在配置文件redis.conf中） save 900 1：表示900秒内至少一个键被更改则进行快照。 save 300 10 save 60 10000 dbfilename dump.rdb 快照保存文件名 dir ./ 快照保存地址 也可通过redis客服端执行命令save或者bgsave保存快照： 两个命令的区别在于，save是由主进程进行快照操作，会阻塞其它请求。bgsave是由redis执行fork函数复制出一个子进程来进行快照操作。 文件修复：redis-check-dump rdb的优缺点 优点：由于存储的有数据快照文件，恢复数据很方便。 缺点：会丢失最后一次快照以后更改的所有数据。 AOF:aof方式的持久化是通过日志文件的方式，记录下redis服务器的每一条修改指令。默认情况下redis没有开启aof，可以通过参数appendonly参数开启。 appendonly yes aof文件的保存位置和rdb文件的位置相同，都是dir参数设置的，默认的文件名是appendonly.aof，可以通过 appendfilename参数修改 appendfilename appendonly.aof redis写命令同步的时机： appendfsync always 每次都会执行 appendfsync everysec 默认 每秒执行一次同步操作（推荐，默认） appendfsync no不主动进行同步，由操作系统来做，30秒一次 redis服务器启动时会读取appendonly.aof中的指令，进行执行，这样便保证了重启后数据不会丢失。 注意：当redis启动时，如果rdb持久化和aof持久化都打开了，那么程序会优先使用aof方式来恢复数据集，因为aof方式所保存的数据通常是最完整的。 最后记录下redis服务器的启动与关闭指令： [root@localhost src]# ./redis-server ../redis.conf 启动redis [root@localhost src]# ./redis-cli shutdown 关闭redis Redis 加入系统服务 新建文件 vi /etc/rc.d/init.d/redis 文件内容 #!/bin/sh # chkconfig: 2345 80 90 # # Simple Redis init.d script conceived to work on Linux systems # as it does use of the /proc filesystem. ### BEGIN INIT INFO # Provides: redis_6379 # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: Redis data structure server # Description: Redis data structure server. See https://redis.io ### END INIT INFO REDISPORT=6379 EXEC=/data1/databases/redis/bin/redis-server CLIEXEC=/data1/databases/redis/bin/redis-cli PIDFILE=/var/run/redis_${REDISPORT}.pid CONF=&quot;/etc/redis/${REDISPORT}.conf&quot; function check_pid() { if [ -f $PIDFILE ];then pid=`cat $PIDFILE` if [ -n $pid ]; then running=`ps -p $pid|grep -v &quot;PID TTY&quot; |wc -l` return $running fi fi return 0 } function start() { check_pid running=$? if [ $running -gt 0 ];then echo -n &quot;Redis server now is running, pid=&quot; cat $PIDFILE else echo &quot;Starting Redis server...&quot; $EXEC $CONF &amp; echo $! &gt; $PIDFILE echo &quot;Redis started..., pid=$!&quot; fi return 0 } function stop() { check_pid running=$? if [ $running -gt 0 ];then echo &quot;Stopping ...&quot; PID=$(cat $PIDFILE) $CLIEXEC -p $REDISPORT shutdown while [ -x /proc/${PID} ] do echo &quot;Waiting for Redis to shutdown ...&quot; sleep 1 done fi echo &quot;Redis stopped&quot; return 0 } function status() { check_pid running=$? if [ $running -gt 0 ];then echo -n &quot;Redis server now is running, pid=&quot; cat $PIDFILE else echo &quot;Redis server is stoped&quot; fi return 0 } case &quot;$1&quot; in start) start ;; stop) stop ;; status) status ;; restart) stop start ;; *) echo &quot;Please use start / stop / status / restart as first argument&quot; ;; esac 修改文件权限 chmod 755 /etc/rc.d/init.d/redis 设置开机启动 chkconfig redis on 启动、停止命令 service redis start/stop centos 7 加入系统服务 # cat /usr/lib/systemd/system/redis.service [Unit] Description=Redis persistent key-value database After=network.target After=network-online.target Wants=network-online.target [Service] ExecStart=/data/redis/bin/redis-server /etc/redis/6379.conf --supervised systemd #ExecStop=/usr/libexec/redis-shutdown ExecStop=kill -9 $(ps -ef|grep /data/redis/bin/redis-server | grep 6379 |awk &#39;{print $2}&#39;) Type=notify #User=redis #Group=redis RuntimeDirectory=redis RuntimeDirectoryMode=0755 [Install] WantedBy=multi-user.target 设置开机启动 systemctl enable redis 启动、停止、状态命令 systemctl start/stop/status redis]]></content>
      <categories>
        <category>centos</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装 Nginx]]></title>
    <url>%2FCentOS-7-install-Nginx%2F</url>
    <content type="text"><![CDATA[安装所需环境Nginx 是 C语言 开发，建议在 Linux 上运行，当然，也可以安装 Windows 版本，本篇则使用 CentOS 7 作为安装环境。 一. gcc 安装安装 nginx 需要先将官网下载的源码进行编译，编译依赖 gcc 环境，如果没有 gcc 环境，则需要安装： yum install gcc-c++ 二. PCRE pcre-devel 安装PCRE(Perl Compatible Regular Expressions) 是一个Perl库，包括 perl 兼容的正则表达式库。nginx 的 http 模块使用 pcre 来解析正则表达式，所以需要在 linux 上安装 pcre 库，pcre-devel 是使用 pcre 开发的一个二次开发库。nginx也需要此库。命令： yum install -y pcre pcre-devel 三. zlib 安装zlib 库提供了很多种压缩和解压缩的方式， nginx 使用 zlib 对 http 包的内容进行 gzip ，所以需要在 Centos 上安装 zlib 库。 yum install -y zlib zlib-devel 四. OpenSSL 安装OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及 SSL 协议，并提供丰富的应用程序供测试或其它目的使用。nginx 不仅支持 http 协议，还支持 https（即在ssl协议上传输http），所以需要在 Centos 安装 OpenSSL 库。 yum install -y openssl openssl-devel 所有工具和依赖一起安装 yum install -y openssl openssl-devel zlib zlib-devel pcre pcre-devel gcc-c++ 官网下载 直接下载.tar.gz安装包，地址：https://nginx.org/en/download.html 使用wget命令下载（推荐）。确保系统已经安装了wget，如果没有安装，执行 yum install wget 安装。 wget -c https://nginx.org/download/nginx-1.15.12.tar.gz 我下载的是1.12.0版本，这个是目前的稳定版。 解压依然是直接命令： tar -zxvf nginx-1.15.12.tar.gz cd nginx-1.15.12 配置其实在 nginx-1.15.12 版本中你就不需要去配置相关东西，默认就可以了。当然，如果你要自己配置目录也是可以的。 使用默认配置 ./configure 自定义配置（不推荐） ./configure \ --prefix=/usr/local/nginx \ --conf-path=/usr/local/nginx/conf/nginx.conf \ --pid-path=/usr/local/nginx/conf/nginx.pid \ --lock-path=/var/lock/nginx.lock \ --error-log-path=/var/log/nginx/error.log \ --http-log-path=/var/log/nginx/access.log \ --with-http_gzip_static_module \ --with-http_ssl_module \ --with-stream \ --http-client-body-temp-path=/var/temp/nginx/client \ --http-proxy-temp-path=/var/temp/nginx/proxy \ --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \ --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \ --http-scgi-temp-path=/var/temp/nginx/scgi 注：将临时文件目录指定为/var/temp/nginx，需要在/var下创建temp及nginx目录 编译安装make make install 查找安装路径： whereis nginx 启动、停止nginxcd /usr/local/nginx/sbin/ ./nginx ./nginx -s stop ./nginx -s quit ./nginx -s reload 启动时报80端口被占用: nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use) 解决办法，查看占用端口的进程 ➜ ~ lsof -i:80 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME nginx 4214 root 6u IPv4 46826 0t0 TCP *:http (LISTEN) nginx 4216 root 6u IPv4 46826 0t0 TCP *:http (LISTEN) ➜ ~ ps -ef|grep nginx root 4214 1 0 4月27 ? 00:00:00 nginx: master process /usr/bin/nginx root 4216 4214 0 4月27 ? 00:00:00 nginx: worker process root 122099 121530 0 22:06 pts/0 00:00:00 grep --color=auto --exclude-dir=.bzr --exclude-dir=CVS --exclude-dir=.git --exclude-dir=.hg --exclude-dir=.svn nginx ➜ ~ ./nginx -s quit:此方式停止步骤是待nginx进程处理任务完毕进行停止。./nginx -s stop:此方式相当于先查出nginx进程id再使用kill命令强制杀掉进程。 查询nginx进程： ps aux|grep nginx 重启 nginx1.先停止再启动（推荐）：对 nginx 进行重启相当于先停止再启动，即先执行停止命令再执行启动命令。如下： ./nginx -s quit ./nginx 2.重新加载配置文件：当 ngin x的配置文件 nginx.conf 修改后，要想让配置生效需要重启 nginx，使用-s reload不用先停止 ngin x再启动 nginx 即可将配置信息在 nginx 中生效，如下： ./nginx -s reload 启动成功后，在浏览器可以打开页面了 开机自启动即在rc.local增加启动代码就可以了。 vi /etc/rc.local 增加一行 /usr/local/nginx/sbin/nginx设置执行权限： chmod 755 rc.local 到这里，nginx就安装完毕了，启动、停止、重启操作也都完成了，当然，你也可以添加为系统服务。 添加系统服务Centos 6 添加系统服务nginx源码安装完成后默认不会注册为系统服务，所以需要手工添加系统服务脚本。在/etc/init.d目录下新建nginx文件，并更改权限其即可。 新建nginx文件vim /etc/init.d/nginx 填写以下内容(根据自己的实际目录修改): # !/bin/bash # nginx Startup script for the Nginx HTTP Server # this script create it by caffreyxin at 2007.10.15. # it is v.0.0.1 version. # if you find any errors on this scripts, please contact caffreyxin. # and send mail to xinyflove at sina dot com. # # chkconfig: - 85 15 # description: Nginx is a high-performance web and proxy server. # It has a lot of features, but it&#39;s not for everyone. # processname: nginx # pidfile: /usr/local/nginx/logs/nginx.pid # config: /usr/local/nginx/conf/nginx.conf nginxd=/usr/local/nginx/sbin/nginx nginx_config=/usr/local/nginx/conf/nginx.conf nginx_pid=/usr/local/nginx/logs/nginx.pid RETVAL=0 prog=&quot;nginx&quot; # Source function library. . /etc/rc.d/init.d/functions # Source networking configuration. . /etc/sysconfig/network # Check that networking is up. [ ${NETWORKING} = &quot;no&quot; ] &amp;&amp; exit 0 [ -x $nginxd ] || exit 0 # Start nginx daemons functions. start() { if [ -e $nginx_pid ];then echo &quot;nginx already running....&quot; exit 1 fi echo -n $&quot;Starting $prog: &quot; daemon $nginxd -c ${nginx_config} RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; touch /var/lock/subsys/nginx return $RETVAL } # Stop nginx daemons functions. stop() { echo -n $&quot;Stopping $prog: &quot; killproc $nginxd RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; rm -f /var/lock/subsys/nginx /var/run/nginx.pid } # reload nginx service functions. reload() { echo -n $&quot;Reloading $prog: &quot; #kill -HUP `cat ${nginx_pid}` killproc $nginxd -HUP RETVAL=$? echo } # See how we were called. case &quot;$1&quot; in start) start ;; stop) stop ;; reload) reload ;; restart) stop start ;; status) status $prog RETVAL=$? ;; *) echo $&quot;Usage: $prog {start|stop|restart|reload|status|help}&quot; exit 1 esac exit $RETVAL 或https://github.com/xinyflove/MyDocument/blob/master/Nginx/nginxtip:根据自己实际安装目录，修改这两行: nginxd=/usr/local/nginx/sbin/nginx nginx_config=/usr/local/nginx/conf/nginx.conf 修改文件权限chmod 755 /etc/init.d/nginx 设置开机启动chkconfig nginx on 查看开机启动的服务chkconfig --list 命令启动服务：service nginx start 停止服务：service nginx stop 重启服务：service nginx reload CentOS 7 添加系统服务 新建 nginx.server文件 vi /usr/lib/systemd/system/nginx.service 填写以下内容 #nginx服务配置到该文件中 # cat /usr/lib/systemd/system/nginx.service #服务描述性的配置 [Unit] Description=nginx - high performance web server Documentation=http://nginx.org/en/docs/ After=network.target remote-fs.target nss-lookup.target #服务关键配置 [Service] Type=forking #pid文件位置 #要与nginx配置文件中的pid配置路径一致，这个很重要，否则会服务启动失败 PIDFile=/usr/local/nginx/logs/nginx.pid #启动前检测 nginx配置文件 是否正确 ExecStartPre=/usr/local/nginx/sbin/nginx -t -c /usr/local/nginx/conf/nginx.conf #启动 ExecStart=/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf #重启 ExecReload=/bin/kill -s HUP $MAINPID #关闭 ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.target 启动nginx服务 systemctl start nginx.service 设置开机自启动 systemctl enable nginx.service 停止开机自启动 systemctl disable nginx.service 查看服务当前状态 systemctl status nginx.service 重新启动服务 systemctl restart nginx.service 查看所有已启动的服务 systemctl list-units --type=service 如下出现Failed to execute operation: Access denied无权限错误，则需关闭selinux，操作如下： # vi /etc/sysconfig/selinux … SELINUX=disabled … # setenforce 0 # getenforce Permissive 新旧系统服务命令对比 任务 旧指令 新指令 使某服务自动启动 chkconfig –level 3 nignx on systemctl enable nignx.service 使某服务不自动启动 chkconfig –level 3 nignx off systemctl disable nignx.service 检查服务状态 service nignx status systemctl status nignx.service （服务详细信息） systemctl is-active nignx.service （仅显示是否 Active) 显示所有已启动的服务 chkconfig –list systemctl list-units –type=service 启动某服务 service nignx start systemctl start nignx.service 停止某服务 service nignx stop systemctl stop nignx.service 重启某服务 service nignx restart systemctl restart nignx.service]]></content>
      <categories>
        <category>centos</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装 MySQL 5.7]]></title>
    <url>%2FCentOS-7-install-MySQL-5-7%2F</url>
    <content type="text"><![CDATA[CentOS 7 安装MySQL5.7 一、安装包下载下载地址：https://dev.mysql.com/downloads/mysql/5.6.html#downloads 国内可以使用163镜像加速下载：http://mirrors.163.com/mysql/Downloads/MySQL-5.7/ 选择相应的平台和版本下载 二、安装1.将下载好的安装到解压到/usr/local目录下tar -zxvf mysql-5.7.26-linux-glibc2.12-x86_64.tar.gz -C /usr/local/ 2.进入/usr/local目录cd /usr/local/ 3.为mysql安装目录创建软链接ln -s mysql-5.7.26-linux-glibc2.12-x86_64 mysql 4.为centos添加mysql用户组和mysql用户(-s /bin/false参数指定mysql用户仅拥有所有权，而没有登录权限)groupadd mysql useradd -r -g mysql -s /bin/false mysql 5.进入安装mysql软件的目录，命令如下cd /usr/local/mysql 6.修改当前目录拥有者为新建的mysql用户，命令如下：chown -R mysql:mysql ./ 7.安装mysql，命令如下：./bin/mysqld --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data --initialize 可能会出现如下错误 ./bin/mysqld: error while loading shared libraries: libaio.so.1: cannot open shared object file: No such file or directory 解决方法 yum install -y libaio Loaded plugins: fastestmirror Determining fastest mirrors base | 3.6 kB 00:00:00 epel | 5.3 kB 00:00:00 extras | 3.4 kB 00:00:00 updates | 3.4 kB 00:00:00 (1/4): epel/x86_64/updateinfo | 977 kB 00:00:00 (2/4): extras/7/x86_64/primary_db | 200 kB 00:00:00 (3/4): updates/7/x86_64/primary_db | 5.7 MB 00:00:00 (4/4): epel/x86_64/primary_db | 6.7 MB 00:00:00 Resolving Dependencies --&gt; Running transaction check ---&gt; Package libaio.x86_64 0:0.3.109-13.el7 will be installed --&gt; Finished Dependency Resolution Dependencies Resolved ======================================================================================================================================================================================= Package Arch Version Repository Size ======================================================================================================================================================================================= Installing: libaio x86_64 0.3.109-13.el7 base 24 k Transaction Summary ======================================================================================================================================================================================= Install 1 Package Total download size: 24 k Installed size: 38 k Downloading packages: libaio-0.3.109-13.el7.x86_64.rpm | 24 kB 00:00:00 Running transaction check Running transaction test Transaction test succeeded Running transaction Installing : libaio-0.3.109-13.el7.x86_64 1/1 Verifying : libaio-0.3.109-13.el7.x86_64 1/1 Installed: libaio.x86_64 0:0.3.109-13.el7 Complete! 如果出现如下所示则为安装成功 2019-05-20T14:14:00.607305Z 0 [Warning] InnoDB: New log files created, LSN=45790 2019-05-20T14:14:00.643051Z 0 [Warning] InnoDB: Creating foreign key constraint system tables. 2019-05-20T14:14:00.833733Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: 83d6fb34-7b09-11e9-96b7-000c2932f18d. 2019-05-20T14:14:00.892413Z 0 [Warning] Gtid table is not ready to be used. Table &#39;mysql.gtid_executed&#39; cannot be opened. 2019-05-20T14:14:00.893234Z 1 [Note] A temporary password is generated for root@localhost: sBN18?Wq&amp;&gt;&gt;I 2019-05-20T14:14:01.309353Z 1 [Warning] &#39;user&#39; entry &#39;root@localhost&#39; ignored in --skip-name-resolve mode. 2019-05-20T14:14:01.309376Z 1 [Warning] &#39;user&#39; entry &#39;mysql.session@localhost&#39; ignored in --skip-name-resolve mode. 2019-05-20T14:14:01.309382Z 1 [Warning] &#39;user&#39; entry &#39;mysql.sys@localhost&#39; ignored in --skip-name-resolve mode. 2019-05-20T14:14:01.309392Z 1 [Warning] &#39;db&#39; entry &#39;performance_schema mysql.session@localhost&#39; ignored in --skip-name-resolve mode. 2019-05-20T14:14:01.309395Z 1 [Warning] &#39;db&#39; entry &#39;sys mysql.sys@localhost&#39; ignored in --skip-name-resolve mode. 2019-05-20T14:14:01.309400Z 1 [Warning] &#39;proxies_priv&#39; entry &#39;@ root@localhost&#39; ignored in --skip-name-resolve mode. 2019-05-20T14:14:01.309416Z 1 [Warning] &#39;tables_priv&#39; entry &#39;user mysql.session@localhost&#39; ignored in --skip-name-resolve mode. 2019-05-20T14:14:01.309420Z 1 [Warning] &#39;tables_priv&#39; entry &#39;sys_config mysql.sys@localhost&#39; ignored in --skip-name-resolve mode. 其实已经生成了root的临时账号： A temporary password is generated for root@localhost: sBN18?Wq&amp;&gt;&gt;I 8.开启mysql服务，命令如下：./support-files/mysql.server start 如果出现文件不存在错误，则说明mysql配置文件/etc/my.cnf中的路径不对，修改内容如下，datadir和socket都修改成mysql的安装目录下，增加[client]板块，用于命令行连接mysql数据库。 #在etc下新建配置文件my.cnf，并在该文件内添加以下配置 [mysql] # 设置mysql客户端默认字符集 default-character-set=utf8mb4 [mysqld] skip-name-resolve #skip-grant-tables #设置3306端口 port = 3306 # 设置mysql的安装目录 basedir=/usr/local/mysql # 设置mysql数据库的数据的存放目录 datadir=/usr/local/mysql/data # 允许最大连接数 max_connections=200 # 设置忽略大小写 lower_case_table_names = 1 # 服务端使用的字符集默认为8比特编码的latin1字符集 # 指定编码 character-set-client-handshake=FALSE character-set-server=utf8mb4 collation-server=utf8mb4_unicode_ci init_connect=&#39;SET NAMES utf8mb4&#39; # 开启ip绑定 bind-address = 0.0.0.0 # 创建新表时将使用的默认存储引擎 default-storage-engine=INNODB lower_case_table_names=1 max_allowed_packet=16M [mysqld_safe] log-error=/var/log/mysql/mysqld.log pid-file=/var/run/mysql/mysqld.pid #指定客户端连接mysql时的编码设置 [client] default-character-set=utf8mb4 创建相应目录并赋权 mkdir -p /var/log/mysql/ chown -R mysql:mysql /var/log/mysql mkdir -p /var/run/mysql chown -R mysql:mysql /var/run/mysql 9.重新启开启mysql服务，如下所示则开启成功！./support-files/mysql.server start Starting MySQL.. SUCCESS! 10.将mysql进程放入系统进程中，命令如下：cp support-files/mysql.server /etc/init.d/mysqld 11.重新启动mysql服务，命令如下：service mysqld restart Shutting down MySQL.... SUCCESS! Starting MySQL. SUCCESS! 修改文件权限 chmod 755 /etc/rc.d/init.d/mysqld 设置开机启动 chkconfig mysqld on 启动、停止命令 service mysqld start/stop 12.配置mysql环境变量vi /etc/profile export PATH=$PATH:/usr/local/mysql/bin 保存退出，再编译下： source /etc/profile 13.使用随机密码登录mysql数据库，命令如下：mysql -u root -p 输入密码回车可能出现如下错误 mysql -uroot -p Enter password: ERROR 2002 (HY000): Can&#39;t connect to local MySQL server through socket &#39;/usr/local/mysql/mysql.sock&#39; (2) 查看是否系统自带的mariadb rpm -qa|grep mariadb mariadb-libs-5.5.60-1.el7_5.x86_64 卸载系统自带的mariadb yum remove mariadb-libs-5.5.60-1.el7_5.x86_64 可能出现如下错误 mysql -uroot -p mysql: error while loading shared libraries: libncurses.so.5: cannot open shared object file: No such file or directory 安装相关依赖 yum install libncurses.so.5 Last metadata expiration check: 0:11:30 ago on Tue 07 Jan 2020 07:57:07 AM CST. Dependencies resolved. =================================================================================================================================================================================================================== Package Arch Version Repository Size =================================================================================================================================================================================================================== Installing: ncurses-compat-libs i686 6.1-7.20180224.el8 BaseOS 350 k Installing dependencies: glibc32 x86_64 2.28-42.1.el8 AppStream 1.5 M libgcc i686 8.2.1-3.5.el8 BaseOS 84 k libstdc++ i686 8.2.1-3.5.el8 BaseOS 485 k Transaction Summary =================================================================================================================================================================================================================== Install 4 Packages Total download size: 2.4 M Installed size: 8.3 M Is this ok [y/N]: y Downloading Packages: (1/4): libgcc-8.2.1-3.5.el8.i686.rpm 72 kB/s | 84 kB 00:01 (2/4): glibc32-2.28-42.1.el8.x86_64.rpm 596 kB/s | 1.5 MB 00:02 (3/4): libstdc++-8.2.1-3.5.el8.i686.rpm 180 kB/s | 485 kB 00:02 (4/4): ncurses-compat-libs-6.1-7.20180224.el8.i686.rpm 227 kB/s | 350 kB 00:01 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Total 510 kB/s | 2.4 MB 00:04 Running transaction check Transaction check succeeded. Running transaction test Transaction test succeeded. Running transaction Preparing : 1/1 Installing : libgcc-8.2.1-3.5.el8.i686 1/4 Running scriptlet: libgcc-8.2.1-3.5.el8.i686 1/4 Installing : glibc32-2.28-42.1.el8.x86_64 2/4 Running scriptlet: glibc32-2.28-42.1.el8.x86_64 2/4 Installing : libstdc++-8.2.1-3.5.el8.i686 3/4 Running scriptlet: libstdc++-8.2.1-3.5.el8.i686 3/4 Installing : ncurses-compat-libs-6.1-7.20180224.el8.i686 4/4 Running scriptlet: ncurses-compat-libs-6.1-7.20180224.el8.i686 4/4 Verifying : glibc32-2.28-42.1.el8.x86_64 1/4 Verifying : libgcc-8.2.1-3.5.el8.i686 2/4 Verifying : libstdc++-8.2.1-3.5.el8.i686 3/4 Verifying : ncurses-compat-libs-6.1-7.20180224.el8.i686 4/4 Installed: ncurses-compat-libs-6.1-7.20180224.el8.i686 glibc32-2.28-42.1.el8.x86_64 libgcc-8.2.1-3.5.el8.i686 libstdc++-8.2.1-3.5.el8.i686 Complete! 如果是 CentOS 8 还需要执行以下脚本 ln -s /usr/lib64/libncurses.so.6 /usr/lib64/libncurses.so.5 ln -s /usr/lib64/libtinfo.so.6 /usr/lib64/libtinfo.so.5 输入随机密码登录成功： Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 2010 Server version: 5.7.26 MySQL Community Server (GPL) Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement. mysql&gt; 14.进入mysql操作行，为root用户设置新密码（比如设为123456）：在13条已经登录的终端中输入如下命令： alter user &#39;root&#39;@&#39;localhost&#39; identified by &#39;123456&#39;; # 或者 use mysql update user set authentication_string=password(&#39;新密码&#39;) where user=&#39;root&#39;; 15.设置允许远程连接数据库，命令如下：先选择数据库： use mysql update user set user.Host=&#39;%&#39; where user.User=&#39;root&#39;; 查看修改后的值： select user,host from user; 16.刷新权限，命令如下：flush privileges; 17、开启3306防火墙端口，然后即可远程连接mysql（因为我的防火墙是全部关闭，所以省略了这步）18、如果还是无法远程连接，查看/etc/my.cnf找到bind-address = 127.0.0.1这一行 改为bind-address = 0.0.0.0即可 19、添加新的用户并授权CREATE USER &#39;developer&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39;; grant all privileges on *.* to &#39;developer&#39;@&#39;%&#39; ; -- grant all privileges on *.* to &#39;developer&#39;@&#39;%&#39; identified by &#39;123456&#39;; GRANT Grant Option ON *.* TO &#39;developer&#39;@&#39;%&#39;; flush privileges;]]></content>
      <categories>
        <category>centos</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql配置主从复制]]></title>
    <url>%2FMysql-Master-Slave%2F</url>
    <content type="text"><![CDATA[一、概述Mysql Replication（复制） 即 主从同步（Master/Slave）： 主要用于数据库的备份，负载均衡，读写分离等。 1、数据复制技术有以下一些特点：(1) 数据分布(2) 负载平衡(load balancing)，读写分离，主写从读(3) 备份(4) 高可用性(high availability)和容错 2、复制如何工作从高层来看，复制分成三步：(1) master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）；(2) slave将master的binary log events拷贝到它的中继日志(relay log)；(3) slave重做中继日志中的事件，将改变反映它自己的数据。 二、数据备份还原在做主从同步之前首先需要对主库进行数据备份，恢复到所有的从数据库，数据库备份有冷备和热备，冷备即拷贝所有的数据文件及日志文件到从服务器， 这里使用mysqldump工具做在线热备 步骤:（这里需要备份的数据库为 db_test） 1、Master锁定库，使只能读取不能写入mysql &gt; flush tables with read lock; 2、Master导出备份~$ mysqldump –master-data -uroot -p db_test&gt;db_test.sql 说明：–master-data参数在生成的dump 文件中产生一条 CHANGE MASTER TO 命令，查看可知master当前使用的binlog文件名 3、Slave导入备份~$ mysql -uroot -p db_test&lt;db_test.sql 4、最后配置好同步以后，Master解除写锁定mysql &gt; unlock tables; 三、配置参考1、网络配置1主1从，主从数据库处于同一装有CentOS机器上，使用docker运行，可互相访问。 主数据库master端口：3311 从数据库slave1端口：3312 2、master配置3311.cnf文件mysqld段： [mysqld]server-id=1log-bin=mysql-bin说明：必需配置，server-id指定服务器唯一id，不可重复，log-bin开启binlog日志 运行master docker run --name mysql3311 -v $(PWD)/3311.cnf:/etc/mysql/conf.d/my.cnf -p 3311:3306 -e MYSQL_ROOT_PASSWORD=123456 -tid mysql:5.6 通过mysql客户端连胜主库，设置复制账号： GRANT REPLICATION SLAVE ON *.* TO &#39;test&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39;; FLUSH PRIVILEGES; show master status; 说明：添加一个 test 账号在任何机器上使用 123456 这个密码对任何数据库行使 replication slave 权限 查看Master状态： mysql &gt; show master status; mysql&gt; show master status;+——————+———-+————–+——————+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+——————+———-+————–+——————+| mysql-bin.000022 | 389 | | |+——————+———-+————–+——————+ 3、Slave配置3312.cnf文件配置: [mysqld]server-id=2log-bin=mysql-bin 运行slave docker run --name mysql3312 -v $(PWD)/3312.cnf:/etc/mysql/conf.d/my.cnf -p 3312:3306 -e MYSQL_ROOT_PASSWORD=123456 -tid mysql:5.6 使用mysql客户端连上从库，设置主从复制 stop slave; CHANGE MASTER TO MASTER_HOST = &#39;172.20.8.113&#39;, MASTER_USER = &#39;test&#39;, MASTER_PASSWORD = &#39;123456&#39;, MASTER_PORT = 3311, MASTER_RETRY_COUNT = 0, MASTER_LOG_POS = 389; START SLAVE; SHOW SLAVE STATUS ; 核对host、user、master_log_file是否正确，Slave_IO_Running: YesSlave_SQL_Running: Yes这两项yes，说明配置成功。 最后别忘了，Master解除写锁定： mysql &gt; unlock tables; 注意：如果Master的mysql服务重启会生成新的bin log日志，这时候，Slave也需要重启一下服务或者stop slave - start slave， 如果slave服务不重启，则可以修改 mysql - replication -slave 自动生成的配置文件：/var/lib/mysql/master.info 18mysql-bin.000022398172.20.8.113test123456331160查看第二行 mysq-bin文件名是否跟Master上对应，如果不对应可直接修改； 四、常见错误1、master发生故障，经修复后启动后，slave无法与master同步报错：Got fatal error 1236 from master when reading data from binary log 原因：master重启后，mysql的binlog会重新生成，相应的记录位置会改变 解决方法： -master： mysql &gt; flush logs; mysql &gt; show master status; 记录下File和Position值 -slave： mysql &gt; stop slave; mysql &gt; CHANGE MASTER TO MASTER_LOG_FILE=’mysql-bin.000049’,MASTER_LOG_POS=1359; mysql &gt; start slave; mysql &gt; show slave status\G; 2、slave发生故障，设置正确，但是无法初始化报错：ERROR 1201 (HY000): Could not initialize master 解决方法： -master： mysql &gt; flush logs; mysql &gt; show master status; 记录下File和Position值 -slave： mysql &gt; reset slave; mysql &gt; CHANGE MASTER TO MASTER_HOST = ‘172.20.8.113’, MASTER_USER = ‘test’, MASTER_PASSWORD = ‘123456’, MASTER_PORT = 3311, MASTER_RETRY_COUNT = 0, MASTER_LOG_POS = 389; mysql &gt; start slave; mysql &gt; show slave status\G;]]></content>
      <categories>
        <category>myql</category>
        <category>master</category>
        <category>slave</category>
      </categories>
      <tags>
        <tag>myql</tag>
        <tag>master</tag>
        <tag>slave</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决NVIDIA驱动程序安装和加载问题]]></title>
    <url>%2FHackintosh-Nvidia-Driver%2F</url>
    <content type="text"><![CDATA[问题6：您在菜单栏或Nvidia驱动程序管理器首选项面板中选择了Nvidia Web Drivers，但是当您选择时重启OS X默认图形驱动程序已选中。 当您的主板没有本机NVRAM支持（例如技嘉100系列主板）时会导致这种情况。 修复： 设置模拟NVRAM以在boot-args中存储nvda_drv = 1引导标志。 在 此处 下载最新的Clover安装程序pkg ，启动安装程序并在此处选择自定义： 之后确保您选择了EmuVariableUefi-64： 继续完成Clover升级安装并重新启动。重新启动后打开系统首选项并转到Nvidia驱动程序管理器。确保您拥有最新的驱动程序是个好主意，因此请转到更新选项卡并单击立即检查按钮。如果有更新，请执行更新并在它告诉您时重新启动。你应该在这一点上完成。如果没有更新，请继续执行下一步。 如果没有升级，请单击“图形驱动程序”选项卡，然后选择NVIDIA Web Drive旁边的单选按钮。重启。 重新启动后，应该说您使用的是NVIDIA网络驱动程序。如果它仍然不起作用，那么您可能需要重新运行Clover安装程序并选择“在目标卷上安装RC脚本”。 -————————— 如果您遇到任何其他错误，请告知我们，我将使用解决方案更新此帖子。 nvidia显卡驱动 https://www.tonymacx86.com/nvidia-drivers/https://www.tonymacx86.com/threads/nvidia-releases-alternate-graphics-drivers-for-macos-sierra-10-12-6-378-05-05-25.227494/ 解决NVIDIA驱动程序安装和加载问题 https://www.tonymacx86.com/threads/solving-nvidia-driver-install-loading-problems.161256/]]></content>
      <categories>
        <category>Mac osx</category>
        <category>Hackintosh</category>
        <category>Nvidia</category>
      </categories>
      <tags>
        <tag>Mac osx</tag>
        <tag>Hackintosh</tag>
        <tag>Nvidia</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[黑苹果]]></title>
    <url>%2FHackintosh%2F</url>
    <content type="text"><![CDATA[写在开头 什么是黑苹果？ 自从苹果采用Intel的处理器，OSX被黑客破解后可以安装在Intel CPU与部分AMDCPU的机器上。从而出现了一大批非苹果设备而使用苹果操作系统的机器，被称为黑苹果(Hackintosh)；在Mac苹果机上面安装原版Mac系统的被称为白苹果（Macintosh），与黑苹果相对。 MAC系统 OS X 是全球领先的操作系统。基于坚如磐石的 UNIX ，设计简单直观，让处处充满创新的Mac 安全易用，高度兼容，出类拔萃。UNIX 之威力，iMac 之简单让Mac OS X 既简单易用且功能强大。所有的一切 - 从启动 Mac 后所看到的桌面，到你日常使用的应用程序，都设计得简约精致。无论是浏览网页、查看邮件和与外地朋友视频聊天，所有事情都简单高效、趣味盎然。当然，简化复杂任务要求尖端科技，而 Mac OS X 正拥有这些尖端科技。它不仅使用基础坚实、久经考验的 UNIX 系统提供空前的稳定性，还提供超强性能、超炫图形并支持互联网标准。 参考资料：High Sierra 以及 Mojave 镜像集合贴 http://bbs.pcbeta.com/viewthread-1753062-1-1.html High Sierra 和 Mojave 镜像大全 https://blog.iamzhl.top/High-Sierra-and-Mojave-Images-update.html 笔记本黑果安装向导 http://bbs.pcbeta.com/viewthread-1779539-1-7.html UEFI+GPT+Clover macOS原版单、双系统双版教程(正式版) https://alansachin.github.io/2017/05/07/UEFI+GPT+Clover-macOS%E5%8E%9F%E7%89%88%E5%8D%95-%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%8F%8C%E7%89%88%E6%95%99%E7%A8%8B(%E6%AD%A3%E5%BC%8F%E7%89%88) 黑苹果安装 https://mp.weixin.qq.com/s/oYIrNOy8Co-SbKTPlGOlLw 增强型 macOS 维护系统https://pe.firewolf.app/cn/ 黑苹果EFI https://zhih.me/hackintosh clover-configurator https://mackie100projects.altervista.org/download-clover-configurator/ 7700hq 微星GS63VR 安装10.12，除声卡外基本完美 http://bbs.pcbeta.com/forum.php?mod=viewthread&amp;tid=1736121&amp;highlight=gs63 黑果小兵的部落阁 https://blog.daliansky.net/ 黑苹果安装从0开始—-clover优盘引导改硬盘引导篇 http://bbs.pcbeta.com/viewthread-1683571-1-1.html Mac High Sierra外接显示器设置（解决字体模糊问题，开启high dpi） https://yanke.info/?id=74 一键开启MacOS HiDPI https://zhih.me/one-key-hidpi/ mac 10.14 Mojave 外接屏幕字体发虚 https://www.cnblogs.com/mooniitt/p/9753112.html nvidia显卡驱动 https://www.tonymacx86.com/nvidia-drivers/https://www.tonymacx86.com/threads/nvidia-releases-alternate-graphics-drivers-for-macos-sierra-10-12-6-378-05-05-25.227494/ 黑苹果从sierra升级到high sierra https://www.tonymacx86.com/threads/update-directly-to-macos-high-sierra.232707/ Broadcom BCM94352z/DW1560驱动新姿势[新方法] https://blog.daliansky.net/Broadcom-BCM94352z-DW1560-drive-new-posture.html]]></content>
      <categories>
        <category>Mac osx</category>
        <category>Hackintosh</category>
      </categories>
      <tags>
        <tag>Mac osx</tag>
        <tag>Hackintosh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iOS越狱]]></title>
    <url>%2FiOS-Jailbreaking%2F</url>
    <content type="text"><![CDATA[写在开头 什么是iOS越狱？ iOS越狱（英语：iOS Jailbreaking）是获取iOS设备的Root权限的技术手段。iOS系统的Root用户对除Apple特定私有进程之外的其他进程不开放，使用Root用户运行的进程在进程树中的PID为0。程序员在iOS中挖掘出一些可以将进程提权至PID0的漏洞（例如Task For PID0）。利用Root用户运行的进程意味着可以任意读取设备其中的APFS分区表和内核缓存地址，拥有一个用户可以随意控制的PID0进程还不能称之为一个完整的越狱。之后还需要利用Bypass（旁路）手段绕过Apple在iOS系统中设置的其他安全防护措施，将APFS或HFS+文件系统中的ROOTFS分区重新挂载（Remount）为可读写（R/W），从而达到添加二进制文件和守护进程的目的。通常大众用户认为能够正常使用Cydia才能被称为越狱，但其实这种说法是不正确的。但通过此软件可以完成越狱前不可能进行的动作，例如安装App Store以外未经过签名的应用、修改SpringBoard、运行Shell程序、使有运营商锁的设备利用卡贴解锁后通过替换配置文件形式实现本地化（例如“去除+86”，解锁FaceTime功能）。[1] 越狱软件分发商店Cydia的创始人Jay Freeman在2010年10月估计，全球大概有10%的iPhone曾进行过越狱[2]。 当一台iOS设备越狱之后，用户将能实践很多此前无能以得的各种功能，或是使用很多被Apple认为不安全的软件。比如：虚拟定位、修改iPhone的登录设备、翻越防火墙、修改设备界面字体和主题、快速转换自定义铃声、使用自己编程的软件或插件等。 越狱工具： 挂神团队越狱 https://app.nk8686.xin/ios/ electra越狱 https://coolstar.org/electra/ pp助手越狱 https://pro.25pp.com/ppghost 爱思越狱助手：https://www.i4.cn/ iOS9.2~iOS9.3.3越狱修复 http://jb92.i4.cn/]]></content>
      <categories>
        <category>ios</category>
        <category>Jailbreaking</category>
      </categories>
      <tags>
        <tag>ios</tag>
        <tag>Jailbreaking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Reactor模式的角色构成]]></title>
    <url>%2FReactor%2F</url>
    <content type="text"><![CDATA[Reactor模式的角色构成（Reactor模式一共有5种角色构成）：1. Handle（句柄或是描述符）：本质上表示一种资源，是由操作系统提供的；改资源用于表示一个个的事件，比如说文件描述符，或是针对网络编程过程中的Socket描述符。事件即可以来自于外部，可以来自于内部；外部事件比如说客户端的连接请求，客户端发送过来的数据等；内部事件，比如说操作系统产生的定时器事件等。它本质上就是一个文件描述符。 2. Synchronous Event Demultiplexer（同步事件分离器）：它本身是一个系统调用，用于等待事件的发生（事件可能是一个，也可能是多个）。调用方在调用它的时候会被阻塞，一直阻塞到同步事件分离器上有事件产生为止。对于Linux来说，同步事件分离器指的就是常用的I/O多路复用机制，比如说select、poll、epoll等。在Java NIO领域中，同步事件分离器对应的组件就是Slector；对应的阻塞方法就是select方法。 3. Event Handler（事件处理器）：本身由多个回调方法构成，这些方法构成了与应用相关的对于某个事件的反馈机制。Netty相比于Java NIO来说，在事件处理器这个角色上进行了一个升级，它为我们开发者提供了大量的回调方法，供我们在特定事件产生时实现相应的回调方法进行业务逻辑的处理。 4. Contrete Event Handler（具体事件处理器）：是事件处理器的实现。它本身实现了事件处理器所提供的各个回调方法，从而实现了特定于业务的逻辑。它本质上就是我们所编写的一个个的处理器实现。 5. Initiation Dispatcher（初始分发器）：实际上就是Reactor角色。它本身定义了一些规范，这些规范用于控制事件的调度方式，同时又提供了应用进行事件处理器的注册、删除等设施。它本身是整个事件处理器的核心所在，Initiation Dispatcher会通过同步事件分离器来等待事件的发生。一旦事件发生，Initiation Dispatcher首先会分离出每一个事件，然后调用事件处理器，最后调用相关的回调方法来处理这些事件。 Reactor模式流程 当应用向Initiation Dispatcher注册具体的事件处理器时，应用会标识出该事件处理器希望Initiation Dispatcher在某个事件发生时向其通知该事件，该事件与Handle关联。 Initiation Dispatcher会要求每个事件处理器向其传递内部的Handle。该Handler向操作系统标识了事件处理器。 当所有的事件处理器注册完毕后，应用会调用handle_events方法来启动Initiation Dispatcher的事件循环。这时，Initiation Dispatcher会将每个注册的事件管理的handle合并起来，并使用同步事件分离器等待这些事件的发生。比如说，TCP协议层会使用select同步事件分离器操作来等待客户端发送的数据到达连接的socket handle上。 当与某个事件源对应的Handle变为ready状态时（比如说，TCP socket变为等待读状态时），同步事件分离器就会通知Initiation Dispatcher。 Initiation Dispatcher会触发事件处理器的回调方法，从而响应这个处于ready状态的Handle。当事件发生时，Initiation Dispatcher会将被事件源激活的Handle[key]来寻找并分发恰当的事件处理器回调方法。 Initiation Dispatcher会回调事件处理器的handle_event回调方法来执行特定于应用的功能（开发者自己所编写的功能），从而响应这个事件。所发生的事件类型可以作为该方法参数并被该方法内部使用来执行额外的特定于服务的分类和分发。]]></content>
      <categories>
        <category>reactor</category>
        <category>nio</category>
        <category>netty</category>
      </categories>
      <tags>
        <tag>reactor</tag>
        <tag>nio</tag>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清除Kubernetes环境]]></title>
    <url>%2FClean-Kubernetes-Environment%2F</url>
    <content type="text"><![CDATA[在学习过程中可能有机器加入Kubernetes时设置出错，可以从Kubernetes集群中移除并清理，然后再重新加入 清理kubelet挂载的磁盘和设置df -h|grep kubelet |awk -F % &#39;{print $2}&#39;|xargs umount rm /var/lib/kubelet/* -rf 清理kubernetes设置rm /etc/kubernetes/* -rf 清理rancher设置rm /var/lib/rancher/* -rf 清理etc设置rm /var/lib/etcd/* -rf 清理cni设置rm /var/lib/cni/* -rf 清理iptable设置iptables -F &amp;&amp; iptables -t nat –F 清理flannel设置ip link del flannel.1 清理docker containerdocker ps -a|awk &#39;{print $1}&#39;|xargs docker rm -f 清理docker挂载的磁盘docker volume ls|awk &#39;{print $2}&#39;|xargs docker volume rm 合并在一起df -h|grep kubelet |awk -F % &#39;{print $2}&#39;|xargs umount rm /var/lib/kubelet/* -rf rm /etc/kubernetes/* -rf rm /var/lib/rancher/* -rf rm /var/lib/etcd/* -rf rm /var/lib/cni/* -rf iptables -F &amp;&amp; iptables -t nat –F ip link del flannel.1 docker ps -a|awk &#39;{print $1}&#39;|xargs docker rm -f docker volume ls|awk &#39;{print $2}&#39;|xargs docker volume rm]]></content>
      <categories>
        <category>kubernetes</category>
        <category>docker</category>
        <category>rancher</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>docker</tag>
        <tag>rancher</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 设置DNS服务器]]></title>
    <url>%2FCentOS-7-Seting-DNS-Server%2F</url>
    <content type="text"><![CDATA[CentOS 7需要使用全新的命令行工具 nmcli 来设置 显示当前网络连接[root@bogon ~]# nmcli connection show NAME UUID TYPE DEVICE cni0 b2b8f5f9-acd2-42fd-9ec9-a76282425cd9 bridge cni0 docker0 33ebd49e-fd1b-4a2c-8261-c0463f4f4146 bridge docker0 enp2s0 b6579214-0ba6-4bf0-9319-2e0e4f584afd ethernet enp2s0 virbr0 976717ae-c3ae-4582-aa09-039c26bef80d bridge virbr0 修改当前网络连接对应的DNS服务器，这里的网络连接可以用名称或者UUID来标识[root@bogon ~]# nmcli con mod enp2s0 ipv4.dns &quot;114.114.114.114 8.8.8.8&quot; [root@bogon ~]# 将dns配置生效[root@bogon ~]# nmcli con up enp2s0 Connection successfully activated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/7) 测试网络[root@bogon ~]# ping www.baidu.com PING www.a.shifen.com (14.215.177.39) 56(84) bytes of data. 64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=1 ttl=53 time=5.48 ms 64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=2 ttl=53 time=5.60 ms 64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=3 ttl=53 time=5.48 ms 64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=4 ttl=53 time=8.57 ms 64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=5 ttl=53 time=5.54 ms ^C --- www.a.shifen.com ping statistics --- 5 packets transmitted, 5 received, 0% packet loss, time 4005ms rtt min/avg/max/mdev = 5.485/6.138/8.575/1.222 ms [root@bogon ~]#]]></content>
      <categories>
        <category>centos</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mycat 按月分表]]></title>
    <url>%2Fmycat-single-database-log-table-part-by-month%2F</url>
    <content type="text"><![CDATA[什么是MYCAT• 一个彻底开源的，面向企业应用开发的大数据库集群• 支持事务、ACID、可以替代MySQL的加强版数据库• 一个可以视为MySQL集群的企业级数据库，用来替代昂贵的Oracle集群• 一个融合内存缓存技术、NoSQL技术、HDFS大数据的新型SQL Server• 结合传统数据库和新型分布式数据仓库的新一代企业级数据库产品• 一个新颖的数据库中间件产品 Mycat关键特性• 支持SQL92标准• 支持MySQL、Oracle、DB2、SQL Server、PostgreSQL等DB的常见SQL语法• 遵守Mysql原生协议，跨语言，跨平台，跨数据库的通用中间件代理。• 基于心跳的自动故障切换，支持读写分离，支持MySQL主从，以及galera cluster集群。• 支持Galera for MySQL集群，Percona Cluster或者MariaDB cluster• 基于Nio实现，有效管理线程，解决高并发问题。• 支持数据的多片自动路由与聚合，支持sum,count,max等常用的聚合函数,支持跨库分页。• 支持单库内部任意join，支持跨库2表join，甚至基于caltlet的多表join。• 支持通过全局表，ER关系的分片策略，实现了高效的多表join查询。• 支持多租户方案。• 支持分布式事务（弱xa）。• 支持XA分布式事务（1.6.5）。• 支持全局序列号，解决分布式下的主键生成问题。• 分片规则丰富，插件化开发，易于扩展。• 强大的web，命令行监控。• 支持前端作为MySQL通用代理，后端JDBC方式支持Oracle、DB2、SQL Server 、 mongodb 、巨杉。• 支持密码加密• 支持服务降级• 支持IP白名单• 支持SQL黑名单、sql注入攻击拦截• 支持prepare预编译指令（1.6）• 支持非堆内存(Direct Memory)聚合计算（1.6）• 支持PostgreSQL的native协议（1.6）• 支持mysql和oracle存储过程，out参数、多结果集返回（1.6）• 支持zookeeper协调主从切换、zk序列、配置zk化（1.6）• 支持库内分表（1.6）• 集群基于ZooKeeper管理，在线升级，扩容，智能优化，大数据处理（2.0开发版）。一、分表规则dm_log和dm_opendoor_record表每年数据量两千万左右，平均每个月两百万左右，mysql单表数据量达到800万时性能出现明显下降，此时需要考虑优化。优先方案考虑优化程序以及sql语句，再优化表结构，最后才是分库分表。自然月分表，每个月分一张表，分表规则定义在MYCAT_HOME/conf/rule.xml中具体如下： &lt;tableRule name=&quot;dm_log_sharding-by-date&quot;&gt; &lt;rule&gt; &lt;columns&gt;logtime&lt;/columns&gt; &lt;algorithm&gt;partbymonth&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;tableRule name=&quot;dm_opendoor_record_sharding-by-date&quot;&gt; &lt;rule&gt; &lt;columns&gt;opertime&lt;/columns&gt; &lt;algorithm&gt;partbymonth&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;function name=&quot;partbymonth&quot; class=&quot;io.mycat.route.function.PartitionByMonth&quot;&gt; &lt;property name=&quot;dateFormat&quot;&gt;yyyy-MM-dd HH:mm:ss&lt;/property&gt; &lt;property name=&quot;sBeginDate&quot;&gt;2014-01-01 00:00:00&lt;/property&gt; &lt;property name=&quot;sEndDate&quot;&gt;2014-12-31 00:00:00&lt;/property&gt; &lt;/function&gt; dm_log表按logtime字段根据partbymonth算法分表，dm_opendoor_record表按opertime字段根据partbymonth算法分表，算法partbymonth中的dateFormat定义时间格式，在sql语句增删改查中时间需要按照定义格式传入，才能正常执行分表算法。分表名称定义在MYCAT_HOME/conf/schema.xml &lt;schema name=&quot;mt_pm&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot; dataNode=&quot;mt_pm_dn&quot;&gt; &lt;table name=&quot;dm_log&quot; primaryKey=&quot;logid&quot; autoIncrement=&quot;true&quot; subTables=&quot;dm_log_$1-12&quot; dataNode=&quot;mt_pm_dn&quot; rule=&quot;dm_log_sharding-by-month&quot;/&gt; &lt;table name=&quot;dm_opendoor_record&quot; primaryKey=&quot;id&quot; autoIncrement=&quot;true&quot; subTables=&quot;dm_opendoor_record_$1-12&quot; dataNode=&quot;mt_pm_dn&quot; rule=&quot;dm_opendoor_record_sharding-by-month&quot;/&gt; &lt;/schema&gt; subTables定义了分表的名称：​ dm_log表定义了分表名为dm_log_$1-12，表示分为12张表，表名分别为：dm_log_1、dm_log_2、dm_log_3、dm_log_4、dm_log_5、dm_log_6、dm_log_7、dm_log_8、dm_log_9、dm_log_10、dm_log_11、dm_log_12。logtime为一月份时，根据算法会将数据分配到dm_log_1表，二月份数据插入表dm_log_2，以此类推，到十二月份后的一月份数据又循环插入dm_log_1表。​ dm_opendoor_record表定义了分表名为dm_opendoor_record _$1-12，表示分为12张表，表名分别为：dm_opendoor_record _1、dm_opendoor_record _2、dm_opendoor_record _3、dm_opendoor_record _4、dm_opendoor_record _5、dm_opendoor_record _6、dm_opendoor_record_7、dm_opendoor_record_8、dm_opendoor_record_9、dm_opendoor_record _10、dm_opendoor_record _11、dm_opendoor_record _12。opertime为一月份时，根据算法会将数据分配到dm_opendoor_record _1表，二月份数据插入表dm_opendoor_record_2，以此类推，到十二月份后的一月份数据又循环插入dm_opendoor_record _1表。 二、自增主键原理:​ 在数据库中建立一张表，存放 sequence 名称(name)，sequence 当前值(current_value)，步长(increment) int 类型每次读取多少个 sequence，假设为 K)等信息；Sequence 获取步骤：​ 1).当初次使用该 sequence 时，根据传入的 sequence 名称，从数据库这张表中读取 current_value，和 increment 到 MyCat 中，并将数据库中的 current_value 设置为原 current_value 值+increment 值；​ 2).MyCat 将读取到 current_value+increment 作为本次要使用的 sequence 值，下次使用时，自动加 1，当使用 increment 次后，执行步骤 1)相同的操作.MyCat 负责维护这张表，用到哪些 sequence，只需要在这张表中插入一条记录即可。若某次读取的sequence 没有用完，系统就停掉了，则这次读取的 sequence 剩余值不会再使用。配置方式：MYCAT_HOME/conf/server.xml 配置： &lt;system&gt;&lt;property name=&quot;sequnceHandlerType&quot;&gt;1&lt;/property&gt;&lt;/system&gt; 注：sequnceHandlerType 需要配置为 1，表示使用数据库方式生成 sequence.MYCAT_HOME/conf/schema.xml配置： &lt;schema name=&quot;mt_pm&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot; dataNode=&quot;mt_pm_dn&quot;&gt; &lt;table name=&quot;dm_log&quot; primaryKey=&quot;logid&quot; autoIncrement=&quot;true&quot; subTables=&quot;dm_log_$1-12&quot; dataNode=&quot;mt_pm_dn&quot; rule=&quot;dm_log_sharding-by-month&quot;/&gt; &lt;table name=&quot;dm_opendoor_record&quot; primaryKey=&quot;id&quot; autoIncrement=&quot;true&quot; subTables=&quot;dm_opendoor_record_$1-12&quot; dataNode=&quot;mt_pm_dn&quot; rule=&quot;dm_opendoor_record_sharding-by-month&quot;/&gt; &lt;/schema&gt; 在table节点配置primaryKey和autoIncrement，primaryKey为自增主键，autoIncrement值为ture。 数据库配置：1) 创建 MYCAT_SEQUENCE 表– 创建存放 sequence 的表 DROP TABLE IF EXISTS MYCAT_SEQUENCE; CREATE TABLE MYCAT_SEQUENCE (name VARCHAR(50) NOT NULL,current_value INT NOT NULL,increment INT NOT NULL DEFAULT 100, PRIMARY KEY(name)) ENGINE=InnoDB; name sequence 名称 current_value 当前 value increment 增长步长，可理解为 mycat 在数据库中一次读取多少个 sequence， 当这些用完后, 下次再从数据库中读取。 – 插入sequence INSERT INTO `mycat_sequence` (`name`, `current_value`, `increment`) VALUES (&#39;dm_log&#39;, &#39;152509809922444&#39;, &#39;1000&#39;); INSERT INTO `mycat_sequence` (`name`, `current_value`, `increment`) VALUES (&#39;dm_opendoor_record&#39;, &#39;58733280&#39;, &#39;1000&#39;); 2) 创建相关 function –- 获取当前 sequence 的值 (返回当前值,增量) DROP FUNCTION IF EXISTS mycat_seq_currval; DELIMITER CREATE FUNCTION mycat_seq_currval(seq_name VARCHAR(50)) RETURNS varchar(64) CHARSET utf-8 DETERMINISTIC BEGIN DECLARE retval VARCHAR(64); SET retval=“-999999999,null” ; SELECT concat(CAST(current_value AS CHAR),“,” ,CAST(increment AS CHAR)) INTO retval FROM MYCAT_SEQUENCE WHERE name = seq_name; RETURN retval; END DELIMITER; –- 设置 sequence 值 DROP FUNCTION IF EXISTS mycat_seq_setval; DELIMITER CREATE FUNCTION mycat_seq_setval(seq_name VARCHAR(50),value INTEGER) RETURNS varchar(64) CHARSET utf-8 DETERMINISTIC BEGIN UPDATE MYCAT_SEQUENCE SET current_value = value WHERE name = seq_name; RETURN mycat_seq_currval(seq_name); END DELIMITER; –- 获取下一个 sequence 值 DROP FUNCTION IF EXISTS mycat_seq_nextval; DELIMITER CREATE FUNCTION mycat_seq_nextval(seq_name VARCHAR(50)) RETURNS varchar(64) CHARSET utf-8 DETERMINISTIC BEGIN UPDATE MYCAT_SEQUENCE SET current_value = current_value + increment WHERE name = seq_name; RETURN mycat_seq_currval(seq_name); END DELIMITER; 4) sequence_db_conf.properties 相关配置,指定 sequence 相关配置在哪个节点上：例如： DM_LOG=mt_pm_dn DM_OPENDOOR_RECORD=mt_pm_dn 注意：MYCAT_SEQUENCE 表和以上的 3 个 function，需要放在同一个节点上。 function 请直接在具体节点的数据库上执行，如果执行的时候报：you might want to use the less safe log_bin_trust_function_creators variable需要对数据库做如下设置：windows 下 my.ini[mysqld]加上 log_bin_trust_function_creators=1linux 下/etc/my.cnf 下 my.ini[mysqld]加上 log_bin_trust_function_creators=1修改完后，即可在 mysql 数据库中执行上面的函数.使用示例： INSERT INTO `mt_pm`.`dm_log` (`logid`, `deviceid`, `logtype`, `logtime`, `content`, `picurl`, `id`, `positionid`, `position`, `comid`, `launchposition`, `status`) VALUES (next value for MYCATSEQ_DM_LOG, &#39;af0f69db62-4d31-d4e2-c041-793ed33931&#39;, &#39;unlock&#39;, &#39;2018-01-01 08:01:39&#39;, &#39;3|0e3f6740|1&#39;, NULL, NULL, NULL, NULL, NULL, NULL, NULL); 或者不带主键 INSERT INTO `mt_pm`.`dm_log` (`deviceid`, `logtype`, `logtime`, `content`, `picurl`, `id`, `positionid`, `position`, `comid`, `launchposition`, `status`) VALUES (&#39;af0f69db62-4d31-d4e2-c041-793ed33931&#39;, &#39;unlock&#39;, &#39;2018-01-01 08:01:39&#39;, &#39;3|0e3f6740|1&#39;, NULL, NULL, NULL, NULL, NULL, NULL, NULL); 三、定期备份表数据​ 分为12张表后，每年循环插入数据，最终数据量越来越大，需要定期将历史数据备份或迁移。这里采用修改表名，再新建和原表名结构一样的新表。例如： ALTER TABLE dm_log_1 RENAME TO dm_log201801; CREATE TABLE IF NOT EXISTS dm_log_1 LIKE dm_log201801; ​ 备份dm_log_1的数据，假设dm_log_1存的都是2018年1月份数据，则把表名修改为dm_log201801，然后再吉安一张表名为dm_log_1的表。​ 上述操作在数据库中写成存储过程，通过数据库定时事件调用执行，详细请看附件中相关sql语句。 定时事件调用策略： 每月1日的凌晨3:30执行备份历史数据，例如:2018年7月1日凌晨3:30把表dm_log_1改为dm_log201801并新建表dm_log_1，2018年8月1日凌晨3:30把表dm_log_2改为dm_log201802并新建表dm_log_2，以此类推，保留最近半年的数据供物管系统页面查询，超过半年数据则需通过数据库查询历史数据。 rename_dm_log_history为备份dm_log表数据的存储过程，Event_Rename_dm_log_history为定时事件每月调用rename_dm_log_history备份数据。 每月1日的凌晨3:30执行备份历史数据，例如:2018年7月1日凌晨3:30把表`dm_opendoor_record_1`改为dm_opendoor_record201801并新建表dm_opendoor_record_1，2018年8月1日凌晨3:30把表dm_opendoor_record_2改为dm_opendoor_record201802并新建表dm_opendoor_record_2，以此类推，保留最近半年的数据供物管系统页面查询，超过半年数据则需通过数据库查询历史数据。 rename_dm_opendoor_record_history为备份dm_opendoor_record表数据的存储过程，Event_Rename_dm_opendoor_record_history为定时事件每月调用rename_dm_log_history备份数据。 四、附件1.相关sql语句 2.mycat​五、参考资料Mycat官网：http://www.mycat.io/Mycat权威指南：http://www.mycat.io/document/Mycat_V1.6.0.pdf]]></content>
      <categories>
        <category>mysql</category>
        <category>mycat</category>
        <category>subtable</category>
        <category>partbymonth</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mycat</tag>
        <tag>subtable</tag>
        <tag>partbymonth</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker常用命令]]></title>
    <url>%2FDocker-common%2F</url>
    <content type="text"><![CDATA[Docker使用比较频繁的命令 查看docker 版本# docker version Client: Version: 18.03.1-ce API version: 1.37 Go version: go1.9.5 Git commit: 9ee9f40 Built: Thu Apr 26 07:12:48 2018 OS/Arch: windows/amd64 Experimental: false Orchestrator: swarm Server: Engine: Version: 18.06.1-ce API version: 1.38 (minimum version 1.12) Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17:25:29 2018 OS/Arch: linux/amd64 Experimental: true docker 配置信息# docker info Containers: 128 Running: 62 Paused: 0 Stopped: 66 Images: 256 Server Version: 18.06.1-ce Storage Driver: overlay2 Backing Filesystem: xfs Supports d_type: true Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 468a545b9edcd5932818eb9de8e72413e616e86e runc version: 69663f0bd4b60df09991c08812a60108003fa340 init version: fec3683 Security Options: seccomp Profile: default Kernel Version: 3.10.0-862.el7.x86_64 Operating System: CentOS Linux 7 (Core) OSType: linux Architecture: x86_64 CPUs: 3 Total Memory: 15.02GiB Name: bogon ID: CAI4:PHBY:FKFP:5BI6:LWUG:L3XF:OVU6:OGDF:IS5J:IPF4:3JKZ:KTUZ Docker Root Dir: /var/lib/docker Debug Mode (client): false Debug Mode (server): true File Descriptors: 312 Goroutines: 273 System Time: 2018-12-19T11:26:00.704470694+08:00 EventsListeners: 0 Registry: https://index.docker.io/v1/ Labels: name=docker Experimental: true Insecure Registries: loclhost:5000 172.20.8.5:5000 172.20.8.5:8888 127.0.0.0/8 Registry Mirrors: https://registry.docker-cn.com/ https://container-registry.oracle.com/ https://dhcl9iu5.mirror.aliyuncs.com/ https://docker.mirrors.ustc.edu.cn/ http://29bd46d3.m.daocloud.io/ http://hub-mirror.c.163.com/ Live Restore Enabled: false 拉取镜像# docker pull tomcat Using default tag: latest latest: Pulling from library/tomcat 54f7e8ac135a: Downloading [===========&gt; ] 9.98MB/45.32MB d6341e30912f: Downloading [============================&gt; ] 6.038MB/10.74MB 087a57faf949: Download complete 95065f220961: Download complete 0887630ce576: Download complete c375d1959fab: Download complete e00a5e6055cc: Waiting 8319f5fb56cf: Waiting 258c74eb25ab: Waiting 5c135322994c: Waiting b2cc25ec4861: Waiting 40140bebba00: Waiting d1786b40ed4f: Waiting Digest: sha256:d6f67aacce64010880a1e9ea6f0ace9fe9e20d39aae0489c8e88b4c14effe3a0 Status: Downloaded newer image for tomcat:latest 运行容器# docker run --name tomcat -p 8080:8080 -v /data:/usr/local/tomcat/webapps/data -idt tomcat bf0c6f766a2ceec0cdd06ae1b5556bf53bb14c7a0205d9531b259f72ca6698c1 查看运行中的容器# docker ps | grep tomcat CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES bf0c6f766a2c tomcat &quot;catalina.sh run&quot; 47 seconds ago Up 45 seconds 0.0.0.0:8080-&gt;8080/tcp tomcat 查看容器日志# docker logs tomcat Using CATALINA_BASE: /usr/local/tomcat Using CATALINA_HOME: /usr/local/tomcat Using CATALINA_TMPDIR: /usr/local/tomcat/temp Using JRE_HOME: /docker-java-home/jre Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar 21-Dec-2018 08:39:43.621 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server version: Apache Tomcat/8.5.35 21-Dec-2018 08:39:43.624 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server built: Nov 3 2018 17:39:20 UTC 21-Dec-2018 08:39:43.625 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server number: 8.5.35.0 21-Dec-2018 08:39:43.625 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log OS Name: Linux 21-Dec-2018 08:39:43.625 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log OS Version: 3.10.0-862.el7.x86_64 21-Dec-2018 08:39:43.625 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Architecture: amd64 21-Dec-2018 08:39:43.625 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Java Home: /usr/lib/jvm/java-8-openjdk-amd64/jre 21-Dec-2018 08:39:43.625 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log JVM Version: 1.8.0_181-8u181-b13-2~deb9u1-b13 21-Dec-2018 08:39:43.626 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log JVM Vendor: Oracle Corporation 21-Dec-2018 08:39:43.626 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log CATALINA_BASE: /usr/local/tomcat 21-Dec-2018 08:39:43.626 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log CATALINA_HOME: /usr/local/tomcat 21-Dec-2018 08:39:43.626 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.util.logging.config.file=/usr/local/tomcat/conf/logging.properties 21-Dec-2018 08:39:43.627 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager 21-Dec-2018 08:39:43.627 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djdk.tls.ephemeralDHKeySize=2048 21-Dec-2018 08:39:43.628 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.protocol.handler.pkgs=org.apache.catalina.webresources 21-Dec-2018 08:39:43.629 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 21-Dec-2018 08:39:43.629 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dignore.endorsed.dirs= 21-Dec-2018 08:39:43.629 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dcatalina.base=/usr/local/tomcat 21-Dec-2018 08:39:43.631 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dcatalina.home=/usr/local/tomcat 21-Dec-2018 08:39:43.631 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.io.tmpdir=/usr/local/tomcat/temp 21-Dec-2018 08:39:43.631 INFO [main] org.apache.catalina.core.AprLifecycleListener.lifecycleEvent Loaded APR based Apache Tomcat Native library [1.2.18] using APR version [1.5.2]. 21-Dec-2018 08:39:43.631 INFO [main] org.apache.catalina.core.AprLifecycleListener.lifecycleEvent APR capabilities: IPv6 [true], sendfile [true], accept filters [false], random [true]. 21-Dec-2018 08:39:43.632 INFO [main] org.apache.catalina.core.AprLifecycleListener.lifecycleEvent APR/OpenSSL configuration: useAprConnector [false], useOpenSSL [true] 21-Dec-2018 08:39:43.637 INFO [main] org.apache.catalina.core.AprLifecycleListener.initializeSSL OpenSSL successfully initialized [OpenSSL 1.1.0j 20 Nov 2018] 21-Dec-2018 08:39:43.784 INFO [main] org.apache.coyote.AbstractProtocol.init Initializing ProtocolHandler [&quot;http-nio-8080&quot;] 21-Dec-2018 08:39:43.800 INFO [main] org.apache.tomcat.util.net.NioSelectorPool.getSharedSelector Using a shared selector for servlet write/read 21-Dec-2018 08:39:43.819 INFO [main] org.apache.coyote.AbstractProtocol.init Initializing ProtocolHandler [&quot;ajp-nio-8009&quot;] 21-Dec-2018 08:39:43.821 INFO [main] org.apache.tomcat.util.net.NioSelectorPool.getSharedSelector Using a shared selector for servlet write/read 21-Dec-2018 08:39:43.823 INFO [main] org.apache.catalina.startup.Catalina.load Initialization processed in 858 ms 21-Dec-2018 08:39:43.861 INFO [main] org.apache.catalina.core.StandardService.startInternal Starting service [Catalina] 21-Dec-2018 08:39:43.861 INFO [main] org.apache.catalina.core.StandardEngine.startInternal Starting Servlet Engine: Apache Tomcat/8.5.35 21-Dec-2018 08:39:43.879 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/usr/local/tomcat/webapps/ROOT] 21-Dec-2018 08:39:44.378 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/usr/local/tomcat/webapps/ROOT] has finished in [499] ms 21-Dec-2018 08:39:44.379 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/usr/local/tomcat/webapps/docs] 21-Dec-2018 08:39:44.436 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/usr/local/tomcat/webapps/docs] has finished in [57] ms 21-Dec-2018 08:39:44.436 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/usr/local/tomcat/webapps/examples] 21-Dec-2018 08:39:45.443 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/usr/local/tomcat/webapps/examples] has finished in [1,006] ms 21-Dec-2018 08:39:45.443 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/usr/local/tomcat/webapps/host-manager] 21-Dec-2018 08:39:46.070 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/usr/local/tomcat/webapps/host-manager] has finished in [626] ms 21-Dec-2018 08:39:46.071 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/usr/local/tomcat/webapps/manager] 21-Dec-2018 08:39:46.204 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/usr/local/tomcat/webapps/manager] has finished in [133] ms 21-Dec-2018 08:39:46.207 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/usr/local/tomcat/webapps/data] 21-Dec-2018 08:39:46.282 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/usr/local/tomcat/webapps/data] has finished in [75] ms 21-Dec-2018 08:39:46.289 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;http-nio-8080&quot;] 21-Dec-2018 08:39:46.315 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;ajp-nio-8009&quot;] 21-Dec-2018 08:39:46.345 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 2520 ms 停止运行中的容器# docker stop tomcat tomcat 重新运行停止的容器# docker start tomcat tomcat 重启容器# docker restart tomcat tomcat 强制删除运行中的容器# docker rm tomcat -f tomcat]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用的Shell脚本和Linux命令]]></title>
    <url>%2FCommon-shell-script%2F</url>
    <content type="text"><![CDATA[收集工作中经常用的Linux命令和shell脚本 zip 压缩和解压缩# 压缩文件夹 zip -r data.zip data # 解压缩文件,默认解压到当前路径 unzip data.zip # 解压到指定路径 unzip data.zip -d destDir # 查看帮助 unzip -h tar 压缩和解压缩# 压缩文件夹 tar -czf data.tar.gz data # 解压缩到当前路径 tar -xzf data.tar.gz -C /destDir tail查看和过滤日志文件# 动态输出Tomcat日志到控制台 tail -1000f catalina.out # 按字段过滤日志 tail -1000f catalina.out | grap -A 20 &#39;ERROR&#39; netstat 查看监听端口的进程# 查看监听端口为1600的进程 netstat -tlpn | grep &quot;\b16000\b&quot; kill停止指定进程# 停止当前路径下的应用进程 kill -9 $(ps -ef|grep $(pwd)|grep -v grep|awk &#39;{print $2}&#39;) # 停止监听端口为1600的进程 kill -9 $(netstat -tlpn | grep &quot;\b16000\b&quot; | awk &#39;{print $7}&#39; | cut -d &#39;/&#39; -f 1) sed替换文件内容# 替换Tomcat默认端口 sed -i &quot;s|&lt;Connector port=\&quot;8080\&quot;|&lt;Connector port=\&quot;51000\&quot;|g&quot; server.xml &amp;&amp; \ sed -i &quot;s|&lt;Connector port=\&quot;8009\&quot;|&lt;Connector port=\&quot;51080\&quot;|g&quot; server.xml shell 判断文件夹或文件是否存在文件夹不存在则创建 if [ ! -d &quot;/data/&quot; ];then mkdir /data else echo &quot;文件夹已经存在&quot; fi 文件存在则删除 if [ ! -f &quot;/data/filename&quot; ];then echo &quot;文件不存在&quot; else rm -f /data/filename fi 判断文件夹是否存在 if [ -d &quot;/data/&quot; ];then echo &quot;文件夹存在&quot; else echo &quot;文件夹不存在&quot; fi 判断文件是否存在 if [ -f &quot;/data/filename&quot; ];then echo &quot;文件存在&quot; else echo &quot;文件不存在&quot; fi 文件比较符 -e 判断对象是否存在 -d 判断对象是否存在，并且为目录 -f 判断对象是否存在，并且为常规文件 -L 判断对象是否存在，并且为符号链接 -h 判断对象是否存在，并且为软链接 -s 判断对象是否存在，并且长度不为0 -r 判断对象是否存在，并且可读 -w 判断对象是否存在，并且可写 -x 判断对象是否存在，并且可执行 -O 判断对象是否存在，并且属于当前用户 -G 判断对象是否存在，并且属于当前用户组 -nt 判断file1是否比file2新 [ &quot;/data/file1&quot; -nt &quot;/data/file2&quot; ] -ot 判断file1是否比file2旧 [ &quot;/data/file1&quot; -ot &quot;/data/file2&quot; ] 判断某个变量是否包含字符串/变量的方法尝试了有3种方法： 使用“=~”符号，注意前后必须要有空格！ 可以输出正确结果,被匹配的字符串必须要有引号括起来！ ➜ ~ a1=&#39;hello.world&#39; ➜ ~ a2=&#39;helloworld&#39; ➜ ~ b=&#39;.&#39; ➜ ~ if [[ ${a1} =~ &#39;.&#39; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a2} =~ &#39;.&#39; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a1} =~ &quot;.&quot; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a2} =~ &quot;.&quot; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a1} =~ &quot;${b}&quot; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a2} =~ &quot;${b}&quot; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ 不能输出正确结果 ➜ ~ a1=&#39;hello.world&#39; ➜ ~ &#39; ➜ ~ b=&#39;.&#39; ➜ ~ if [[ ${a1} =~ . ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a2} =~ . ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a1} =~ ${b} ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a2} =~ ${b} ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a1} =~ &#39;${b}&#39; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if [[ ${a2} =~ &#39;${b}&#39; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no 使用”==“加通配符wildcard，注意等号前后必须有空格，注意，通配符跟正则表达式有所区别，*表示匹配 0 或多个字符 可以输出正确结果 ➜ ~ a1=&#39;hello.world&#39; ➜ ~ a2=&#39;helloworld&#39; ➜ ~ if [[ ${a1} == *.* ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a2} == *.* ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no 不能输出正确结果 ，通配符不能用括号括起来！ ➜ ~ a1=&#39;hello.world&#39; ➜ ~ a2=&#39;helloworld&#39; ➜ ~ if [[ ${a2} == &quot;*.*&quot; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if [[ ${a1} == &quot;*.*&quot; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if [[ ${a1} == &#39;*.*&#39; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if [[ ${a2} == &#39;*.*&#39; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no 使用echo + grep -q 选项 使用这种方法时匹配是否有”.”会不正常，所以我们换成匹配普通字符，有没有括号都可以 ➜ ~ a1=&#39;hello.world&#39; ➜ ~ a2=&#39;helloworld&#39; ➜ ~ a3=&quot;helloworlda&quot; ➜ ~ if ( echo ${a1} |grep -q a );then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if ( echo ${a2} |grep -q a );then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if ( echo ${a3} |grep -q a );then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if ( echo ${a1} |grep -q &#39;a&#39; );then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if ( echo ${a2} |grep -q &#39;a&#39; );then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if ( echo ${a3} |grep -q &#39;a&#39; );then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if ( echo ${a1} |grep -q &quot;a&quot; );then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if ( echo ${a2} |grep -q &quot;a&quot; );then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if ( echo ${a3} |grep -q &quot;a&quot; );then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes crontab定时任务crontab -e # 每分钟执行一次monitor.sh脚步 */1 * * * * /usr/java/monitor.sh # 数据库备份 0 3 * * * /bin/sh /data1/script/databak.sh &amp; 0 4 * * * find /data1/databak -type f -mtime +3 -exec rm {} \; databak.sh内容#!/bin/bash /usr/bin/mysqldump -uroot -p123456 test &gt;/data1/databak/`date +%Y%m%d`test.sql 2&gt;/dev/null 监控Tomcat是否正常启动 #!/bin/sh # 定义环境变量（要改成自己的jdk相关地址） PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_191-oraclejdk export CLASSPATH=$JAVA_HOME/lib:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin TomcatHome=/opt/webserver/pf-platform #获取tomcat进程ID（这里注意tomcat7要改成自己的tomcat目录名） TomcatID=$(ps -ef |grep tomcat |grep -w $TomcatHome|grep -v &#39;grep&#39;|awk &#39;{print $2}&#39;) #tomcat启动程序(这里注意要改成自己tomcat实际安装的路径) StartTomcat=$TomcatHome/bin/startup.sh TomcatCache=$TomcatHome/work #自己定义要监控的页面地址，页面越简单越好，比如：页面上写个success即可 WebUrl=http://172.20.8.5:41000/pf-platform/login/login #日志输出 （自己定义地址，用于输出监控日志和监控报错日志） #TomcatMonitorLog=$TomcatHome/TomcatMonitor-$(date &#39;+%Y%m%d%H%M%S&#39;).log TomcatMonitorLog=$TomcatHome/logs/TomcatMonitor-$(date &#39;+%Y-%m-%d&#39;).log GetPageInfo=$TomcatHome/logs/PageInfo-$(date &#39;+%Y-%m-%d&#39;).log if [ ! -d $TomcatHome/logs ]; then mkdir -p $TomcatHome/logs ; fi Monitor() { echo &quot;[info]开始监控tomcat...[$(date +&#39;%F %H:%M:%S&#39;)]&quot; if [[ $TomcatID ]];then # 这里判断TOMCAT进程是否存在 echo &quot;[info]当前tomcat进程ID为:$TomcatID,继续检测页面...&quot; # 检测是否启动成功(成功的话页面会返回状态&quot;302&quot;) TomcatServiceCode=$(curl -s -o $GetPageInfo -m 10 --connect-timeout 10 $WebUrl -w %{http_code}) if [ $TomcatServiceCode -eq 302 ];then echo &quot;[info]页面返回码为$TomcatServiceCode,tomcat启动成功,测试页面正常......&quot; else echo &quot;[error]tomcat页面出错,请注意......状态码为$TomcatServiceCode,错误日志已输出到$GetPageInfo&quot; echo &quot;[error]页面访问出错,开始重启tomcat&quot; kill -9 $TomcatID # 杀掉原tomcat进程 sleep 3 #rm -rf $TomcatCache # 清理tomcat缓存 $StartTomcat fi else echo &quot;[error]tomcat进程不存在!tomcat开始自动重启...&quot; echo &quot;[info]$StartTomcat,请稍候......&quot; #rm -rf $TomcatCache $StartTomcat fi echo &quot;------------------------------&quot; } Monitor&gt;&gt;$TomcatMonitorLog 监控netty服务是否正常开启端口#!/bin/sh # 定义环境变量（要改成自己的jdk相关地址） PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_191-oraclejdk export CLASSPATH=$JAVA_HOME/lib:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin NettyServerHome=/opt/webserver/mtech-cloud-netty-server #获取netty-server进程ID（这里注意netty-server7要改成自己的netty-server目录名） NettyServerID=$(ps -ef |grep netty-server |grep -w $NettyServerHome |grep -w java |grep -v &#39;grep&#39;|awk &#39;{print $2}&#39;) #netty-server启动程序(这里注意要改成自己netty-server实际安装的路径) StartNettyServer=$NettyServerHome/bin/start.sh #netty监听端口 NettyPort=16000 #日志输出 （自己定义地址，用于输出监控日志和监控报错日志） NettyServerMonitorLog=$NettyServerHome/logs/NettyServerMonitor-$(date +&#39;%F&#39;).log GetPageInfo=$NettyServerHome/logs/PortInfo-$(date +&#39;%F&#39;).log if [ ! -d $NettyServerHome/logs ]; then mkdir -p $NettyServerHome/logs ; fi Monitor() { echo &quot;[info]开始监控netty-server...[$(date +&#39;%F %H:%M:%S&#39;)]&quot; if [[ $NettyServerID ]];then # 这里判断netty-server进程是否存在 echo &quot;[info]当前netty-server进程ID为:$NettyServerID,继续检测端口...&quot; # 检测是否启动成功(成功的话会返回端口信息) NettyServerPort=$(checkPort $NettyPort) echo &quot;端口检测结果：$NettyServerPort &quot; if [ $NettyServerPort -eq 0 ];then echo &quot;[info]返回码为$NettyServerPort,netty-server启动成功,测试端口正常......&quot; else echo &quot;[error]netty-server启动出错,请注意......, 错误日志已输出到$GetPageInfo&quot; echo &quot;[error]端口$NettyPort检测出错,开始重启netty-server&quot; kill -9 $NettyServerID # 杀掉原netty-server进程 sleep 3 #rm -rf $netty-serverCache # 清理netty-server缓存 $StartNettyServer &gt;&gt; $NettyServerHome/logs/nohub.out &amp; &gt;&gt; /dev/null fi else echo &quot;[error]netty-server进程不存在!netty-server开始自动重启...&quot; echo &quot;[info]$StartNettyServer,请稍候......&quot; #rm -rf $netty-serverCache # $StartNettyServer &gt;&gt; /dev/null &amp; $StartNettyServer &gt;&gt; $NettyServerHome/logs/nohub.out &amp; &gt;&gt; /dev/null fi echo &quot;------------------------------&quot; } checkPort() { echo &quot;------------------------------&quot; &gt;&gt; $GetPageInfo echo &quot;$(date +&#39;%F %H:%M:%S&#39;) &quot; &gt;&gt; $GetPageInfo echo $(netstat -tlpn | grep &quot;\b$1\b&quot;) &gt;&gt; $GetPageInfo netstat -tlpn | grep &quot;\b$1\b&quot; | awk &#39;{print $2}&#39; } Monitor&gt;&gt;$NettyServerMonitorLog &amp; 部署war包到tomcat➜ web cat start.sh WORKDIR=/data1/webserver/mt_chs/web cd $WORKDIR kill -9 $(netstat -tlpn | grep &quot;\b18080\b&quot; | awk &#39;{print $7}&#39; | cut -d &#39;/&#39; -f 1) echo &#39;&#39; &gt; $WORKDIR/logs/catalina.out $WORKDIR/bin/startup.sh ➜ web cat tailf.sh WORKDIR=/data1/webserver/mt_chs/web tail -f $WORKDIR/logs/catalina.out ➜ web cat stop.sh WORKDIR=/data1/webserver/mt_chs/web cd $WORKDIR kill -9 $(netstat -tlpn | grep &quot;\b18080\b&quot; | awk &#39;{print $7}&#39; | cut -d &#39;/&#39; -f 1) ➜ ~ cat deploy_web.sh WEB_DIR=/data1/webserver/mt_chs/web APP_DIR=$WEB_DIR/webapps/chs_web HOME_DIR=/home/ledmon WAR_FILE=$HOME_DIR/$1 function deploy(){ echo &quot;停止tomcat...&quot; $WEB_DIR/stop.sh mkdir -p $APP_DIR echo &quot;更新应用...&quot; rm -rf $APP_DIR/* unzip $WAR_FILE -d $APP_DIR &gt;&gt; /dev/null echo &quot;启动tomcat...&quot; $WEB_DIR/start.sh echo &quot;查看启动日志&quot; $WEB_DIR/tailf.sh } if [ ! -f &quot;$WAR_FILE&quot; ];then echo &quot;文件不存在，路径: $WAR_FILE&quot; elif (! echo ${WAR_FILE} |grep -q &quot;.war&quot; );then echo &quot;文件不合法，路径：$WAR_FILE&quot; echo &quot;请选择war文件&quot; elif (! echo ${WAR_FILE} |grep -q &quot;web_product&quot; );then echo &quot;文件不合法，路径：$WAR_FILE&quot; echo &quot;请选择web_proeuct*.war文件&quot; else deploy fi 部署springboot的jar包应用➜ appint cat start.sh WORKDIR=/data1/webserver/mt_chs/appint cd $WORKDIR kill -9 $(netstat -tlpn | grep &quot;\b18083\b&quot; | awk &#39;{print $7}&#39; | cut -d &#39;/&#39; -f 1) echo &#39;&#39; &gt; $WORKDIR/out.log nohup java -jar $WORKDIR/appint_*.jar &gt; $WORKDIR/out.log &amp; ➜ appint cat tailf.sh WORKDIR=/data1/webserver/mt_chs/appint tail -f $WORKDIR/out.log ➜ ~ cat deploy_appint.sh APP_DIR=/data1/webserver/mt_chs/appint HOME_DIR=/home/ledmon JAR_FILE=$HOME_DIR/$1 function deploy(){ echo &quot;停止应用...&quot; kill -9 $(netstat -tlpn | grep &quot;\b18083\b&quot; | awk &#39;{print $7}&#39; | cut -d &#39;/&#39; -f 1) mkdir -p $APP_DIR echo &quot;更新应用...&quot; rm -rf $APP_DIR/*.jar cp $JAR_FILE $APP_DIR echo &quot;启动应用...&quot; $APP_DIR/start.sh echo &quot;查看启动日志&quot; $APP_DIR/tailf.sh } if [ ! -f &quot;$JAR_FILE&quot; ];then echo &quot;文件不存在，路径: $JAR_FILE&quot; elif (! echo ${JAR_FILE} |grep -q &quot;.jar&quot; );then echo &quot;文件不合法，路径：$JAR_FILE&quot; echo &quot;请选择*.jar文件&quot; elif (! echo ${JAR_FILE} |grep -q &quot;appint_product&quot; );then echo &quot;文件不合法，路径：$JAR_FILE&quot; echo &quot;请选择appint_product*.jar文件&quot; else deploy fi]]></content>
      <categories>
        <category>linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发问题--乐观锁与悲观锁以及乐观锁的一种实现方式-CAS]]></title>
    <url>%2FJava-Concurrent-Optimistic-And-Pessimistic-Locks%2F</url>
    <content type="text"><![CDATA[原文：https://www.cnblogs.com/qjjazry/p/6581568.html 首先介绍一些乐观锁与悲观锁: 悲观锁：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。再比如Java里面的同步原语synchronized关键字的实现也是悲观锁。 乐观锁：顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。 乐观锁的一种实现方式-CAS(Compare and Swap 比较并交换)： 锁存在的问题: Java在JDK1.5之前都是靠 synchronized关键字保证同步的，这种通过使用一致的锁定协议来协调对共享状态的访问，可以确保无论哪个线程持有共享变量的锁，都采用独占的方式来访问这些变量。这就是一种独占锁，独占锁其实就是一种悲观锁，所以可以说 synchronized 是悲观锁。 悲观锁机制存在以下问题： 1. 在多线程竞争下，加锁、释放锁会导致比较多的上下文切换和调度延时，引起性能问题。 2. 一个线程持有锁会导致其它所有需要此锁的线程挂起。 3. 如果一个优先级高的线程等待一个优先级低的线程释放锁会导致优先级倒置，引起性能风险。 对比于悲观锁的这些问题，另一个更加有效的锁就是乐观锁。其实乐观锁就是：每次不加锁而是假设没有并发冲突而去完成某项操作，如果因为并发冲突失败就重试，直到成功为止。 乐观锁： 乐观锁（ Optimistic Locking ）在上文已经说过了，其实就是一种思想。相对悲观锁而言，乐观锁假设认为数据一般情况下不会产生并发冲突，所以在数据进行提交更新的时候，才会正式对数据是否产生并发冲突进行检测，如果发现并发冲突了，则让返回用户错误的信息，让用户决定如何去做。 上面提到的乐观锁的概念中其实已经阐述了它的具体实现细节：主要就是两个步骤：冲突检测和数据更新。其实现方式有一种比较典型的就是 Compare and Swap ( CAS )。 CAS： CAS是乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。 CAS 操作中包含三个操作数 —— 需要读写的内存位置（V）、进行比较的预期原值（A）和拟写入的新值(B)。如果内存位置V的值与预期原值A相匹配，那么处理器会自动将该位置值更新为新值B。否则处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。（在 CAS 的一些特殊情况下将仅返回 CAS 是否成功，而不提取当前值。）CAS 有效地说明了“ 我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。 ”这其实和乐观锁的冲突检查+数据更新的原理是一样的。 这里再强调一下，乐观锁是一种思想。CAS是这种思想的一种实现方式。 JAVA对CAS的支持： 在JDK1.5 中新增 java.util.concurrent (J.U.C)就是建立在CAS之上的。相对于对于 synchronized 这种阻塞算法，CAS是非阻塞算法的一种常见实现。所以J.U.C在性能上有了很大的提升。 以 java.util.concurrent 中的 AtomicInteger 为例，看一下在不使用锁的情况下是如何保证线程安全的。主要理解 getAndIncrement 方法，该方法的作用相当于 ++i 操作。 public class AtomicInteger extends Number implements java.io.Serializable { private volatile int value; public final int get() { return value; } public final int getAndIncrement() { for (;;) { int current = get(); int next = current + 1; if (compareAndSet(current, next)) return current; } } public final boolean compareAndSet(int expect, int update) { return unsafe.compareAndSwapInt(this, valueOffset, expect, update); } } 在没有锁的机制下,字段value要借助volatile原语，保证线程间的数据是可见性。这样在获取变量的值的时候才能直接读取。然后来看看 ++i 是怎么做到的。 getAndIncrement 采用了CAS操作，每次从内存中读取数据然后将此数据和 +1 后的结果进行CAS操作，如果成功就返回结果，否则重试直到成功为止。 而 compareAndSet 利用JNI（Java Native Interface）来完成CPU指令的操作： public final boolean compareAndSet(int expect, int update) { return unsafe.compareAndSwapInt(this, valueOffset, expect, update); } 其中unsafe.compareAndSwapInt(this, valueOffset, expect, update);类似如下逻辑： if (this == expect) { this = update return true; } else { return false; } 那么比较this == expect，替换this = update，compareAndSwapInt实现这两个步骤的原子性呢？ 参考CAS的原理 CAS原理： CAS通过调用JNI的代码实现的。而compareAndSwapInt就是借助C来调用CPU底层指令实现的。 下面从分析比较常用的CPU（intel x86）来解释CAS的实现原理。 下面是sun.misc.Unsafe类的compareAndSwapInt()方法的源代码： public final native boolean compareAndSwapInt(Object o, long offset, int expected, int x); 可以看到这是个本地方法调用。这个本地方法在JDK中依次调用的C++代码为： #define LOCK_IF_MP(mp) __asm cmp mp, 0 \ __asm je L0 \ __asm _emit 0xF0 \ __asm L0: inline jint Atomic::cmpxchg (jint exchange_value, volatile jint* dest, jint compare_value) { // alternative for InterlockedCompareExchange int mp = os::is_MP(); __asm { mov edx, dest mov ecx, exchange_value mov eax, compare_value LOCK_IF_MP(mp) cmpxchg dword ptr [edx], ecx } } 如上面源代码所示，程序会根据当前处理器的类型来决定是否为cmpxchg指令添加lock前缀。如果程序是在多处理器上运行，就为cmpxchg指令加上lock前缀（lock cmpxchg）。反之，如果程序是在单处理器上运行，就省略lock前缀（单处理器自身会维护单处理器内的顺序一致性，不需要lock前缀提供的内存屏障效果）。 CAS缺点： 1. ABA问题： 比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且two进行了一些操作变成了B，然后two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后one操作成功。尽管线程one的CAS操作成功，但可能存在潜藏的问题。如下所示： 现有一个用单向链表实现的堆栈，栈顶为A，这时线程T1已经知道A.next为B，然后希望用CAS将栈顶替换为B： head.compareAndSet(A,B); 在T1执行上面这条指令之前，线程T2介入，将A、B出栈，再pushD、C、A，此时堆栈结构如下图，而对象B此时处于游离状态： 此时轮到线程T1执行CAS操作，检测发现栈顶仍为A，所以CAS成功，栈顶变为B，但实际上B.next为null，所以此时的情况变为： 其中堆栈中只有B一个元素，C和D组成的链表不再存在于堆栈中，平白无故就把C、D丢掉了。 从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 public boolean compareAndSet( V expectedReference,//预期引用 V newReference,//更新后的引用 int expectedStamp, //预期标志 int newStamp //更新后的标志 ) 实际应用代码： private static AtomicStampedReference&lt;Integer&gt; atomicStampedRef = new AtomicStampedReference&lt;Integer&gt;(100, 0); ........ atomicStampedRef.compareAndSet(100, 101, stamp, stamp + 1); 2. 循环时间长开销大： 自旋CAS（不成功，就一直循环执行，直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。 3. 只能保证一个共享变量的原子操作： 当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量i＝2,j=a，合并一下ij=2a，然后用CAS来操作ij。从Java1.5开始JDK提供了AtomicReference**类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作。** CAS与Synchronized的使用情景： 1、对于资源竞争较少（线程冲突较轻）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。 2、对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。 补充： synchronized在jdk1.6之后，已经改进优化。synchronized的底层实现主要依靠Lock-Free的队列，基本思路是自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。 concurrent包的实现： 由于java的CAS同时具有 volatile 读和volatile写的内存语义，因此Java线程之间的通信现在有了下面四种方式： 1. A线程写volatile变量，随后B线程读这个volatile变量。 2. A线程写volatile变量，随后B线程用CAS更新这个volatile变量。 3. A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量。 4. A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量。 Java的CAS会使用现代处理器上提供的高效机器级别原子指令，这些原子指令以原子方式对内存执行读-改-写操作，这是在多处理器中实现同步的关键（从本质上来说，能够支持原子性读-改-写指令的计算机器，是顺序计算图灵机的异步等价机器，因此任何现代的多处理器都会去支持某种能对内存执行原子性读-改-写操作的原子指令）。同时，volatile变量的读/写和CAS可以实现线程之间的通信。把这些特性整合在一起，就形成了整个concurrent包得以实现的基石。如果我们仔细分析concurrent包的源代码实现，会发现一个通用化的实现模式： 1. 首先，声明共享变量为volatile； 2. 然后，使用CAS的原子条件更新来实现线程之间的同步； 3. 同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。 AQS，非阻塞数据结构和原子变量类（java.util.concurrent.atomic包中的类），这些concurrent包中的基础类都是使用这种模式来实现的，而concurrent包中的高层类又是依赖于这些基础类来实现的。从整体来看，concurrent包的实现示意图如下： JVM中的CAS（堆中对象的分配）： Java调用new object()会创建一个对象，这个对象会被分配到JVM的堆中。那么这个对象到底是怎么在堆中保存的呢？ 首先，new object()执行的时候，这个对象需要多大的空间，其实是已经确定的，因为java中的各种数据类型，占用多大的空间都是固定的（对其原理不清楚的请自行Google）。那么接下来的工作就是在堆中找出那么一块空间用于存放这个对象。 在单线程的情况下，一般有两种分配策略： 1. 指针碰撞：这种一般适用于内存是绝对规整的（内存是否规整取决于内存回收策略），分配空间的工作只是将指针像空闲内存一侧移动对象大小的距离即可。 2. 空闲列表：这种适用于内存非规整的情况，这种情况下JVM会维护一个内存列表，记录哪些内存区域是空闲的，大小是多少。给对象分配空间的时候去空闲列表里查询到合适的区域然后进行分配即可。 但是JVM不可能一直在单线程状态下运行，那样效率太差了。由于再给一个对象分配内存的时候不是原子性的操作，至少需要以下几步：查找空闲列表、分配内存、修改空闲列表等等，这是不安全的。解决并发时的安全问题也有两种策略： 1. CAS：实际上虚拟机采用CAS配合上失败重试的方式保证更新操作的原子性，原理和上面讲的一样。 2. TLAB：如果使用CAS其实对性能还是会有影响的，所以JVM又提出了一种更高级的优化策略：每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲区（TLAB），线程内部需要分配内存时直接在TLAB上分配就行，避免了线程冲突。只有当缓冲区的内存用光需要重新分配内存的时候才会进行CAS操作分配更大的内存空间。 虚拟机是否使用TLAB，可以通过-XX:+/-UseTLAB参数来进行配置（jdk5及以后的版本默认是启用TLAB的）。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>lock</tag>
        <tag>java</tag>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows环境下Vmware中Centos共享文件]]></title>
    <url>%2FWindows-Vmware-Centos-share-Folder%2F</url>
    <content type="text"><![CDATA[先安装包依赖：yum -y install kernel-devel-$(uname -r) net-tools perl gcc gcc-c++ 安装vm tool在home文件夹下新建tmp文件夹：mkdir tmp mount /dev/cdrom /home/tmp cp /home/tmp/VMwareTools-10.2.5-8068393.tar.gz /tmp cd /tmp tar -zxvf VMwareTools-10.2.5-8068393.tar.gz cd vmware-tools-distrib ./vmware-install.pl 根据提示输入或一直回车即 安装挂载工具yum install -y open-vm-tools-devel]]></content>
      <categories>
        <category>linux</category>
        <category>centos</category>
        <category>vmware</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>linux</tag>
        <tag>vmware</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github安装hexo博客]]></title>
    <url>%2FBlog-Hexo-Install%2F</url>
    <content type="text"><![CDATA[写在开头 什么是Hexo？ Hexo是一个轻量级的Node.js博客框架，由一位台湾的在校大学生开发完成！ Hexo的配置文件_config.yml分为两种，一种是站点配置文件，也就是站点根目录下的_config.yml配置文件，另一个是主题配置文件，位于theme文件夹中对应主题的文件夹下的_config.yml。 在后续的网站配置中需要多次使用站点配置文件和主题配置文件，需要注意辨析。 安装node.jsWindows下安装在nodejs官网上下载最新的Windows安装包，直接安装即可。 ubuntu下安装命令行方式安装：sudo apt-get update sudo apt-get install nodejs 编译源码方式安装：在nodejs官网上找到需要下载的源码（不是二进制文件），解压之后进入目录，执行： $ ./configure $ make &amp;&amp; make install 注意如果需要sudo的话， make和make install 要分开，因为sudo不能传递到&amp;&amp;后面的指令。 安装npmsudo apt-get update sudo apt-get install npm 查看node和npm版本 node -v npm -v 安装cnpm 因为防火墙的缘故，很多境外网站被墙了，所以使用node.js的原生工具npm是无法正常安装模块的，建议使用淘宝前端组的国内镜像，使用他们定制的 cnpm (gzip 压缩支持) 命令行工具代替默认的 npm: npm install -g cnpm --registry=https://registry.npm.taobao.org 使用方法如下： 从registry.npm.taobao.org 安装所有模块. 当安装的时候发现安装的模块还没有同步过来, 淘宝 NPM 会自动在后台进行同步, 并且会让你从官方 NPM registry.npmjs.org 进行安装. 下次你再安装这个模块的时候, 就会直接从 淘宝 NPM 安装了. cnpm install [name] Hexo的安装与使用安装Hexo安转了node之后，就可以使用以下命令来安装hexo： npm install -g hexo-cli 使用Hexo安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。 hexo init &lt;folder&gt; cd &lt;folder&gt; npm install 新建完成后，指定文件夹的目录如下： ├── _config.yml├── package.json├── scaffolds├── source | ├── _drafts | └── _posts└── themes _config.yml 网站的 配置 信息 您可以在此配置网站大部分的参数。 package.json 应用程序的信息。EJS, Stylus 和 Markdown renderer 已默认安装，您可以自由移除。 package.json { &quot;name&quot;: &quot;hexo-site&quot;, &quot;version&quot;: &quot;0.0.0&quot;, &quot;private&quot;: true, &quot;hexo&quot;: { &quot;version&quot;: &quot;&quot; }, &quot;dependencies&quot;: { &quot;hexo&quot;: &quot;^3.0.0&quot;, &quot;hexo-generator-archive&quot;: &quot;^0.1.0&quot;, &quot;hexo-generator-category&quot;: &quot;^0.1.0&quot;, &quot;hexo-generator-index&quot;: &quot;^0.1.0&quot;, &quot;hexo-generator-tag&quot;: &quot;^0.1.0&quot;, &quot;hexo-renderer-ejs&quot;: &quot;^0.1.0&quot;, &quot;hexo-renderer-stylus&quot;: &quot;^0.2.0&quot;, &quot;hexo-renderer-marked&quot;: &quot;^0.2.4&quot;, &quot;hexo-server&quot;: &quot;^0.1.2&quot; } } scaffolds模版 文件夹。当您新建文章时，Hexo 会根据 scaffold 来建立文件。 Hexo的模板是指在新建的markdown文件中默认填充的内容。例如，如果您修改scaffold/post.md中的Front-matter内容，那么每次新建一篇文章时都会包含这个修改。 source资源文件夹是存放用户资源的地方。 除 _posts 文件夹之外，开头命名为 _(下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。 themes主题 文件夹。 Hexo 会根据主题来生成静态页面。 安装hexo插件在hexo中实现可视化编辑博客（hexo-admin）hexo-admin-github 安装并使用hexo-adminnpm install --save hexo-admin hexo server -d open http://localhost:4000/admin/ 设置后台密码修改站点配置文件，就是网站根目录下的 _config.yml文件: admin: username: myfavoritename password_hash: be121740bf988b2225a313fa1f107ca1 secret: a secret something username是用户名 password_hash是密码的哈希映射值，由于不同版本的node.js的哈希算法是不一样的，所有用以下方法来产生有效的密码哈希值。 &gt; node &gt; const bcrypt = require(&#39;bcrypt-nodejs&#39;) &gt; bcrypt.hashSync(&#39;your password secret here!&#39;) &gt; //=&gt; &#39;2a10$8f0CO288aEgpb0BQk0mAEOIDwPS.s6nl703xL6PLTVzM.758x8xsi&#39; &gt; secret是用于产生cookie值的。 在站点配置文件中设置好以下三个值之后，登录 http://localhost:4000/admin/ 就会提示输入账号密码。 在hexo中实现RRS功能（ hexo-generator-feed ）安装 npm install hexo-generator-feed --save 配置在网站的根目中的_config.yml文件设置 feed: type: atom path: atom.xml limit: 20 hub: content: type - Feed type. (atom/rss2)path - Feed path. (Default: atom.xml/rss2.xml)limit - Maximum number of posts in the feed (Use 0 or false to show all posts)hub - URL of the PubSubHubbub hubs (Leave it empty if you don’t use it)content - (optional) set to ‘true’ to include the contents of the entire post in the feed. 在hexo中实现本地搜索功能（hexo-generator-searchdb）安装 hexo-generator-searchdb，在站点的根目录下执行以下命令： npm install hexo-generator-searchdb --save 编辑 站点配置文件，新增以下内容到任意位置： search: path: search.xml field: post format: html limit: 10000 除了安装本地搜索，还可以考虑 swiftype 的搜索。 更换hexo主题Hexo有很多主题，可以在 Hexo官网的主题页面 选择自己喜欢。以Next为例，本站使用的就是Next主题。 使用Git来获取主题文件 git clone https://github.com/iissnan/hexo-theme-next themes/next 直接在Next的 GitHub主页 下载主题文件 将Next文件夹放到theme文件夹中，修改站点配置文件，也就是网站根目录下的_config.yml文件中的theme： # Extensions ## Plugins: https://hexo.io/plugins/ ## Themes: https://hexo.io/themes/ theme: next 上传到github如果你一切都配置好了，发布上传很容易，一句hexo d就搞定，当然关键还是你要把所有东西配置好。 首先，ssh key肯定要配置好。 创建SSH在gitbash中输入：ssh-keygen -t rsa -C &quot;youremail@example.com，生成ssh。然后按下面的方式找到id_rsa.pub文件的内容。 $ cd ~/.ssh/ $ ls id_rsa id_rsa.pub known_hosts $ cat id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC0avsgprEOmpE1yVnbU4hjireV3Ozxb5vFLl4KXgkVY9X3O78E5y10rSa9CHs4lFao/Gij3G/VuXAC/id0pY7ti/BD6CmY8etFlZun9Zw+7Z41gRRrFxreXGwFhzfJeu6CVGYSQgPMjgu1TCCO9wM1hwU41T/Nof3F2kDlRn0pxvmIAkGNy/E8dtB9alY7ObNyrMuACZX8k42STttlte6MlelBVckFyks5IwQ+WdBc0giZTlfXbrL455HiEXitN20FQDznFoX96+iBlAa/WTE2fqVlKY22t5rmyU//JQkFG9ttxAOinADzTLskysE3eWaiupvA0gAjRc4rr8Sg83gJ huangkuier@gmail.com 把id_rsa.pub文件的内容添加到github的ssh key中。 其次，配置_config.yml中有关deploy的部分： 正确写法： deploy: type: git repository: git@github.com:hunkier/hunkier.github.io.git branch: master 错误写法： deploy: type: github repository: https://github.com/hunkier/hunkier.github.io.git branch: master 后面一种写法是hexo2.x的写法，现在已经不行了，无论是哪种写法，此时直接执行hexo d的话一般会报如下错误： Deployer not found: github 或者 Deployer not found: git 原因是还需要安装一个插件： npm install hexo-deployer-git --save 其它命令不确定，部署这个命令一定要用git bash，否则会提示Permission denied (publickey). 打开你的git bash，输入hexo d就会将本次有改动的代码全部提交，没有改动的不会： 常用hexo命令常见命令 hexo new &quot;postName&quot; #新建文章 hexo new page &quot;pageName&quot; #新建页面 hexo generate #生成静态页面至public目录 hexo server #开启预览访问端口（默认端口4000，&#39;ctrl + c&#39;关闭server） hexo deploy #部署到GitHub hexo help # 查看帮助 hexo version #查看Hexo的版本 缩写： hexo n == hexo new hexo g == hexo generate hexo s == hexo server hexo d == hexo deploy 组合命令： hexo s -g #生成并本地预览 hexo d -g #生成并上传 使用其他端口命令： hexo s -p 5000 (node:13224) [DEP0061] DeprecationWarning: fs.SyncWriteStream is deprecated. INFO Start processing INFO Hexo is running at http://localhost:5000/. 4.11. _config.yml这里面都是一些全局配置，每个参数的意思都比较简单明了，所以就不作详细介绍了。 需要特别注意的地方是，冒号后面必须有一个空格，否则可能会出问题。 4.12. 写博客定位到我们的hexo根目录，执行命令： hexo new &#39;my-first-blog&#39; hexo会帮我们在_posts下生成相关md文件 当然你也可以直接自己新建md文件，用这个命令的好处是帮我们自动生成了时间。 一般完整格式如下： --- title: postName #文章页面上的显示名称，一般是中文 date: 2013-12-02 15:30:16 #文章生成时间，一般不改，当然也可以任意修改 categories: 默认分类 #分类 tags: [tag1,tag2,tag3] #文章标签，可空，多标签请用格式，注意:后面有个空格 description: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面 --- 以下是正文 那么hexo new page &#39;postName&#39;命令和hexo new &#39;postName&#39;有什么区别呢？ hexo new page &quot;my-second-blog&quot; 最终部署时生成：hexo\public\my-second-blog\index.html，但是它不会作为文章出现在博文目录。 写博客工具那么用什么工具写博客呢？这个我还没去找，以前自己使用editor.md简单弄了个，大家有好用的hexo写博客工具可以推荐个。 https://www.typora.io 如何让博文列表不显示全部内容默认情况下，生成的博文目录会显示全部的文章内容，如何设置文章摘要的长度呢？ 答案是在合适的位置加上&lt;!--more--&gt;即可，例如： # 前言 使用github pages服务搭建博客的好处有： 1. 全是静态文件，访问速度快； 2. 免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台； 3. 可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于github的； &lt;!--more--&gt; 4. 数据绝对安全，基于github的版本管理，想恢复到哪个历史版本都行； 5. 博客内容可以轻松打包、转移、发布到其它平台； 6. 等等；]]></content>
      <categories>
        <category>github</category>
        <category>blog</category>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>blog</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell脚本命令备忘]]></title>
    <url>%2FShell-notes%2F</url>
    <content type="text"><![CDATA[这里收藏工作中用到的脚本，也为了防止做重复的搜索工作，同时分享给大家。 数组 初始化数组name = (value1 value2 ... valuen) $ A=(a b c d) $ echo ${A[@]} # 输出所有元素 数组去重 $ array=($(awk -vRS=&#39; &#39; &#39;!a[$1]++&#39; &lt;&lt;&lt; ${array[@]})) 取得数组元素的个数 $ echo ${#A[@]} 取下标 $ echo ${A[1]} # 从1开始 清除元素 $ unset A $ echo ${A[@]} 循环取元素 $ for a in ${A[@]}; do $ echo &quot;$a&quot; $ done 替换 $ ${A[@]/3/100} date 获取当前日期并格式化成指定格式 $ NOW=$(date +&#39;%Y-%m-%d_%H%M%S&#39;) # 2016-09-07_184914 计算当前时间的时间戳 $ STAMP=$(($(date +%s -d &quot;$(date +&#39;%Y-%m-%d %H:%M:%S&#39;)&quot;))) # 1473245414 计算N天之前的时间 # 十天之前的日期 $ TEN_DAYS_AGO=$(($(date -d &#39;-10 day&#39; &quot;+%Y%m%d%H%M%S&quot;))) #20160828185138 获取xxxx年xx月的天数 # 获取 2016-10 的天数 $ cal 10 2016 | awk &#39;NF{out=$NF;}END{print out}&#39; 输出 31 vim vi/vim修改只读(readonly)文件，使用sudo修改:w !sudo tee % &gt; /dev/null awk 过滤数字 $ echo &quot;123&quot; |awk &#39;{if($0 ~ /^[0-9]+$/) print $0;}&#39; 数字求和 $ cat ${FILE} | awk &#39;{sum += $1};END {printf (&quot;%d\n&quot;, sum)}&#39; 截取字符串 $ echo &quot;123456&quot; | awk &#39;{print substr($1,1,4)}&#39; #1234 获取月份所在季度 $ for q in `seq 1 12`; echo $q | awk &#39;{season_least=$1%3} {season=$1/3} {if(season_least&gt;0) season+=1} {printf(&quot;%d\n&quot;,season)}&#39; 输出 1 1 1 2 2 2 3 3 3 4 4 4 删除所有空格 $ echo &quot;1 2 3 4&quot; | sed -e &#39;s/[[:space:]]//g &#39; 输出 1234 替换所有的.为/ $ echo &quot;com.xiongyingqi.Test&quot; | awk &#39;{gsub(/\./,&quot;/&quot;); print $0}&#39; 输出 com/xiongyingqi/Test sed 去除首尾空格 $ FOO_NO_EXTERNAL_SPACE=&quot;$(echo -e &quot;${FOO}&quot; | sed -e &#39;s/^[[:space:]]*//&#39; -e &#39;s/[[:space:]]*$//&#39;)&quot; 删除空行 $ sed &#39;/^$/d&#39; sources.list uniq 统计重复数$ cat file | uniq -c 文件 寻找有指定内容的文件 $ FOUND=&quot;test&quot; # 需要查找的内容 $ find . | while read file; do if [ -f $file ]; then content=`cat ${file} | grep &quot;${FOUND}&quot;`; if [ -n &quot;$content&quot; ]; then echo ${file} ; fi; fi; done 列举文件并用管道打包 $ find . -name &quot;*.class&quot; | xargs tar cvf classes.tar 批量重命名文件for file in `ls `;do mv $file `echo $file|sed &#39;s/aaa/bbb/g&#39;`;done; 变量我们先写一个简单的脚本，执行以后再解释各个变量的意义 $ touch variable $ vi variable 脚本内容如下： #!/bin/sh echo &quot;number:$#&quot; echo &quot;scname:$0&quot; echo &quot;first :$1&quot; echo &quot;second:$2&quot; echo &quot;argume:$@&quot; echo &quot;show parm list:$*&quot; echo &quot;show process id:$$&quot; echo &quot;show precomm stat: $?&quot; 保存退出 赋予脚本执行权限 $ chmod +x variable 执行脚本 $ ./variable aa bb 输出 number:2 scname:./variable first:aa second:bb argume:aa bb show parm list:aa bb show process id:24544 show precomm stat:0 通过显示结果可以看到： $# 是传给脚本的参数个数 $0 是脚本本身的名字 $1 是传递给该shell脚本的第一个参数 $2 是传递给该shell脚本的第二个参数 $@ 是传给脚本的所有参数的列表 $* 是以一个单字符串显示所有向脚本传递的参数，与位置变量不同，参数可超过9个 $$ 是脚本运行的当前进程ID号 $? 是显示最后命令的退出状态，0表示没有错误，其他表示有错误 例子 *amount.txt 下所有文件的第8列数字之和 iconv -fgbk 为转换文件为 gbk ls *amount.txt | while read file; do cat ${file}; done | iconv -fgbk | awk -F &quot;\t&quot; &#39;{print $8}&#39; | awk &#39;{if($0 ~ /^[0-9]+$/) print $0;}&#39; | awk &#39;{sum += $1};END {printf (&quot;%d\n&quot;, sum)}&#39; 将目录下的jar文件转换为maven格式的依赖 #!/bin/bash find . -name &quot;*.jar&quot; | while read jar; do artifact=`echo ${jar} | awk &#39;{print substr($jar,1,length($jar)-4);}&#39;` version=`echo &quot;$artifact&quot; | awk -F &#39;-&#39; &#39; { print $NF } &#39;` if [ $version == $artifact ]; then version=&quot;1.0&quot; else artifact=`echo &quot;$artifact&quot; | awk -v version=&quot;$version&quot; &#39;{print substr($1,1,index($1,version)-2)}&#39;` fi # find group groupDirectory=`jar -tf $jar | grep &quot;.class&quot; | head -n 1` last=`echo &quot;$groupDirectory&quot; | awk -F &#39;/&#39; &#39; { print $NF } &#39;` group=`echo &quot;$groupDirectory&quot; | awk -v last=&quot;$last&quot; &#39;{print substr($1,1,index($1,last)-2)}&#39;` # replace / to . group=`echo $group | awk &#39;{gsub(/\//,&quot;.&quot;); print $0}&#39;` echo &quot; &lt;dependency&gt; &lt;groupId&gt;${group}&lt;/groupId&gt; &lt;artifactId&gt;${artifact}&lt;/artifactId&gt; &lt;version&gt;${version}&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;\${project.basedir}/lib/${jar}&lt;/systemPath&gt; &lt;/dependency&gt;&quot; #&gt;&gt; &quot;dependencies.tmp&quot; done 查找java类所在当前目录内的jar包 $ FOUND=&quot;com.xiongyingqi.Test&quot; &amp;&amp; ls *.jar | while read jar; do jar tf $jar | grep `echo &quot;${FOUND}&quot; | awk &#39;{gsub(/\./,&quot;/&quot;); print $0}&#39;` | awk -v jar=&quot;$jar&quot; &#39;{if (length($1) &gt; 0) print jar}&#39;; done 将目录内的文件转换为classpath需要的参数 ls lib/*.jar | xargs | awk -v d=&quot;${delete}&quot; &#39;{ str=&quot;&quot;; is_in=0; for(i=1;i&lt;=NF;i++){ if($i!=d){ if(is_in == 1){ str=str&quot;:&quot;$i; }else{ str=str&quot;&quot;$i; is_in=1; } } } print str }&#39; 查找某个目录下所有的jar包里面有哪些class是冲突的shell脚本 #!bin/bash echo &quot;Find out conflict class in the given path&quot;; if [ $# != 1 ] ; then echo &quot;Usage: sh findconflictclass.sh $1 ,first param means the path you want to find,eg: sh findconflictclass.sh lib&quot;; exit 1; fifindconflictclass.sh echo &quot;Please wait ...&quot;; jarpath=$1; function unjarclass(){ for i in `find $jarpath -name *.jar`; do jar -tvf &quot;$i&quot; |grep .class$ | awk &#39;{print $8}&#39; ; # if [[ $? == 0 ]]; then echo $i; fi; done } unjarclass 1&gt;temp.txt; echo &#39;unjar class in the given path has done&#39;; sleep 10s function findclassinjar(){ echo -e &quot;\033[47;31m &#39;The class $1 exists in multi-place below:&#39; \033[0m&quot; ; for i in `find $2 -name *.jar`; do jar -tvf &quot;$i&quot; | grep --color -i &quot;$1&quot; ; if [[ $? == 0 ]]; then echo -e &quot;\033[33m &#39;The jar path is: $i&#39; \033[0m&quot; ; fi; done } sort temp.txt | uniq -d | cat | while read line; do a=$line; findclassinjar $a $jarpath;done rm -rf temp.txt 替换字符串 $ data=&quot;a&quot; &amp;&amp; newdata=&quot;c&quot; &amp;&amp; echo &quot;aaabbba&quot;|awk -v var=${1} -v var1=${data} -v var2=${newdata} &#39;$0 ~ var {gsub(var1,var2); print}&#39; 输出 cccbbbc 文件内容替换替换当前目录下的所有文件内容中的hello为helloworld find . -type f | while read file; do sed -i &#39;s/hello/helloworld/g&#39; $file;done 测试curl $ size=1000;i=0; while [ $i -lt $size ];do i=$((i+1)); curl &quot;http://baidu.com&quot; &amp; done 获取从开始日期到结束日期所经历过的季度 FROM_DATE=&quot;$1&quot; TO_DATE=&quot;$2&quot; FROM_SEASON=`echo &quot;${FROM_DATE}&quot; | awk -F &quot;-&quot; &#39;{print $2}&#39;| awk &#39;{season_least=$1%3} {season=$1/3} {if(season_least&gt;0) season+=1} {printf(&quot;%d\n&quot;,season)}&#39;` TO_SEASON=`echo &quot;${TO_DATE}&quot; | awk -F &quot;-&quot; &#39;{print $2}&#39;| awk &#39;{season_least=$1%3} {season=$1/3} {if(season_least&gt;0) season+=1} {printf(&quot;%d\n&quot;,season)}&#39;` echo &quot;FROM_SEASON: ${FROM_SEASON}&quot; echo &quot;TO_SEASON: ${TO_SEASON}&quot; FROM_YEAR=`echo &quot;${FROM_DATE}&quot; | awk -F &quot;-&quot; &#39;{print $1}&#39;` TO_YEAR=`echo &quot;${TO_DATE}&quot; | awk -F &quot;-&quot; &#39;{print $1}&#39;` year_season_file=&quot;year_season.tmp&quot; if [ -f ${year_season_file} ];then echo &quot;delete file: ${year_season_file}&quot; rm -f ${year_season_file} fi if [ ${FROM_YEAR} -eq ${TO_YEAR} ]; then for season in `seq ${FROM_SEASON} ${TO_SEASON}`; do echo &quot;${FROM_YEAR}Q${season}&quot; &gt;&gt; ${year_season_file} done else for season in `seq ${FROM_SEASON} 4`; do echo &quot;${FROM_YEAR}Q${season}&quot; &gt;&gt; ${year_season_file} done #FROM_YEAR if [ $((TO_YEAR-FROM_YEAR)) -ge 2 ]; then for year in `seq $((FROM_YEAR+1)) $((TO_YEAR-1))`; do for season in `seq 1 4`; do echo &quot;${year}Q${season}&quot; &gt;&gt; ${year_season_file} done done fi for season in `seq 1 ${TO_SEASON}`; do echo &quot;${TO_YEAR}Q${season}&quot; &gt;&gt; ${year_season_file} done fi cat ${year_season_file} 多线程访问 for ((i=0;i&lt;10;)); do for j in `seq 1 100`; do curl &quot;http://baidu.com&quot; &amp; done; wait; i=$((i+1)); done 按列合并 cat filtsoort | awk &#39;{sum[$1]+=$2}END{for (i in sum) print i&quot; &quot;sum[i]}&#39; 转换编码 find . -name &quot;*.java&quot; | while read file; do iconv -f gbk -t utf-8 $file &gt; ${file}.bak; mv -f ${file}.bak $file; done word转换为markdown需要先安装w2m: benbalter/word-to-markdown find doc -name &quot;*.doc&quot; | while read file; do folder_tmp=&quot;markdown/$file&quot;; folder=${folder_tmp%/*}; target_file=&quot;${folder_tmp%%.*}&quot;.md mkdir -p $folder; w2m $file &gt; $target_file; done 移除base64图像 sed -i &#39;s-\!\[\](data:image\/\*;base64,.*)--g&#39; $file 判断是否为asccii字符串（英文字符） echo &quot;呵呵&quot; | awk &#39;{ print (length($0)&gt;NF)}&#39; #1 输出带颜色的字符shell脚本中echo显示内容带颜色显示,echo显示带颜色，需要使用参数-e格式如下： echo -e &quot;\033[字背景颜色；文字颜色m字符串\033[0m&quot; 例如： echo -e &quot;\033[41;36m something here \033[0m&quot; 其中41的位置代表底色， 36的位置是代表字的颜色 注：1、字背景颜色和文字颜色之间是英文的””2、文字颜色后面有个m3、字符串前后可以没有空格，如果有的话，输出也是同样有空格 下面是相应的字和背景颜色，可以自己来尝试找出不同颜色搭配例 echo -e &quot;\033[31m 红色字 \033[0m&quot; echo -e &quot;\033[34m 黄色字 \033[0m&quot; echo -e &quot;\033[41;33m 红底黄字 \033[0m&quot; echo -e &quot;\033[41;37m 红底白字 \033[0m&quot; 字颜色：30—–37 echo -e &quot;\033[30m 黑色字 \033[0m&quot; echo -e &quot;\033[31m 红色字 \033[0m&quot; echo -e &quot;\033[32m 绿色字 \033[0m&quot; echo -e &quot;\033[33m 黄色字 \033[0m&quot; echo -e &quot;\033[34m 蓝色字 \033[0m&quot; echo -e &quot;\033[35m 紫色字 \033[0m&quot; echo -e &quot;\033[36m 天蓝字 \033[0m&quot; echo -e &quot;\033[37m 白色字 \033[0m&quot; 字背景颜色范围：40—–47 echo -e &quot;\033[40;37m 黑底白字 \033[0m&quot; echo -e &quot;\033[41;37m 红底白字 \033[0m&quot; echo -e &quot;\033[42;37m 绿底白字 \033[0m&quot; echo -e &quot;\033[43;37m 黄底白字 \033[0m&quot; echo -e &quot;\033[44;37m 蓝底白字 \033[0m&quot; echo -e &quot;\033[45;37m 紫底白字 \033[0m&quot; echo -e &quot;\033[46;37m 天蓝底白字 \033[0m&quot; echo -e &quot;\033[47;30m 白底黑字 \033[0m&quot; 最后面控制选项说明 \33[0m 关闭所有属性 \33[1m 设置高亮度 \33[4m 下划线 \33[5m 闪烁 \33[7m 反显 \33[8m 消隐 \33[30m — \33[37m 设置前景色 \33[40m — \33[47m 设置背景色 \33[nA 光标上移n行 \33[nB 光标下移n行 \33[nC 光标右移n行 \33[nD 光标左移n行 \33[y;xH设置光标位置 \33[2J 清屏 \33[K 清除从光标到行尾的内容 \33[s 保存光标位置 \33[u 恢复光标位置 \33[?25l 隐藏光标 \33[?25h 显示光标 function echoGreen(){ echo -e &quot;\033[32m$1\033[0m&quot; } function echoRed(){ echo -e &quot;\033[31m$1\033[0m&quot; } function echoYellow(){ echo -e &quot;\033[33m$1\033[0m&quot; } 从第二行开始显示cat file | awk &#39;NR&gt;2{print p}{p=$0}&#39;]]></content>
      <tags>
        <tag>shell</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[加微信好友]]></title>
    <url>%2FMy-wechat%2F</url>
    <content type="text"><![CDATA[打开微信，扫一扫加微信好友]]></content>
      <categories>
        <category>github</category>
        <category>hexo</category>
        <category>wechat</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>hexo</tag>
        <tag>wechat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Hosted by Coding Pages Quick StartCreate a new post$ hexo new &quot;My New Post&quot; More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>github</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
