<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[使用 https 协议部署博客]]></title>
    <url>%2Fdeploy-blog-with-https%2F</url>
    <content type="text"><![CDATA[前言https 成为互联网标配，自然得跟上，给自己的博客用加密版的传输协议 https。 首先需要一个域名和一台拥有固定外网 ip 的服务器，使域名可以解析到该服务器上。caddy 可以自动能够向 Let’s Encrypt 申请和续期免费证书，有效期为 3 个月， 到期后自动续期。 博客源码托管在 GitHub，因此需要先安装 git yum install -y git 安装 caddy curl https://getcaddy.com | bash -s personal http.git,http.cors,http.forwardproxy,http.authz,hook.service,dns 添加 caddy 到系统服务 vi /etc/init.d/caddy 写入内容 #!/bin/bash ### BEGIN INIT INFO # Provides: Caddy # Required-Start: $network $local_fs $remote_fs # Required-Stop: $network $local_fs $remote_fs # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: The HTTP/2 web server with automatic HTTPS # Description: Start or stop the Caddy server ### END INIT INFO NAME=&quot;Caddy&quot; NAME_BIN=&quot;caddy&quot; BIN=&quot;/usr/local/bin/caddy&quot; if [ -f &quot;/usr/local/caddy/Caddyfile&quot; ]; then CONF=&quot;/usr/local/caddy/Caddyfile&quot; elif [ -f &quot;/etc/caddy/Caddyfile&quot; ]; then CONF=&quot;/etc/caddy/Caddyfile&quot; fi Info_font_prefix=&quot;\033[32m&quot; &amp;&amp; Error_font_prefix=&quot;\033[31m&quot; &amp;&amp; Info_background_prefix=&quot;\033[42;37m&quot; &amp;&amp; Error_background_prefix=&quot;\033[41;37m&quot; &amp;&amp; Font_suffix=&quot;\033[0m&quot; RETVAL=0 check_running(){ PID=`ps -ef |grep &quot;${NAME_BIN}&quot; |grep -v &quot;grep&quot; |grep -v &quot;init.d&quot; |grep -v &quot;service&quot; |awk &#39;{print $2}&#39;` if [[ ! -z ${PID} ]]; then return 0 else return 1 fi } do_start(){ check_running if [[ $? -eq 0 ]]; then echo -e &quot;${Info_font_prefix}[信息]${Font_suffix} $NAME (PID ${PID}) 正在运行...&quot; &amp;&amp; exit 0 else ulimit -n 51200 nohup &quot;$BIN&quot; --conf=&quot;$CONF&quot; -agree &gt;&gt; /tmp/caddy.log 2&gt;&amp;1 &amp; sleep 2s check_running if [[ $? -eq 0 ]]; then echo -e &quot;${Info_font_prefix}[信息]${Font_suffix} $NAME 启动成功 !&quot; else echo -e &quot;${Error_font_prefix}[错误]${Font_suffix} $NAME 启动失败 !&quot; fi fi } do_stop(){ check_running if [[ $? -eq 0 ]]; then kill -9 ${PID} RETVAL=$? if [[ $RETVAL -eq 0 ]]; then echo -e &quot;${Info_font_prefix}[信息]${Font_suffix} $NAME 停止成功 !&quot; else echo -e &quot;${Error_font_prefix}[错误]${Font_suffix}$NAME 停止失败 !&quot; fi else echo -e &quot;${Info_font_prefix}[信息]${Font_suffix} $NAME 未运行 !&quot; RETVAL=1 fi } do_status(){ check_running if [[ $? -eq 0 ]]; then echo -e &quot;${Info_font_prefix}[信息]${Font_suffix} $NAME (PID ${PID}) 正在运行...&quot; else echo -e &quot;${Info_font_prefix}[信息]${Font_suffix} $NAME 未运行 !&quot; RETVAL=1 fi } do_tail(){ tail -100f /tmp/caddy.log } do_restart(){ do_stop do_start } do_console(){ do_start do_tail } case &quot;$1&quot; in start|stop|restart|status|console|tail) do_$1 ;; *) echo &quot;使用方法: $0 { start | stop | restart | status | console | tail }&quot; RETVAL=1 ;; esac exit $RETVAL 更改权限，加入开机自启动 chmod 755 /etc/init.d/caddy chkconfig caddy on 编辑配置文件 vi /usr/local/caddy/Caddyfile caddyfile 文件内容 # 配置文件分开存放 import vhost/*.conf 具体配置文件 vi /usr/local/caddy/vhosts/hunkier.cn.conf 这里的代码仓库是开放的，若是私有项目，请自行查阅相关资料。 文件内容 hunkier.cn www.hunkier.cn { # web 页面存放路径 root /var/www/hunkier/ # 配置错误页面，所有错误都显示 404.html 页面 errors { * 404.html } # 启用压缩 gzip # 用来申请及更新 https 证书的邮箱，前提是 hunkier.cn 的域名能解析到 本机 tls huangkuier@gmail.com git github.com/hunkier/hunkier.github.io { # git clone 的目标路径 path /var/www/hunkier # 使用 webhook 触发自动部署， # GitHub 项目的 setting -&gt; Webhooks 页 Add webhook # Payload URL 为 https://hunkier.cn/webhook # Content type 为 application/json # Cecret 为 GitHubSecretKey hook /webhook GitHubSecretKey hook_type github clone_args --recursive pull_args --recurse-submodules } } 创建目录 mkdir -p /var/www/hunkier 解除链接文件限制 ulimit -n 8192 也可以使用 caddy 用作代理服务器用来科学上网（你懂得^_^） vi /usr/local/caddy/vhost/xxx.hunkier.cn.conf 文件 xxx.hunkier.cn.conf 内容如下： xxx.hunkier.cn { # 伪装成正常的网站 root /var/www/hunkier/ # 配置错误页面，所有错误都显示 404.html 页面 errors { * 404.html } # 开启压缩 gzip # 使用邮箱申请和续期证书 tls huangkuier@gmail.com # http 代理设置 forwardproxy { hide_ip hide_via # 使用 basic 认证 basicauth user1 passwd1 basicauth user2 passwd2 basicauth user3 passwd3 } } 此时 caddy 被用作 web 服务器和代理服务器，协议转换推荐使用gost 。 caddy 服务 启动/停止/重启/检查状态 service caddy start/stop/restart/status 启动成功后可以在浏览器里面正常访问 https://hunkier.cn 若启动失败，查看日志 tail -100f /tmp/caddy.log]]></content>
      <categories>
        <category>https</category>
        <category>blog</category>
        <category>caddy</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>https</tag>
        <tag>caddy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 修改时区、设置时间]]></title>
    <url>%2FCentOS-chanage-date-zone%2F</url>
    <content type="text"><![CDATA[一、修改时区： 方法1: cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 方法2： 列出时区： timedatectl list-timezones 设置时区： timedatectl set-timezone Asia/Shanghai 方法3：使用 tzselect 查看是否修改成功： date Fri Dec 14 10:48:05 CST 2018 如果显示CST则说明时区设置成功 CST：中国标准时间（China Standard Time），这个解释可能是针对RedHat Linux。 UTC：协调世界时，又称世界标准时间，简称UTC，从英文国际时间/法文协调时间”Universal Time/Temps Cordonn&eacute;”而来。中国大陆、香港、澳门、台湾、蒙古国、新加坡、马来西亚、菲律宾、澳洲西部的时间与UTC的时差均为+8，也就是UTC+8。 GMT：格林尼治标准时间（旧译格林威治平均时间或格林威治标准时间；英语：Greenwich Mean Time，GMT）是指位于英国伦敦郊区的皇家格林尼治天文台的标准时间，因为本初子午线被定义在通过那里的经线。 设置完系统时间后,还需要同步到硬件时钟上 二、查看和修改时间 1.显示时间 ： date 2.修改时间 date -s 时间 如：设置当前时间为：2018年12月10点50分 date -s ‘2018-12-14 10:50:00’ 3.根据网络同步时间 使用ntp同步标准时间，ntp：网络时间协议（network time protol） 安装：yum install ntp 同步：ntpdate pool.ntp.org]]></content>
      <categories>
        <category>centos</category>
        <category>date</category>
        <category>timezone</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>date</tag>
        <tag>timezone</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 安装 cockpit 管理系统]]></title>
    <url>%2FCentOS-install-mamager-cockpit%2F</url>
    <content type="text"><![CDATA[Cockpit 是一个基于 Web 界面的应用，它提供了对系统的图形化管理。 拥有如下功能： 监控系统活动（CPU、内存、磁盘 IO 和网络流量） —— 系统 查看系统日志条目 —— 日志 查看磁盘分区的容量 —— 存储 查看网络活动（发送和接收） —— 网络 查看用户帐户 —— 帐户 检查系统服务的状态 —— 服务 提取已安装应用的信息 —— 应用 查看和安装可用更新（如果以 root 身份登录）并在需要时重新启动系统 —— 软件更新 打开并使用终端窗口 —— 终端 安装cockpit yum -y install cockpit yum install cockpit* -y #所有cockpit模块安装 修改默认端口9090 vi /usr/lib/systemd/system/cockpit.socket 启动cockpit systemctl start cockpit 开机自启动 vi /usr/lib/systemd/system/cockpit.service # 在最后加上下面两行 [Install] WantedBy=multi-user.target # 退出编辑，加入系统启动 systemctl enable cockpit 防火墙配置 firewall-cmd --add-port=9090/tcp --permanent firewall-cmd --reload 登录在任意浏览器输入IP地址+端口号（https://ip:9090）]]></content>
      <categories>
        <category>Linux</category>
        <category>cockpit</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>cockpit</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计数排序]]></title>
    <url>%2Falgorithm-radix-sort%2F</url>
    <content type="text"><![CDATA[将所有待比较数值 （正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后，数列就变成一个有序序列。 public class RadixSort { int[] a ={49,38,65,97,76,13,27,49,78,34,12,64,5,4,62,99,98,54,101,56,17,18,23,34,15,35,25,53,51}; public void radixSort(){ sort(a); for(int i=0; i&lt;a.length; i++){ System.out.println(a[i]); } } public void sort(int[] array){ // 首先确定排序的趟数； int max = array[0]; for(int i=1; i&lt;array.length; i++){ if(array[i]&gt;max){ max = array[i]; } } int time = 0; // 判断位数； while(max &gt;0){ max/=10; time++; } // 建立 10 个队列 List&lt;ArrayList&gt; queue = new ArrayList&lt;ArrayList&gt;(); for(int i = 0 ; i &lt; 10 ; i++){ ArrayList&lt;Integer&gt; queue1 = new ArrayList&lt;Integer&gt;(); queue.add(queue1); } // 进行 time 次分配和收集 for(int i =0; i&lt; time; i++){ // 分配数组元素 for(int j=0; j&lt;array.length; j++){ // 得到数字的第 time+1 位数 int x = array[j]%(int)Math.pow(10,i+1)/(int)Math.pow(10,i); ArrayList&lt;Integer&gt; queue2 = queue.get(x); queue2.add(array[j]); queue.set(x,queue2); } } // 元素计数器； int count = 0 ; for(int k = 0; k &lt; 10; k++){ while(queue.get(k).size()&gt;0){ ArrayList&lt;Integer&gt; queue3 = queue.get(k); array[count] = queue3.get(0); queue3.remove(0); count++; } } } }]]></content>
      <categories>
        <category>java</category>
        <category>algorithm</category>
        <category>radix sort</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>algorithm</tag>
        <tag>radix sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[桶排序]]></title>
    <url>%2Falgorithm-bucket-sort%2F</url>
    <content type="text"><![CDATA[桶排序的基本思想是：把数组 arr 划分为 n 个大小相同子区间 (桶), 每个子区间各自排序，最后合并。计数排序是桶排序的一种特殊情况，可以把计数排序当成每个桶里面只有一个元素的情况。 找出待排序数组中的最大值 max、最小值 min 我们使用 动态数组 ArrayList 作为桶，桶里放的元素也用 ArrayList 存储。桶的数量为 (max-min)/arr.length+1 遍历数组 arr，计算每个元素 arr[i] 放的桶 每个桶各自排序 public static void bucketSort(int[] arr){ int max = Interger.MIN_VALUE; int min = Integer.MAX_VALUE; for(int i = 0; i&lt;arr.length; i++){ max = Math.max(max,arr[i]); min = Math.min(min,arr[i]); } // 创建桶 int bucketNum = (max-min)/arr.length +1; ArrayList&lt;ArrayList&lt;Interger&gt;&gt; bucketArr = new ArrayList&lt;&gt;(bucketNum); for(int i = 0 ;i &lt; bucketNum; i++){ bucketArr.add(new ArrayList&lt;Integer&gt;()); } // 将每个元素放入桶 for(int i = 0 ; i&lt;arr.length; i++){ int num = (arr[i] - min) / (arr.length); bucketArr.get(num).add(arr[i]); } // 对每个桶进行排序 for(int i = 0 ; i&lt;bucketArr.size(); i++){ Collections.sort(bucketArr.get(i)); } }]]></content>
      <categories>
        <category>java</category>
        <category>algorithm</category>
        <category>bucket sort</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>algorithm</tag>
        <tag>bucket sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 下使用 Percona XtraBackup 备份和恢复 MySQL5.7]]></title>
    <url>%2FPercona-XtraBackup-MySQL5-7%2F</url>
    <content type="text"><![CDATA[一、概述XtraBackup 是 Percona 开源的免费数据库热备份软件，它能对InnoDB数据库和XtraDB存储引擎的数据库非阻塞地备份（对于MyISAM的备份同样需要加表锁）；mysqldump备份方式是采用的逻辑备份，其最大的缺陷是备份和恢复速度较慢，如果数据库大于50G，mysqldump备份就不太适合。 mysqldump优缺点优点使用场景：10G以下的数据库操作简单 缺点数据量范围：30G –&gt; TB级别 的时候备份、恢复操作很慢，效率低 xtrabackup备份软件使用场景：1、数据量大，变换量小2、数据量小，变化量大 Xtrabackup安装完成后有4个可执行文件，其中2个比较重要的备份工具是innobackupex、xtrabackup 1）xtrabackup 是专门用来备份InnoDB表的，和mysql server没有交互；2）innobackupex 是一个封装xtrabackup的Perl脚本，支持同时备份innodb和myisam，但在对myisam备份时需要加一个全局的读锁。3）xbcrypt 加密解密备份工具4）xbstream 流传打包传输工具，类似tar5）物理备份工具，在同级数据量基础上，都要比逻辑备份性能好的多，特别是在数据量较大的时候，体现的更加明显。 Xtrabackup优点1）备份速度快，物理备份可靠 2）备份过程不会打断正在执行的事务（无需锁表） 3）能够基于压缩等功能节约磁盘空间和流量 4）自动备份校验 5）还原速度快 6）可以流传将备份传输到另外一台机器上 7）在不增加服务器负载的情况备份数据 8）物理备份工具，在同级数据量基础上，都要比逻辑备份性能要好的多。几十G到不超过TB级别的条件下。但在同数据量级别，物理备份恢复数据上有一定优势。 备份原理拷贝数据文件、拷贝数据页 对于innodb表可以实现热备。 (1) 在数据库还有修改操作的时刻，直接将数据文件备走，此时，备份走的数据对于当前mysql来讲是不一致的。(2) 将备份过程中的redo和undo一并备走。(3) 为了恢复的时候，只要保证备份出来的数据页lsn能和redo lsn匹配，将来恢复的就是一致的数据。redo应用和undo应用。 对于myisam表实现自动锁表拷贝文件。 备份开始时首先会开启一个后台检测进程，实时检测mysql redo的变化，一旦发现有新的日志写入，立刻将日志记入后台日志文件xtrabackup_log中，之后复制innodb的数据文件一系统表空间文件ibdatax，复制结束后，将执行flush tables with readlock,然后复制.frm MYI MYD等文件，最后执行unlock tables,最终停止xtrabackup_log 二、背景最近公司上线一个新项目，使用用 DELL 单片机和磁盘阵列，配置如下 名称 配置 操作系统 CentOS 7.7 x64 主机地址 172.20.8.132 主机名称 localhost MySQL 版本 5.7.28 XtraBack 版本 2.4.16 三、安装按照官网文档，通用 yum 在线方式安装，步骤如下： 安装 Percona 的 yum 仓库，使用 root 账号执行下面命令：[root@localhost ~]# yum install https://repo.percona.com/yum/percona-release-latest.noarch.rpm Loaded plugins: fastestmirror, langpacks percona-release-latest.noarch.rpm | 17 kB 00:00:00 Examining /var/tmp/yum-root-1mopyU/percona-release-latest.noarch.rpm: percona-release-1.0-13.noarch Marking /var/tmp/yum-root-1mopyU/percona-release-latest.noarch.rpm to be installed Resolving Dependencies --&gt; Running transaction check ---&gt; Package percona-release.noarch 0:1.0-13 will be installed --&gt; Finished Dependency Resolution Dependencies Resolved ================================================================================================================================================ Package Arch Version Repository Size ================================================================================================================================================ Installing: percona-release noarch 1.0-13 /percona-release-latest.noarch 20 k Transaction Summary ================================================================================================================================================ Install 1 Package Total size: 20 k Installed size: 20 k Is this ok [y/d/N]: y Downloading packages: Running transaction check Running transaction test Transaction test succeeded Running transaction Installing : percona-release-1.0-13.noarch 1/1 * Enabling the Percona Original repository &lt;*&gt; All done! The percona-release package now contains a percona-release script that can enable additional repositories for our newer products. For example, to enable the Percona Server 8.0 repository use: percona-release setup ps80 Note: To avoid conflicts with older product versions, the percona-release setup command may disable our original repository for some products. For more information, please visit: https://www.percona.com/doc/percona-repo-config/percona-release.html Verifying : percona-release-1.0-13.noarch 1/1 Installed: percona-release.noarch 0:1.0-13 Complete! 启用 Percona 的 yum 仓库 [root@localhost ~]# percona-release enable-only tools release * Disabling all Percona Repositories * Enabling the Percona Tools repository &lt;*&gt; All done! 安装 Percona XtraBackup[root@localhost databases]# yum list | grep percona percona-release.noarch 1.0-13 @/percona-release-latest.noarch percona-backup-mongodb.x86_64 1.0.0-1.el7 tools-release-x86_64 percona-mysql-shell.x86_64 8.0.15-1.el7 tools-release-x86_64 percona-mysql-shell-debuginfo.x86_64 8.0.15-1.el7 tools-release-x86_64 percona-toolkit.x86_64 3.1.0-2.el7 tools-release-x86_64 percona-toolkit-debuginfo.x86_64 3.0.13-1.el7 tools-release-x86_64 percona-xtrabackup-24.x86_64 2.4.16-1.el7 tools-release-x86_64 percona-xtrabackup-24-debuginfo.x86_64 2.4.16-1.el7 tools-release-x86_64 percona-xtrabackup-80.x86_64 8.0.8-1.el7 tools-release-x86_64 percona-xtrabackup-80-debuginfo.x86_64 8.0.8-1.el7 tools-release-x86_64 percona-xtrabackup-test-24.x86_64 2.4.16-1.el7 tools-release-x86_64 percona-xtrabackup-test-80.x86_64 8.0.8-1.el7 tools-release-x86_64 [root@localhost databases]# yum install -y percona-xtrabackup-24.x86_64 Loaded plugins: fastestmirror, langpacks Loading mirror speeds from cached hostfile * base: mirrors.tuna.tsinghua.edu.cn * extras: mirrors.cqu.edu.cn * updates: mirrors.cqu.edu.cn Resolving Dependencies --&gt; Running transaction check ---&gt; Package percona-xtrabackup-24.x86_64 0:2.4.16-1.el7 will be installed --&gt; Finished Dependency Resolution Dependencies Resolved ================================================================================================================================================ Package Arch Version Repository Size ================================================================================================================================================ Installing: percona-xtrabackup-24 x86_64 2.4.16-1.el7 tools-release-x86_64 7.6 M Transaction Summary ================================================================================================================================================ Install 1 Package Total download size: 7.6 M Installed size: 7.6 M Downloading packages: percona-xtrabackup-24-2.4.16-1.el7.x86_64.rpm | 7.6 MB 00:01:49 Running transaction check Running transaction test Transaction test succeeded Running transaction Installing : percona-xtrabackup-24-2.4.16-1.el7.x86_64 1/1 Verifying : percona-xtrabackup-24-2.4.16-1.el7.x86_64 1/1 Installed: percona-xtrabackup-24.x86_64 0:2.4.16-1.el7 Complete! 若要删除 Percona XtraBackup ，使用 root 账号或者 sudo 执行： [root@localhost databases]# rpm -qa|grep percona percona-xtrabackup-80-8.0.8-1.el7.x86_64 percona-release-1.0-13.noarch [root@localhost databases]# yum remove percona-xtrabackup-80-8.0.8-1.el7.x86_64 Loaded plugins: fastestmirror, langpacks Resolving Dependencies --&gt; Running transaction check ---&gt; Package percona-xtrabackup-80.x86_64 0:8.0.8-1.el7 will be erased --&gt; Finished Dependency Resolution Dependencies Resolved ================================================================================================================================================ Package Arch Version Repository Size ================================================================================================================================================ Removing: percona-xtrabackup-80 x86_64 8.0.8-1.el7 @tools-release-x86_64 54 M Transaction Summary ================================================================================================================================================ Remove 1 Package Installed size: 54 M Is this ok [y/N]: y Downloading packages: Running transaction check Running transaction test Transaction test succeeded Running transaction Erasing : percona-xtrabackup-80-8.0.8-1.el7.x86_64 1/1 Verifying : percona-xtrabackup-80-8.0.8-1.el7.x86_64 1/1 Removed: percona-xtrabackup-80.x86_64 0:8.0.8-1.el7 Complete! 检查是否成功安装 Percona XtraBackup[root@localhost databases]# xtrabackup -v xtrabackup: recognized server arguments: --datadir=/data1/databases/mysql/data xtrabackup version 2.4.16 based on MySQL server 5.7.26 Linux (x86_64) (revision id: c807cfa) xtrabackup实践操作全量备份 innobackupex --defaults-file=/etc/my.cnf --host=127.0.0.1 --user=root --password=123456 /data1/databases/backup/xfull/ 查看备份 [root@localhost databases]# ls /data1/databases/backup/xfull/ -lh total 4.0K drwxr-x---. 5 root root 4.0K Nov 28 22:08 2019-11-28_22-02-20 恢复 service mysql stop innobackupex --apply-log /data1/databases/backup/xfull/2019-11-28_22-02-20/ rm /data1/databases/mysql/data -rf innobackupex --defaults-file=/etc/my.cnf --copy-back /backup/xfull//data1/databases/backup/xfull/2019-11-28_22-02-20/ chown -R mysql.mysql /data1/databases/mysql/ service mysql start 增量备份与恢复innobackupex增量备份过程中的”增量”处理，其实主要是相对innodb而言，对myisam和其他存储引擎而言，它仍然是全拷贝(全备份)增量备份从哪增量？基于上一次的备份进行增量。redo默认情况下是一组两个文件，并且有固定大小。其使用的文件是一种轮询使用方式，他不是永久的，文件随时可能被覆盖。 注意：千万不要在业务繁忙时做备份。 备份什么内容？ 1、可以使用binlog作为增量 2、自带的增量备份，基于上次备份后的变化的数据页，还要备份在备份过程中的undo、redo变化 操作1、先进行第一次全备 innobackupex --defaults-file=/etc/my.cnf --host=127.0.0.1 --user=root --password=123456 /data1/databases/backup/xfull/ 2、再进行增量备份。这个是在全备的基础上做的，需要指定全量备份的目录：/data1/databases/backup/xfull/ ；增量备份到 /data1/databases/backup//xinc1 innobackupex --defaults-file=/etc/my.cnf --host=127.0.0.1 --user=root --password=123456 --incremental --incremental-basedir=/data1/databases/backup/xfull/2019-11-28_22-02-20/ /data1/databases/backup//xinc1 恢复1、先应用全备日志 innobackupex --apply-log --redo-only /data1/databases/backup/xfull/2019-11-28_22-02-20/ 2、合并增量到全备中（一致性的合并） innobackupex --apply-log --incremental-dir=/data1/databases/backup/xinc1/2019-11-28_22-22-57/ /data1/databases/backup/xfull/2019-11-28_22-02-20/ innobackupex --apply-log /data1/databases/backup/xfull/2019-11-28_22-02-20/ 3、合并完成进行恢复使用innobackupex命令进行恢复(推荐) innobackupex --defaults-file=/etc/my.cnf --copy-back /data1/databases/backup/xfull/2019-11-28_22-02-20/ chown -R mysql.mysql /data1/databases/mysql/ 数据库备份策略每周的周日进行一次全备；周一到周六每天做上一天增量，每周轮询一次。备份方案： xtrabackup全备+增量 备份策略（crontab）： crontab -e # 每周一的凌晨3点执行完全备份 0 3 * * 1 /data1/databases/shell/allbak.sh &gt;/dev/null vim /root/allbak.sh #!/bin/bash tmpPath=/data1/databases/backup/xfull compressPath=/data1/databases/backup/compress/$(date &#39;+%Y/%m/&#39;) # 定义日期是时间 day=`date +%F` user=root pass=123456 host=127.0.0.1 # 新建个文件夹临时存放备份文件的 [ ! -e &quot;${tmpPath}/${day}-full&quot; ]&amp;&amp; mkdir -p &quot;${tmpPath}/${day}-full&quot; [ ! -e ${compressPath} ]&amp;&amp; mkdir -p ${compressPath} # 删除历史备份临时文件 [ -e ${tmpPath} ]&amp;&amp; rm -rf &quot;${tmpPath}/*&quot; # 用innobackupex做完全备份 innobackupex --host=$host --user=$user --password=$pass &quot;${tmpPath}/${day}-full&quot; --no-timestamp cd &quot;${tmpPath}&quot; echo &quot;$(date &#39;+%Y-%m-%d %H:%M:%S&#39;)&quot; &gt; &quot;${day}-full/time.txt&quot; echo &quot;本次全量备份时间： $(date &#39;+%Y-%m-%d %H:%M:%S&#39;)&quot; &gt;&gt; &quot;${day}-full/full.txt&quot; tar -czvf &quot;${compressPath}/$(date &#39;+%Y-%m-%d_%H_%M_%S&#39;)-full.tar.gz&quot; &quot;${day}-full&quot; # 启用binlog日志，每次完全备份之后，每周刷新一遍binlog日志 mysql -h$host -u$user -p$pass -e &quot;flush logs&quot; # 每周二到周日的凌晨4点执行增量备份 0 4 * * 2-7 /data1/databases/shell/newbak.sh &gt;/dev/null # 周一全备，如果是周二执行，判断dir1 存在，则增量备份，如果不存在，则判断昨天的增量，存在则执行周三的增量，如果都没有，则全备执行一次吧 vi /data1/databases/shell/newbak.sh #!/bin/bash # 定义时间，用日期来区分 d1=`date +%F` # 找到昨天的日期，好指明上一次备份的备份文件 d2=`date +%F -d &quot;-1 days&quot; ` # 昨天做的完全备份文件 dir1=&quot;/data1/databases/backup/xfull/${d2}-full&quot; #昨天做的增量备份文件 dir2=&quot;/data1/databases/backup/xincrement/${d2}-increment&quot; # 备份压缩文件存储路径 compressPath=/data1/databases/backup/compress/$(date &#39;+%Y/%m/&#39;) host=127.0.0.1 user=root pass=123456 # 如果文件不存在，则创建文件夹 [ ! -e $(dirname $dir1 ) ]&amp;&amp; mkdir -p $(dirname $dir1 ) [ ! -e $(dirname $dir2 ) ]&amp;&amp; mkdir -p $(dirname $dir2 ) [ ! -e ${compressPath} ]&amp;&amp; mkdir -p &quot;${compressPath}&quot; # 判断昨天做的是增量备份 if [ -e ${dir2} ];then # 指定昨天备份的增量备份文件 innobackupex --host=$host --user=$user --password=$pass --incremental &quot;$(dirname $dir2)/${d1}-increment&quot; --incremental-basedir=&quot;${dir2}&quot; --no-timestamp cd &quot;$(dirname $dir2)&quot; echo &quot;$(date &#39;+%Y-%m-%d %H:%M:%S&#39;)&quot; &gt; &quot;${d1}-increment/time.txt&quot; echo &quot;本次增量量备份时间： $(date &#39;+%Y-%m-%d %H:%M:%S&#39;)&quot; &gt; &quot;${d1}-increment/increment.txt&quot; echo &quot;基于上次增量备份时间： $(cat $dir2/time.txt)&quot; &gt;&gt; &quot;${d1}-increment/increment.txt&quot; tar -czvf &quot;${compressPath}/$(date &#39;+%Y-%m-%d_%H_%M_%S&#39;)-increment.tar.gz&quot; &quot;${d1}-increment&quot; echo &quot; 指定昨天备份的增量备份文件&quot; # 删除上次的增量备份的临时文件 [ -e &quot;${dir2}&quot; ]&amp;&amp; rm -rf &quot;${dir2}&quot; # 判断昨天做的是全量备份 elif [ -e ${dir1} ];then # 删除上次的增量备份的临时文件 [ -e &quot;$(dirname $dir2)&quot; ]&amp;&amp; rm -rf &quot;$(dirname $dir2)/*&quot; # 指定昨天备份的完全备份文件 innobackupex --host=$host --user=$user --password=$pass --incremental &quot;$(dirname $dir2)/${d1}-increment&quot; --incremental-basedir=${dir1} --no-timestamp cd &quot;$(dirname $dir2)&quot; echo &quot;$(date &#39;+%Y-%m-%d %H:%M:%S&#39;)&quot; &gt; &quot;${d1}-increment/time.txt&quot; echo &quot;本次增量量备份时间： $(date &#39;+%Y-%m-%d %H:%M:%S&#39;)&quot; &gt; &quot;${d1}-increment/increment.txt&quot; echo &quot;基于上次全量备份时间： $(cat $dir1/time.txt)&quot; &gt;&gt; &quot;${d1}-increment/increment.txt&quot; tar -czvf &quot;${compressPath}/$(date &#39;+%Y-%m-%d_%H_%M_%S&#39;)-increment.tar.gz&quot; &quot;${d1}-increment&quot; echo &quot; 指定昨天备份的完全备份文件 &quot; else # 昨天既没有做增量备份，又没有做完全备份，则做一次完全备份。 # 删除上次的全量备份的临时文件 [ -e &quot;$(dirname $dir1)&quot; ]&amp;&amp; rm -rf &quot;$(dirname $dir1)/*&quot; # 做一次完全备份。 innobackupex --host=$host --user=$user --password=$pass &quot;$(dirname $dir1)/${d1}-full&quot; --no-timestamp cd &quot;$(dirname $dir1)&quot; echo &quot;$(date &#39;+%Y-%m-%d %H:%M:%S&#39;)&quot; &gt; &quot;${d1}-full/time.txt&quot; echo &quot;本次全量备份时间： $(date &#39;+%Y-%m-%d %H:%M:%S&#39;)&quot; &gt; &quot;${d1}-full/full.txt&quot; tar -czvf &quot;${compressPath}/$(date &#39;+%Y-%m-%d_%H_%M_%S&#39;)-full.tar.gz&quot; &quot;${d1}-full&quot; echo &quot; 做一次完全备份&quot; fi echo &quot; ${dir1} ${dir2} ${compressPath}&quot; 实际应用 binlog日志 默认大小：1G左右，设置 ，配置文件里加一个 max_binlog_size = ？ 数据创建阶段 1、创建备份需要的目录 mkdir full inc1 inc2 2、周日全备 innobackupex --user=root --password=123 --no-timestamp /backup/xbackup/full/ 3、模拟数据变化 use oldboy create table test(id int,name char(20),age int); insert into test values(8,&#39;outman&#39;,99); insert into test values(9,&#39;outgirl&#39;,100); commit; 4、周一增量备份 innobackupex --user=root --password=123 --incremental --no-timestamp --incremental-basedir=/backup/xbackup/full/ /backup/xbackup/inc1 5、模拟数据变化 use oldboy insert into test values(8,&#39;outman1&#39;,119); insert into test values(9,&#39;outgirl1&#39;,120); commit; 6、周二的增量备份 innobackupex --user=root --password=123 --incremental --no-timestamp --incremental-basedir=/backup/xbackup/inc1 /backup/xbackup/inc2 再插入新的行操作 use oldboy insert into test values(10,&#39;outman2&#39;,19); insert into test values(11,&#39;outgirl2&#39;,10); commit; 模拟误操作事故 模拟场景，周二下午2点误删除test表 use oldboy; drop table test; 准备恢复数据 1.准备xtrabackup备份，合并备份 innobackupex --apply-log --redo-only /backup/xbackup/full innobackupex --apply-log --redo-only --incremental-dir=/backup/xbackup/inc1 /backup/xbackup/full innobackupex --apply-log --incremental-dir=/backup/xbackup/inc2 /backup/xbackup/full innobackupex --apply-log /backup/xbackup/full 2．确认binlog起点，准备截取binlog。 cd /backup/xbackup/inc2/ cat xtrabackup_binlog_info mysql-bin.000001 1121 3.截取到drop操作之前的binlog mysqlbinlog --start-position=1121 /tmp/mysql-bin.000003 找到drop之前的event和postion号做日志截取，假如 1437 这个可以用 mysqlbinlog master-bin.000032|less mysqlbinlog --start-position=1121 --stop-position=1437 /tmp/mysql-bin.000003 &gt;/tmp/incbinlog.sql 4．关闭数据库、备份二进制日志 /etc/init.d/mysqld stop cd /application/mysql/data/ cp mysql-bin.000001 /tmp 5.删除MySQL所有数据 cd /application/mysql/data/ rm -rf * 恢复数据 1．将全量备份的数据恢复到数据目录下 innobackupex --copy-back /backup/xbackup/full/ chown -R mysql.mysql /application/mysql/data/ /etc/init.d/mysqld start 2.恢复binlog记录 set sql_log_bin=0 source /tmp/incbinlog.sql]]></content>
      <categories>
        <category>centos</category>
        <category>mysql</category>
        <category>Percona XtraBackup</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>mysql</tag>
        <tag>Percona XtraBackup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[归并排序]]></title>
    <url>%2Falgorithm-merge-sort%2F</url>
    <content type="text"><![CDATA[归并 （Merge） 排序法是将两个 （或两个以上）有序表合并成一个新的有序表，即把待排序序列分为多干个子序列，每个子序列是有序的。然后再把有序子序列合并为整体有序序列。 public class MergeSortTest { public static void main(String[] args){ int[] data = new int[]{5, 3, 6, 2, 1, 9, 4, 8, 7}; print(data); mergeSort(data); System.out.println(&quot;排序后的数组&quot;); print(data); } public static void mergeSort(int[] data){ sort(data,0,data.length-1); } public void sort(int[] data, int left, int right){ if(left&gt;=right){ return; } // 找出中间索引 int center = (left + right)/2; // 对左边数组进行递归 sort(data,left,center); // 对右边数组进行递归 sort(data, center+1, right); // 合并 merge(data, left, center, right); print(data); } /** * 将两个数组进行归并，归并前面 2 个数组已经有序，归并后依然有序 * * @param data * 数组对象 * @param left * 左数组的第一个元素的索引 * @param center * 左数组的最后一个元素的索引，center+1 是右数组第一个元素的索引 * @param right * 右数组最后一个元素的索引 */ public static void merge(int[] data, int left, int center, int right) { // 临时数组 int[] tmpArr = new int[data.length]; // 右数组第一个元素索引 int mid = center + 1; // third 记录临时数组的索引 int third = left; // 缓存数组第一个元素的索引 int tmp = left; while(left &lt;= center &amp;&amp; mid &lt;= right){ // 从两个数组中取出最小的放入临时数组 if(data[left] &lt;= data[mid]){ tmpArr[third++] = data[left++]; }else { tempArr[third++] = data[mid++]; } } // 剩余部分依次放入临时数组 （实际上两个 while 只会执行其中一个） while(mid &lt;=right){ tmpArr[third++] = data[mid++]; } while(left &lt;= center){ temArr[third++] = data[left++]; } // 将临时数组中的内容拷贝会原数组中 // （原 left-right 范围的内容被复制回原数组） while(tmp &lt;= right){ data[tmp] = tempArr[tmp++]; } } public static void print(int[] data){ for(int i = 0 ; i &lt; data.length; i++){ System.out.print(data[i] + &quot;\t&quot;); } System.out.println(); } }]]></content>
      <categories>
        <category>java</category>
        <category>algorithm</category>
        <category>merge sort</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>algorithm</tag>
        <tag>merge sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[希尔排序]]></title>
    <url>%2Falgorithm-shell-sort%2F</url>
    <content type="text"><![CDATA[基本思想：先将整个待排序的记录分割成若干子序列分别进行插入排序，待整个序列中的记录 ”基本有序“ 时，再对全体记录进行依次直接插入排序。 1.操作方法： ​ 选择一个增量序列 t1, t2, …, tk, 其中 ti&gt;tj, tk=1; 2.按增量序列个数 k，对序列进行 k 趟排序； 3.每趟排序，根据对应的增量 ti，将待排序列分割成若干长度为 m 的子序列，分别对各字表进行直接插入排序。仅增量因子为 1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 private void shellSort(int[] a){ int dk = a.length/2; while(dk&gt;1){ ShellInSertSort(a,dk); } } private void ShellInsertSort(int[] a,int dk){ // 类似插入排序，只是插入排序增量是1，这里增量是 dk，把 1 换成 dk 就可以了 for(int i=dk; i&lt;a.length; i++){ if(a[i]&lt;a[i-dk]){ int j ; int x = a[i]; // X 为待插入元素 a[i] = a[i-dk]; for(j=i-dk; j&gt;=0 &amp;&amp; x&lt;a[j]; j=j-dk){ // 通过循环，逐个后移一位找到要插入的位置。 a[j+dk] = a[j]; } a[j+dk]=x; // 插入 } } }]]></content>
      <categories>
        <category>java</category>
        <category>algorithm</category>
        <category>shell sort</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>algorithm</tag>
        <tag>shell sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速排序]]></title>
    <url>%2Falgorithm-quick-sort%2F</url>
    <content type="text"><![CDATA[快速排序的原理：选择一个关键值作为基准值。比较基准值小的都放在左边序列(一般是无序的), 比基准值大的都在右边(一般是无序的)。一般选择序列的第一个元素。 一次循环：从后往前比较，用基准值和最后一个值比较，如果比基准值小的交换位置，如果没有继续比较下一个，知道找到第一个比基准值小的值才交换。找到这个值之后，又从前往后开始比较，如果有比基准值大的，交换位置，如果没有继续比较下一个，直到找到第一个比基准值大的值才交换。直到从前往后的比较索引&gt;从后往前比较的索引，结束第一次比较的索引，结束第一次循环，此时，对于基准值来说，左右两边就是有序的了。 public void sort(int[] a, int low, int high){ int start = low; int end = high; int key = a[low]; while(end&gt;start){ // 从后往前比较 while(end&gt;start &amp;&amp; a[end]&gt;=key){ // 如果没有比关键值小的，比较下一个，直到有比关键值小的交换位置，然后又从前往后比较 end--; if(a[end]&lt;=key){ int tem = a[end]; a[end] = a[start]; } // 从前往后比较 while(end&gt;start &amp;&amp; a[start]&lt;=key){ start++; } if(a[start]&gt;=key){ int temp = a[start]; a[start] = a[end]; a[end] = temp; } // 此时第一次循环比较结束，关键值的位置已经确定了。左边的值都比关键值小，右边的值都比关键值大，但是两边的顺序还有可能是不一样的，进行下面的递归调用 } // 递归 if(start&gt;low){ // 左边序列。第一个索引位置到关键值索引-1 sort(a,low,start-1); } if(end&lt;hight){ // 右边序列。从关键值索引+1 到最后一个 sort(a,end+1,high); } } }]]></content>
      <categories>
        <category>java</category>
        <category>algorithm</category>
        <category>quick sort</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>algorithm</tag>
        <tag>quick sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[插入排序]]></title>
    <url>%2Falgorithm-insert-sort%2F</url>
    <content type="text"><![CDATA[通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应的位置并插入。插入排序非常类似于整扑克。在开始摸牌时，左手是空的，牌面朝下放在桌面。接着，一次从桌上磨起一张牌，并将它插入到左手一把牌中的正确位置上。为了找到这张牌的正确位置，要将它与手中已有的牌从左到右地进行比较。无论什么时候，左手中的牌都是排好序的。 如果输入数组已经是排好序的话，插入排序出现最佳情况，其运行时间是输入规模的一个线性函数。如果输入数组是逆序排列的，将出现最坏情况。平均情况与最坏情况一样，其时间代价是($$n^2$$)。 public void sort(int arr[]){ for(int i = 1; i&lt;arr.length; i++){ // 插入的数 int insertVal = arr[i]; // 被插入的位置(准备和前一个数比较) int index = i-1; // 如果插入的数比被插入的数小 while(index&gt;=0 &amp;&amp; insertVal&lt;arr[index]){ // 将把 arr[index] 向后移动 arr[index+1] = arr[index]; // 让 index 向前移动 index--; } // 把插入的数放入合适位置 arr[index+1]=insertVal; } }]]></content>
      <categories>
        <category>java</category>
        <category>algorithm</category>
        <category>insert sort</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>algorithm</tag>
        <tag>insert sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[冒泡排序]]></title>
    <url>%2Falgorithm-bubble-sort%2F</url>
    <content type="text"><![CDATA[(1) 比较前后相邻的二个数据，如果前面数据大于后面的数据，就将这二个数据交换。 (2) 这样对数组的第 0 个数据到 N-1 个数据进行一次遍历后，最大的一个数据就 ”沉“ 到数组di N-1 个位置。 (3) N=N-1，如果 N 不为 0 就重复前面二步，否则排序完成。 public static void bubbleSort(int [] a){ int n = a.length; int i,j; for(i=0; i&lt;n; i++){ // 表示 n 次排序过程 for(j=1; j&lt;n-i; j++){ if(a[j-1] &gt; a[j]){ // 前面的数字大于后面的数字就交换 // 交换 a[j-i] 和 a[j] int temp ; temp = a[j-1]; a[j-1] = a[j]; a[j] = temp; } } } }]]></content>
      <categories>
        <category>java</category>
        <category>algorithm</category>
        <category>bubble sort</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[二分查找]]></title>
    <url>%2Falgorithm-bi-search%2F</url>
    <content type="text"><![CDATA[又叫折半查找，要求待查找的序列有序。每次取中间位置与待查关键字比较，如果中间位置的值比待查关键字大，则在前半部分循环这个查找的过程，如果中间位置的值比待查关键字小，则在后半部分循环这个查找的过程。直到查找到了为止。否则序列中没有待查的关键字。 Java 代码实现如下 public static int biSearch(int []array, int a){ int lo = 0; int hi = array.length - 1; int mid; while(lo&lt;=hi){ mid=(lo+li)/2; // 中间位置 if(array[mid]==a){ return mid + 1; }else if(array[mid]&lt;a){ // 向右查找 lo = mid + 1; }else { // 向左查找 hi = mid - 1; } } return -1; }]]></content>
      <categories>
        <category>java</category>
        <category>algorithm</category>
        <category>biSearch</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>algorithm</tag>
        <tag>biSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kibana 认证登录]]></title>
    <url>%2Fkibana-auth%2F</url>
    <content type="text"><![CDATA[Kibana从5.5开始不提供认证功能，用官方的认证X-Pack，则需购买授权许可。 为了安全访问，我们可以使用Nginx的代理功能来认证登录 安装Nginx安装Apache密码生产工具 yum install httpd-tools 生成密码文件 mkdir -p /etc/nginx/passwd htpasswd -c -b /etc/nginx/passwd/kibana.passwd admin 123456 配置Nginx vim /usr/local/nginx/nginx.conf server { listen 172.20.8.113:5601; auth_basic &quot;Kibana Auth&quot;; auth_basic_user_file /etc/nginx/passwd/kibana.passwd; location / { proxy_pass http://127.0.0.1:5601; proxy_redirect off; } } 修改Kibana配置文件 vim /usr/local/kibana/config/kibana.yml # The host to bind the server to. server.host: &quot;localhost&quot; 重启Kibana服务，配置文件生效 systemctl restart kibana 重载Nginx配置 nginx -s reload 登录KibanaURL: http://172.20.8.113:5601]]></content>
      <categories>
        <category>kibana</category>
        <category>nginx</category>
        <category>htpasswd</category>
        <category>auth</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>kibana</tag>
        <tag>htpasswd</tag>
        <tag>auth</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[wget参数使用参考]]></title>
    <url>%2Fwget-use%2F</url>
    <content type="text"><![CDATA[wget是一个从网络上自动下载文件的自由工具。它支持HTTP，HTTPS和FTP协议，可以使用HTTP代理. 所谓的自动下载是指，wget可以在用户退出系统的之后在后台执行。这意味这你可以登录系统，启动一个wget下载任务，然后退出系统，wget将在后台执行直到任务完成，相对于其它大部分浏览器在下载大量数据时需要用户一直的参与，这省去了极大的麻烦。 ​ wget 可以跟踪HTML页面上的链接依次下载来创建远程服务器的本地版本，完全重建原始站点的目录结构。这又常被称作”递归下载”。在递归下载的时候，wget 遵循Robot Exclusion标准(/robots.txt)。wget可以在下载的同时，将链接转换成指向本地文件，以方便离线浏览。 ​ wget 非常稳定,它在带宽很窄的情况下和不稳定网络中有很强的适应性.如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。如果是服务 器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。 wget的常见用法： wget不但功能强大，而且使用起来比较简单 基本的语法是：wget [参数列表] &quot;URL&quot; 用””引起来可以避免因URL中有特殊字符造成的下载出错。 下面就结合具体的例子来说明一下wget的用法。 ​ 1、下载整个http或者ftp站点。 wget http://place.your.url/here 这个命令可以将http://place.your.url/here首页下载下来。使用-x会强制建立服务器上一模一样的目录，如果使用-nd参数，那么服务器上下载的所有内容都会加到本地当前目录。 wget -r http://place.your.url/here ​ 这个命令会按照递归的方法，下载服务器上所有的目录和文件，实质就是下载整个网站。这个命令一定要小心使用，因为在下载的时候，被下载网站指向的所有地址 同样会被下载，因此，如果这个网站引用了其他网站，那么被引用的网站也会被下载下来！基于这个原因，这个参数不常用。可以用-l number参数来指定下载的层次。例如只下载两层，那么使用-l 2。 ​ 要是您想制作镜像站点，那么可以使用－m参数，例如： wget -m http://place.your.url/here ​ 这时wget会自动判断合适的参数来制作镜像站点。此时，wget会登录到服务器上，读入robots.txt并按robots.txt的规定来执行。 ​ 2、断点续传。​ 当文件特别大或者网络特别慢的时候，往往一个文件还没有下载完，连接就已经被切断，此时就需要断点续传。wget的断点续传是自动的，只需要使用-c参数，例如：​ wget -c http://the.url.of/incomplete/file ​ 使用断点续传要求服务器支持断点续传。-t参数表示重试次数，例如需要重试100次，那么就写-t 100，如果设成-t 0，那么表示无穷次重试，直到连接成功。-T参数表示超时等待时间，例如-T 120，表示等待120秒连接不上就算超时。 ​ 3、批量下载。​ 如果有多个文件需要下载，那么可以生成一个文件，把每个文件的URL写一行，例如生成文件download.txt，然后用命令：wget -i download.txt这样就会把download.txt里面列出的每个URL都下载下来。（如果列的是文件就下载文件，如果列的是网站，那么下载首页） ​ 4、选择性的下载。​ 可以指定让wget只下载一类文件，或者不下载什么文件。例如： wget -m --reject=gif http://target.web.site/subdirectory ​ 表示下载http://target.web.site/subdirectory，但是忽略gif文件。--accept=LIST可以接受的文件类型，--reject=LIST拒绝接受的文件类型。 ​ 表示下载http://target.web.site/subdirectory，但是忽略gif文件。–accept=LIST 可以接受的文件类型，–reject=LIST拒绝接受的文件类型。 ​ 5、密码和认证。​ wget只能处理利用用户名/密码方式限制访问的网站，可以利用两个参数：​ --http-user=USER设置HTTP用户​ --http-passwd=PASS设置HTTP密码​ 对于需要证书做认证的网站，就只能利用其他下载工具了，例如curl。 ​ 6、利用代理服务器进行下载。​ 如果用户的网络需要经过代理服务器，那么可以让wget通过代理服务器进行文件的下载。此时需要在当前用户的目录下创建一个.wgetrc文件。文件中可以设置代理服务器： http-proxy = 111.111.111.111:8080 ftp-proxy = 111.111.111.111:8080 ​ 分别表示http的代理服务器和ftp的代理服务器。如果代理服务器需要密码则使用：​ --proxy-user=USER设置代理用户​ --proxy-passwd=PASS设置代理密码​ 这两个参数。​ 使用参数--proxy=on/off 使用或者关闭代理。​ wget还有很多有用的功能，需要用户去挖掘。 ​ 分别表示http的代理服务器和ftp的代理服务器。如果代理服务器需要密码则使用：​ --proxy-user=USER设置代理用户​ --proxy-passwd=PASS设置代理密码​ 这两个参数。​ 使用参数–proxy=on/off 使用或者关闭代理。​ wget还有很多有用的功能，需要用户去挖掘。 wget的使用格式 Usage: wget [OPTION]... [URL]... 用wget做站点镜像: wget -r -p -np -k http://dsec.pku.edu.cn/~usr_name/ # 或者 wget -m http://dsec.pku.edu.cn/~usr_name/ # 在不稳定的网络上下载一个部分下载的文件，以及在空闲时段下载 wget -t 0 -w 31 -c http://dsec.pku.edu.cn/BBC.avi -o down.log &amp; # 或者从filelist读入要下载的文件列表 wget -t 0 -w 31 -c -B ftp://dsec.pku.edu.cn/linuxsoft -i filelist.txt -o down.log &amp; 上面的代码还可以用来在网络比较空闲的时段进行下载。我的用法是:在mozilla中将不方便当时下载的URL链接拷贝到内存中然后粘贴到文件filelist.txt中，在晚上要出去系统前执行上面代码的第二条。 # 使用代理下载 wget -Y on -p -k https://sourceforge.net/projects/wvware/ 代理可以在环境变量或wgetrc文件中设定 # 在环境变量中设定代理 export PROXY=http://211.90.168.94:8080/ # 在~/.wgetrc中设定代理 http_proxy = http://proxy.yoyodyne.com:18023/ ftp_proxy = http://proxy.yoyodyne.com:18023/ wget各种选项分类列表 启动 -V, --version 显示wget的版本后退出 -h, --help 打印语法帮助 -b, --background 启动后转入后台执行 -e, --execute=COMMAND 执行.wgetrc’格式的命令，wgetrc格式参见/etc/wgetrc或~/.wgetrc` 记录和输入文件 -o, --output-file=FILE 把记录写到FILE文件中 -a, --append-output=FILE 把记录追加到FILE文件中 -d, --debug 打印调试输出 -q, --quiet 安静模式(没有输出) -v, --verbose 冗长模式(这是缺省设置) -nv, --non-verbose 关掉冗长模式，但不是安静模式 -i, --input-file=FILE 下载在FILE文件中出现的URLs -F, --force-html 把输入文件当作HTML格式文件对待 -B, --base=URL 将URL作为在-F -i参数指定的文件中出现的相对链接的前缀 --sslcertfile=FILE 可选客户端证书 --sslcertkey=KEYFILE 可选客户端证书的KEYFILE --egd-file=FILE 指定EGD socket的文件名 下载 --bind-address=ADDRESS 指定本地使用地址(主机名或IP，当本地有多个IP或名字时使用) -t, --tries=NUMBER 设定最大尝试链接次数(0 表示无限制). -O --output-document=FILE 把文档写到FILE文件中 -nc, --no-clobber 不要覆盖存在的文件或使用.#前缀 -c, --continue 接着下载没下载完的文件 --progress=TYPE 设定进程条标记 -N, --timestamping 不要重新下载文件除非比本地文件新 -S, --server-response 打印服务器的回应 --spider 不下载任何东西 -T, --timeout=SECONDS 设定响应超时的秒数 -w, --wait=SECONDS 两次尝试之间间隔SECONDS秒--waitretry=SECONDS 在重新链接之间等待1…SECONDS秒 --random-wait 在下载之间等待0…2*WAIT秒 -Y, --proxy=on/off 打开或关闭代理 -Q, --quota=NUMBER 设置下载的容量限制 --limit-rate=RATE 限定下载输率 目录 -nd --no-directories 不创建目录 -x, --force-directories 强制创建目录 -nH, --no-host-directories 不创建主机目录 -P, --directory-prefix=PREFIX 将文件保存到目录 PREFIX/… --cut-dirs=NUMBER 忽略 NUMBER层远程目录 HTTP 选项 --http-user=USER 设定HTTP用户名为 USER. --http-passwd=PASS 设定http密码为 PASS. -C, --cache=on/off 允许/不允许服务器端的数据缓存 (一般情况下允许). -E, --html-extension 将所有text/html文档以.html扩展名保存 --ignore-length 忽略Content-Length头域 --header=STRING 在headers中插入字符串 STRING --proxy-user=USER 设定代理的用户名为USER --proxy-passwd=PASS 设定代理的密码为PASS --referer=URL 在HTTP请求中包含Referer: URL头 -s, --save-headers 保存HTTP头到文件 -U, --user-agent=AGENT 设定代理的名称为AGENT而不是Wget/VERSION. --no-http-keep-alive 关闭HTTP活动链接 (永远链接). --cookies=off 不使用cookies. --load-cookies=FILE 在开始会话前从文件FILE中加载cookie --save-cookies=FILE 在会话结束后将 cookies保存到 FILE文件中 FTP 选项 -nr, --dont-remove-listing 不移走.listing’`文件 -g, --glob=on/off 打开或关闭文件名的globbing机制 --passive-ftp 使用被动传输模式 (缺省值). --active-ftp 使用主动传输模式 --retr-symlinks 在递归的时候，将链接指向文件(而不是目录) 递归下载 -r, --recursive 递归下载－－慎用! -l, --level=NUMBER 最大递归深度 (inf 或 0 代表无穷). --delete-after 在现在完毕后局部删除文件 -k, --convert-links 转换非相对链接为相对链接 -K, --backup-converted 在转换文件X之前，将之备份为X.orig -m, --mirror 等价于-r -N -l inf -nr. -p, --page-requisites 下载显示HTML文件的所有图片 递归下载中的包含和不包含(accept/reject) -A, --accept=LIST 分号分隔的被接受扩展名的列表 -R, --reject=LIST 分号分隔的不被接受的扩展名的列表 -D, --domains=LIST 分号分隔的被接受域的列表 --exclude-domains=LIST 分号分隔的不被接受的域的列表 --follow-ftp 跟踪HTML文档中的FTP链接 --follow-tags=LIST 分号分隔的被跟踪的HTML标签的列表 -G, --ignore-tags=LIST 分号分隔的被忽略的HTML标签的列表 -H, --span-hosts 当递归时转到外部主机 -L, --relative 仅仅跟踪相对链接 -I, --include-directories=LIST 允许目录的列表 -X, --exclude-directories=LIST 不被包含目录的列表 -np, --no-parent 不要追溯到父目录 wget -S --spider url 不下载只显示过程]]></content>
      <categories>
        <category>wget</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>wget</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[javascript正则表达式验证数字]]></title>
    <url>%2Fjs-reg-exp%2F</url>
    <content type="text"><![CDATA[javascript 验证输入的是否为正确的数组 function validate(){ var reg = new RegExp(&quot;^[0-9]*$&quot;); var obj = document.getElementById(&quot;name&quot;); if(!reg.test(obj.value)){ alert(&quot;请输入数字!&quot;); } if(!/^[0-9]*$/.test(obj.value)){ alert(&quot;请输入数字!&quot;); } } 验证数字的正则表达式集 验证数字：^[0-9]*$ 验证n位的数字：^\d{n}$ 验证至少n位数字：^\d{n,}$ 验证m-n位的数字：^\d{m,n}$ 验证零和非零开头的数字：^(0|[1-9][0-9]*)$ 验证有两位小数的正实数：^[0-9]+(.[0-9]{2})?$ 验证有1-3位小数的正实数：^[0-9]+(.[0-9]{1,3})?$ 验证非零的正整数：^\+?[1-9][0-9]*$ 验证非零的负整数：^\-[1-9][0-9]*$ 验证非负整数（正整数 + 0） ^\d+$ 验证非正整数（负整数 + 0） ^((-\d+)|(0+))$ 验证长度为3的字符：^.{3}$ 验证由26个英文字母组成的字符串：^[A-Za-z]+$ 验证由26个大写英文字母组成的字符串：^[A-Z]+$ 验证由26个小写英文字母组成的字符串：^[a-z]+$ 验证由数字和26个英文字母组成的字符串：^[A-Za-z0-9]+$ 验证由数字、26个英文字母或者下划线组成的字符串：^\w+$ 验证用户密码:^[a-zA-Z]\w{5,17}$ 正确格式为：以字母开头，长度在6-18之间，只能包含字符、数字和下划线。 验证是否含有 ^%&amp;&#39;,;=?$\&quot; 等字符：[^%&amp;&#39;,;=?$\x22]+ 验证汉字：^[\u4e00-\u9fa5],{0,}$ 验证Email地址：^\w+[-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)*$ 验证InternetURL：^http://([\w-]+\.)+[\w-]+(/[\w-./?%&amp;=]*)?$ ；^[a-zA-z]+://(w+(-w+)*)(.(w+(-w+)*))*(?S*)?$ 验证电话号码：^(\(\d{3,4}\)|\d{3,4}-)?\d{7,8}$ 正确格式为：XXXX-XXXXXXX，XXXX-XXXXXXXX，XXX-XXXXXXX，XXX-XXXXXXXX，XXXXXXX，XXXXXXXX。 验证身份证号（15位或18位数字）：^\d{15}|\d{}18$验证一年的12个月：^(0?[1-9]|1[0-2])$正确格式为：“01”-“09”和“1”“12”验证一个月的31天：^((0?[1-9])|((1|2)[0-9])|30|31)$正确格式为：01、09和1、31。整数：^-?\d+$非负浮点数（正浮点数 + 0）：^\d+(\.\d+)?$正浮点数^(([0-9]+\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\.[0-9]+)|([0-9]*[1-9][0-9]*))$非正浮点数（负浮点数 + 0）^((-\d+(\.\d+)?)|(0+(\.0+)?))$负浮点数 ^(-(([0-9]+\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\.[0-9]+)|([0-9]*[1-9][0-9]*)))$浮点数^(-?\d+)(\.\d+)?$]]></content>
      <categories>
        <category>正则</category>
      </categories>
      <tags>
        <tag>正则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS firewall添加开放端口]]></title>
    <url>%2FCentOS-7-firewall%2F</url>
    <content type="text"><![CDATA[添加 firewall-cmd --zone=public --add-port=80/tcp --permanent （ –permanent 永久生效，没有此参数重启后失效） 查看 firewall-cmd --zone=public --query-port=80/tcp 删除 firewall-cmd --zone=public --remove-port=80/tcp --permanent 重新载入 firewall-cmd --reload 1、firewalld的基本使用 启动： systemctl start firewalld 查看状态： systemctl status firewalld 停止： systemctl disable firewalld 禁用： systemctl stop firewalld 2.systemctl是 CentOS 7 的服务管理工具中主要的工具，它融合之前 service 和 chkconfig 的功能于一体。 启动一个服务：systemctl start firewalld.service关闭一个服务：systemctl stop firewalld.service重启一个服务：systemctl restart firewalld.service显示一个服务的状态：systemctl status firewalld.service在开机时启用一个服务：systemctl enable firewalld.service在开机时禁用一个服务：systemctl disable firewalld.service查看服务是否开机启动：systemctl is-enabled firewalld.service查看已启动的服务列表：systemctl list-unit-files|grep enabled查看启动失败的服务列表：systemctl --failed 3.配置firewalld-cmd 查看版本： firewall-cmd --version 查看帮助： firewall-cmd --help 显示状态： firewall-cmd --state 查看所有打开的端口： firewall-cmd --zone=public --list-ports 更新防火墙规则： firewall-cmd --reload 查看区域信息: firewall-cmd --get-active-zones 查看指定接口所属区域： firewall-cmd --get-zone-of-interface=eth0 拒绝所有包：firewall-cmd --panic-on 取消拒绝状态： firewall-cmd --panic-off 查看是否拒绝： firewall-cmd --query-panic 那怎么开启一个端口呢接下来通过以下命令开放http 80 端口： sudo firewall-cmd --add-service=http --permanent sudo firewall-cmd --add-port=80/tcp --permanent 命令末尾的 —permanent 表示用久有效，不加这句的话重启后刚才开放的端口就又失效了。 然后重启防火墙： sudo firewall-cmd --reload 再次查看端口的开放情况： sudo firewall-cmd --list-all 查看 firewall-cmd --zone=public --query-service=http firewall-cmd --zone=public --query-port=80/tcp 删除 firewall-cmd --zone=public --remove-service=http --permanent firewall-cmd --zone=public --remove-port=80/tcp --permanent]]></content>
      <categories>
        <category>centos firewall</category>
      </categories>
      <tags>
        <tag>centos firewall</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 修改ssh 端口]]></title>
    <url>%2FCentOS-7-Modify-sshd-port%2F</url>
    <content type="text"><![CDATA[修改/etc/ssh/sshd_configvi /etc/ssh/sshd_config Port 22 //这行去掉#号，防止配置不好以后不能远程登录，还得去机房修改，等修改以后的端口能使用以后在注释掉 Port 33378 //下面添加这一行 修改firewall配置firewall添加想要修改的ssh端口： 添加到防火墙： firewall-cmd --zone=public --add-port=33378/tcp --permanent (permanent是保存配置，不然下次重启以后这次修改无效) 重启： firewall-cmd --reload 查看添加端口是否成功，如果添加成功则会显示yes，否则no firewall-cmd --zone=public --query-port=33378/tcp 修改SELinux使用以下命令查看当前SElinux 允许的ssh端口： semanage port -l | grep ssh 添加33378端口到 SELinux semanage port -a -t ssh_port_t -p tcp 33378 然后确认一下是否添加进去 semanage port -l | grep ssh 如果成功会输出 ssh_port_t tcp 33378, 22 重启ssh systemctl restart sshd.service 测试新端口的ssh连接测试修改端口以后的ssh连接，如果成功则将step1里面的port 22 重新注释掉 测试新端口的ssh连接测试修改端口以后的ssh连接，如果成功则将step1里面的port 22 重新注释掉 解决CentOS7 下 SSH登录慢的问题登陆SSH时 输入完用户名后要等一会才能输入密码，经总结下面方案可解决此问题。 修改sshd_config以下两处，重启ssh即可。 # vi /etc/ssh/sshd_config GSSAPIAuthentication no UseDNS no 重启 ssh # systemctl restart sshd]]></content>
      <categories>
        <category>centos</category>
        <category>sshd</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>sshd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7上部署vnc服务器并实现远程桌面]]></title>
    <url>%2FCentOS-VNCserver%2F</url>
    <content type="text"><![CDATA[一、安装X Window System注：若已经安装GUI则可跳过 1、切换到root用户，执行 yum groupinstall &quot;X Window System&quot;2、执行 yum install gnome-classic-session gnome-terminal nautilus-open-terminal control-center liberation-mono-fonts -y 安装相关组件3、设置默认启动图形界面 # unlink /etc/systemd/system/default.target # ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target 4、重启系统生效 # reboot 二、安装vnc服务1、执行yum install tigervnc-server -y安装VNC服务器软件# yum install tigervnc-server -y Loaded plugins: fastestmirror, langpacks Loading mirror speeds from cached hostfile * base: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirror.lzu.edu.cn base | 3.6 kB 00:00:00 extras | 3.4 kB 00:00:00 updates | 3.4 kB 00:00:00 Resolving Dependencies --&gt; Running transaction check ---&gt; Package tigervnc-server.x86_64 0:1.8.0-13.el7 will be installed --&gt; Finished Dependency Resolution Dependencies Resolved =================================================================================================================================================================================================================== Package Arch Version Repository Size =================================================================================================================================================================================================================== Installing: tigervnc-server x86_64 1.8.0-13.el7 base 215 k Transaction Summary =================================================================================================================================================================================================================== Install 1 Package Total download size: 215 k Installed size: 509 k Downloading packages: tigervnc-server-1.8.0-13.el7.x86_64.rpm | 215 kB 00:00:00 Running transaction check Running transaction test Transaction test succeeded Running transaction Installing : tigervnc-server-1.8.0-13.el7.x86_64 1/1 Verifying : tigervnc-server-1.8.0-13.el7.x86_64 1/1 Installed: tigervnc-server.x86_64 0:1.8.0-13.el7 Complete! 2、配置VNC在/etc/systemd/system目录里创建一个配置文件（可以将/lib/systemd/system/vncserver@.service拷贝一份配置文件范例过来） cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service 使用文本编辑器打开 /etc/systemd/system/vncserver@:1.service ，找到下面这几行，用自己的用户名替换掉 &lt;USER&gt; User=&lt;USER&gt; PIDFile=/home/&lt;USER&gt;/.vnc/%H%i.pid 替换成 User=root PIDFile=/home/root/.vnc/%H%i.pid 重启systemd systemctl daemon-reload vncpasswd设置VNC登录密码 vncpasswd 执行vncserver开启一个VNC窗口 # vncserver You will require a password to access your desktops. Password: Verify: Would you like to enter a view-only password (y/n)? n A view-only password is not used xauth: file /root/.Xauthority does not exist New &#39;server:1 (root)&#39; desktop is server:1 Creating default startup script /root/.vnc/xstartup Creating default config /root/.vnc/config Starting applications specified in /root/.vnc/xstartup Log file is /root/.vnc/server:1.log 开启远程端口 # vncserver :1 A VNC server is already running as :1 New &#39;server:2 (root)&#39; desktop is server:2 Starting applications specified in /root/.vnc/xstartup Log file is /root/.vnc/server:2.log 设置防火墙规则，允许访问VNC-SERVER的流量通过，并重启firewall服务使之生效 # firewall-cmd --permanent --add-service vnc-server # systemctl restart firewalld.service 三、客户端连接 VNC server客户端可以使用官方，直接去官网下载，推荐使用 MobaXterm，集成常用 ssh，sftp 等功能。 地址栏填写：ip::5901。例如：172.20.8.31::5901 我们开启的是vncserver :1，而 vncserver 默认从5900开始，所以我们使用 5900+1 = 5901，注意需要两个 :: 接下来输入服务端设置的 vncserver 的密码就可以了。 注意关闭防火墙和selinux]]></content>
      <categories>
        <category>centos vnc</category>
      </categories>
      <tags>
        <tag>centos vnc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装 go-fastdfs]]></title>
    <url>%2FCentOS-7-install-GoFastdfs%2F</url>
    <content type="text"><![CDATA[CentOS 7 安装go-fastdfs文件服务 参照官网描述（https://github.com/sjqzhang/go-fastdfs），linux下go-fastdfs安装步骤如下： 下载文件下载相关文件并赋予执行权限$ wget https://github.com/sjqzhang/go-fastdfs/releases/download/v1.3.0/fileserver $ wget https://raw.githubusercontent.com/sjqzhang/go-fastdfs/master/control $ chmod 755 fileserver $ chmod 755 control 常用命令启动/停止/重启/查看状态/查看日志 ./control start|stop|restart|status|tail $ ./control start fileserver started..., pid=20599 $ ./control status fileserver now is running, pid=1080 $ ./control stop fileserver stoped... $ ./control tail Listen on :28088 测试上传启动后可以使用命令体验上传curl -F file=@http-index-fs http://10.1.xx.60:8080/upload web上传使用浏览器打开http://yourserver ip:8080/upload.html，注意不要使用127.0.0.1上传 修改配置在fileserver同目录下会自动生成配置文件，存放在 conf/cfg.json，需要修改几个参数，其他参数按需求修改。 &quot;绑定端号&quot;: &quot;端口&quot;, &quot;addr&quot;: &quot;:28088&quot;, &quot;本主机地址&quot;: &quot;本机http地址,默认自动生成(注意端口必须与addr中的端口一致），必段为内网，自动生成不为内网请自行修改，下同&quot;, &quot;host&quot;: &quot;http://172.20.8.31:28088&quot;, &quot;集群&quot;: &quot;集群列表,注意为了高可用，IP必须不能是同一个,同一不会自动备份，且不能为127.0.0.1,且必须为内网IP，默认自动生成&quot;, &quot;peers&quot;: [&quot;http://172.20.8.31:28088&quot;], &quot;是否自动重命名&quot;: &quot;默认不自动重命名,使用原文件名&quot;, &quot;rename_file&quot;: true, &quot;下载域名&quot;: &quot;用于外网下载文件的域名,不包含http://&quot;, &quot;download_domain&quot;: &quot;172.20.8.31:28088&quot;, 修改完后需要重启服务 $ ./control restart fileserver stoped... fileserver started..., pid=21038 测试文件上传 $ curl -F file=@test.jpeg http://172.20.8.31:28088/upload http://172.20.8.31:28088/group1/default/20190604/16/22/6/7d6ef01d71af04dc61cb388955478121.jpeg# 加入系统服务新建文件gofastdfs vi /etc/rc.d/init.d/gofastdfs 文件内容为 #!/bin/sh # chkconfig: 2345 80 90 # # Simple go-fastdfs init.d script conceived to work on Linux systems # as it does use of the /proc filesystem. ### BEGIN INIT INFO # Provides: gofastdfs_28088 # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: go-fastdfs file server # Description: go-fastdfs file server. See https://github.com/sjqzhang/go-fastdfs ### END INIT INFO # WORKSPACE=$(cd $(dirname $0)/; pwd) WORKSPACE=/data1/webserver/gofastdfs/ cd $WORKSPACE mkdir -p log conf module= app=fileserver conf=conf/cfg.json pidfile=conf/app.pid logfile=log/app.log function check_pid() { if [ -f $pidfile ];then pid=`cat $pidfile` if [ -n $pid ]; then running=`ps -p $pid|grep -v &quot;PID TTY&quot; |wc -l` return $running fi fi return 0 } function start() { check_pid running=$? if [ $running -gt 0 ];then echo -n &quot;$app now is running already, pid=&quot; cat $pidfile return 1 fi nohup ./$app &amp;&gt; $logfile &amp; echo $! &gt; $pidfile echo &quot;$app started..., pid=$!&quot; } function stop() { pid=`cat $pidfile` kill $pid echo &quot;$app stoped...&quot; } function restart() { stop sleep 1 start } function status() { check_pid running=$? if [ $running -gt 0 ];then echo -n &quot;$app now is running, pid=&quot; cat $pidfile else echo &quot;$app is stoped&quot; fi } function tailf() { tail -f $logfile } function build() { go build if [ $? -ne 0 ]; then exit $? fi mv $module $app ./$app -v | grep -v &quot;config&quot; } function pack() { build git log -1 --pretty=%h &gt; gitversion version=`./$app -v|grep -v config` file_list=&quot;control cfg.example.json $app&quot; tar zcf $app-$version.tar.gz gitversion $file_list } function packbin() { build git log -1 --pretty=%h &gt; gitversion version=`./$app -v|grep -v config` tar zcvf $app-bin-$version.tar.gz $app gitversion } function help() { echo &quot;$0 start|stop|restart|status|tail&quot; } if [ &quot;$1&quot; == &quot;&quot; ]; then help elif [ &quot;$1&quot; == &quot;stop&quot; ];then stop elif [ &quot;$1&quot; == &quot;start&quot; ];then start elif [ &quot;$1&quot; == &quot;restart&quot; ];then restart elif [ &quot;$1&quot; == &quot;status&quot; ];then status elif [ &quot;$1&quot; == &quot;tail&quot; ];then tailf else help fi 修改文件权限 chmod 755 /etc/rc.d/init.d/gofastdfs 设置开机启动 chkconfig gofastdfs on 启动、停止、重启、查看状态等命令 service gofastdfs start/stop/restart/status/tail]]></content>
      <categories>
        <category>centos</category>
        <category>go-fastdfs</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>go-fastdfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 用户相关操作]]></title>
    <url>%2FCentOS-Users%2F</url>
    <content type="text"><![CDATA[Centos 用户相关操作 查看centos中的用户和用户组1、用户列表文件：/etc/passwd/ 2、用户组列表文件：/etc/group 3、查看系统中有哪些用户： cut -d : -f 1 /etc/passwd 4、查看可以登录系统的用户： cat /etc/passwd | grep -v /sbin/nologin | cut -d : -f 1 5、查看用户操作：w命令(需要root权限) 6、查看某一用户：w 用户名 7、查看登录用户：who 8、查看用户登录历史记录：last 9、修改root用户密码： passwd 10、root用户修改其他用户密码： passwd &lt;user_name&gt; 11、查看系统版本：cat /etc/redhat-release 12、删除用户 userdel 用户名 13、查看组 cat /etc/group 14、删除组 groupdel 组名]]></content>
      <tags>
        <tag>CentOS Linux Users</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装 Redis]]></title>
    <url>%2FCentOS-7-install-Redis%2F</url>
    <content type="text"><![CDATA[CentOS 7 安装Redis 参照官网描述（https://redis.io/download），linux下redis安装步骤如下： 所有工具和依赖一起安装 yum install -y tcl gcc-c++ $ wget http://download.redis.io/releases/redis-5.0.5.tar.gz $ tar -zxvf redis-5.0.5.tar.gz $ cd redis-5.0.5 $ mkdir -p /data1/databases/redis $ make &amp;&amp; make install PREFIX=/data1/databases/redis 上述流程依次代表，下载redis –&gt; 解压 –&gt; 进入解压目录 –&gt; 编译源码 多数情况下，执行make时，可能会出现如下错误： 异常一： make[2]: cc: Command not found 异常原因：没有安装gcc 解决方案：yum install gcc-c++ 异常二： zmalloc.h:51:31: error: jemalloc/jemalloc.h: No such file or directory 异常原因：一些编译依赖或原来编译遗留出现的问题 解决方案：make distclean。清理一下，然后再make。 在make成功以后，需要make test。在make test出现异常。 异常一： couldn&#39;t execute &quot;tclsh8.5&quot;: no such file or directory 异常原因：没有安装tcl 解决方案：yum install -y tcl。 到此，redis安装完成。 若是通过：make install PREFIX=安装目录， 完成安装的，会在安装目录下生成一个bin目录，bin目录下包含如下可执行文件： redis-benchmark ： 用于测试redis的性能。 redis-check-aof : 当aof备份文件被损坏，可通过该工具对aof文件进行修复，使用方式：redis-check-aof --fix 要修复的aof文件。 redis-check-rdb : 修复损坏的rdb备份文件。 redis-cli : redis客户端，用于连接服务端。 redis-server ： redis服务器端，用于启动redis服务器。 redis-sentinel : 哨兵模式（实际使用较多） 在master-slave模式下（slave默认不支持写），当master出现异常时，自动在slave中选择一台作为master。 连接上redis服务器后，可通过指令“info”查看redis服务器信息，也可查看服务器知道内容信息，例如：info replication 查看主从相关信息 下面介绍几个redis常用配置项（redis.cnf配置文件中配置）1、bind 127.0.0.1 配置redis服务器接受链接的网卡（非客户端ip，而是服务器端ip，服务器可能包含多个网卡） 2、protected-mode yes redis以保护模式运行，只接受本地链接，不能外网访问 3、port 6379 redis接受链接端口 4、daemonize no redis是否后台运行，若为yes，客户端窗口将被锁定重要配置项5、maxmemory redis最大使用内存6、maxmemory-policy 内存达到最大值时的驱逐策略 redis数据持久化支持两种模式：RDB和AOFRDB：rdb方式的持久化是通过快照完成的，当符合一定条件时redis会自动将内存中的所有数据执行快照操作并存储到硬盘上。默认存储在redis根目录的dump.rdb文件中。(文件名在配置文件中dbfilename) redis进行快照的时机（在配置文件redis.conf中） save 900 1：表示900秒内至少一个键被更改则进行快照。 save 300 10 save 60 10000 dbfilename dump.rdb 快照保存文件名 dir ./ 快照保存地址 也可通过redis客服端执行命令save或者bgsave保存快照： 两个命令的区别在于，save是由主进程进行快照操作，会阻塞其它请求。bgsave是由redis执行fork函数复制出一个子进程来进行快照操作。 文件修复：redis-check-dump rdb的优缺点 优点：由于存储的有数据快照文件，恢复数据很方便。 缺点：会丢失最后一次快照以后更改的所有数据。 AOF:aof方式的持久化是通过日志文件的方式，记录下redis服务器的每一条修改指令。默认情况下redis没有开启aof，可以通过参数appendonly参数开启。 appendonly yes aof文件的保存位置和rdb文件的位置相同，都是dir参数设置的，默认的文件名是appendonly.aof，可以通过 appendfilename参数修改 appendfilename appendonly.aof redis写命令同步的时机： appendfsync always 每次都会执行 appendfsync everysec 默认 每秒执行一次同步操作（推荐，默认） appendfsync no不主动进行同步，由操作系统来做，30秒一次 redis服务器启动时会读取appendonly.aof中的指令，进行执行，这样便保证了重启后数据不会丢失。 注意：当redis启动时，如果rdb持久化和aof持久化都打开了，那么程序会优先使用aof方式来恢复数据集，因为aof方式所保存的数据通常是最完整的。 最后记录下redis服务器的启动与关闭指令： [root@localhost src]# ./redis-server ../redis.conf 启动redis [root@localhost src]# ./redis-cli shutdown 关闭redis Redis 加入系统服务 新建文件 vi /etc/rc.d/init.d/redis 文件内容 #!/bin/sh # chkconfig: 2345 80 90 # # Simple Redis init.d script conceived to work on Linux systems # as it does use of the /proc filesystem. ### BEGIN INIT INFO # Provides: redis_6379 # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: Redis data structure server # Description: Redis data structure server. See https://redis.io ### END INIT INFO REDISPORT=6379 EXEC=/data1/databases/redis/bin/redis-server CLIEXEC=/data1/databases/redis/bin/redis-cli PIDFILE=/var/run/redis_${REDISPORT}.pid CONF=&quot;/etc/redis/${REDISPORT}.conf&quot; function check_pid() { if [ -f $PIDFILE ];then pid=`cat $PIDFILE` if [ -n $pid ]; then running=`ps -p $pid|grep -v &quot;PID TTY&quot; |wc -l` return $running fi fi return 0 } function start() { check_pid running=$? if [ $running -gt 0 ];then echo -n &quot;Redis server now is running, pid=&quot; cat $PIDFILE else echo &quot;Starting Redis server...&quot; $EXEC $CONF &amp; echo $! &gt; $PIDFILE echo &quot;Redis started..., pid=$!&quot; fi return 0 } function stop() { check_pid running=$? if [ $running -gt 0 ];then echo &quot;Stopping ...&quot; PID=$(cat $PIDFILE) $CLIEXEC -p $REDISPORT shutdown while [ -x /proc/${PID} ] do echo &quot;Waiting for Redis to shutdown ...&quot; sleep 1 done fi echo &quot;Redis stopped&quot; return 0 } function status() { check_pid running=$? if [ $running -gt 0 ];then echo -n &quot;Redis server now is running, pid=&quot; cat $PIDFILE else echo &quot;Redis server is stoped&quot; fi return 0 } case &quot;$1&quot; in start) start ;; stop) stop ;; status) status ;; restart) stop start ;; *) echo &quot;Please use start / stop / status / restart as first argument&quot; ;; esac 修改文件权限 chmod 755 /etc/rc.d/init.d/redis 设置开机启动 chkconfig redis on 启动、停止命令 service redis start/stop centos 7 加入系统服务 # cat /usr/lib/systemd/system/redis.service [Unit] Description=Redis persistent key-value database After=network.target After=network-online.target Wants=network-online.target [Service] ExecStart=/data/redis/bin/redis-server /etc/redis/6379.conf --supervised systemd #ExecStop=/usr/libexec/redis-shutdown ExecStop=kill -9 $(ps -ef|grep /data/redis/bin/redis-server | grep 6379 |awk &#39;{print $2}&#39;) Type=notify #User=redis #Group=redis RuntimeDirectory=redis RuntimeDirectoryMode=0755 [Install] WantedBy=multi-user.target 设置开机启动 systemctl enable redis 启动、停止、状态命令 systemctl start/stop/status redis]]></content>
      <categories>
        <category>centos</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装 Nginx]]></title>
    <url>%2FCentOS-7-install-Nginx%2F</url>
    <content type="text"><![CDATA[安装所需环境Nginx 是 C语言 开发，建议在 Linux 上运行，当然，也可以安装 Windows 版本，本篇则使用 CentOS 7 作为安装环境。 一. gcc 安装安装 nginx 需要先将官网下载的源码进行编译，编译依赖 gcc 环境，如果没有 gcc 环境，则需要安装： yum install gcc-c++ 二. PCRE pcre-devel 安装PCRE(Perl Compatible Regular Expressions) 是一个Perl库，包括 perl 兼容的正则表达式库。nginx 的 http 模块使用 pcre 来解析正则表达式，所以需要在 linux 上安装 pcre 库，pcre-devel 是使用 pcre 开发的一个二次开发库。nginx也需要此库。命令： yum install -y pcre pcre-devel 三. zlib 安装zlib 库提供了很多种压缩和解压缩的方式， nginx 使用 zlib 对 http 包的内容进行 gzip ，所以需要在 Centos 上安装 zlib 库。 yum install -y zlib zlib-devel 四. OpenSSL 安装OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及 SSL 协议，并提供丰富的应用程序供测试或其它目的使用。nginx 不仅支持 http 协议，还支持 https（即在ssl协议上传输http），所以需要在 Centos 安装 OpenSSL 库。 yum install -y openssl openssl-devel 所有工具和依赖一起安装 yum install -y openssl openssl-devel zlib zlib-devel pcre pcre-devel gcc-c++ 官网下载 直接下载.tar.gz安装包，地址：https://nginx.org/en/download.html 使用wget命令下载（推荐）。确保系统已经安装了wget，如果没有安装，执行 yum install wget 安装。 wget -c https://nginx.org/download/nginx-1.15.12.tar.gz 我下载的是1.12.0版本，这个是目前的稳定版。 解压依然是直接命令： tar -zxvf nginx-1.15.12.tar.gz cd nginx-1.15.12 配置其实在 nginx-1.15.12 版本中你就不需要去配置相关东西，默认就可以了。当然，如果你要自己配置目录也是可以的。 使用默认配置 ./configure 自定义配置（不推荐） ./configure \ --prefix=/usr/local/nginx \ --conf-path=/usr/local/nginx/conf/nginx.conf \ --pid-path=/usr/local/nginx/conf/nginx.pid \ --lock-path=/var/lock/nginx.lock \ --error-log-path=/var/log/nginx/error.log \ --http-log-path=/var/log/nginx/access.log \ --with-http_gzip_static_module \ --with-http_ssl_module \ --http-client-body-temp-path=/var/temp/nginx/client \ --http-proxy-temp-path=/var/temp/nginx/proxy \ --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \ --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \ --http-scgi-temp-path=/var/temp/nginx/scgi 注：将临时文件目录指定为/var/temp/nginx，需要在/var下创建temp及nginx目录 编译安装make make install 查找安装路径： whereis nginx 启动、停止nginxcd /usr/local/nginx/sbin/ ./nginx ./nginx -s stop ./nginx -s quit ./nginx -s reload 启动时报80端口被占用: nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use) 解决办法，查看占用端口的进程 ➜ ~ lsof -i:80 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME nginx 4214 root 6u IPv4 46826 0t0 TCP *:http (LISTEN) nginx 4216 root 6u IPv4 46826 0t0 TCP *:http (LISTEN) ➜ ~ ps -ef|grep nginx root 4214 1 0 4月27 ? 00:00:00 nginx: master process /usr/bin/nginx root 4216 4214 0 4月27 ? 00:00:00 nginx: worker process root 122099 121530 0 22:06 pts/0 00:00:00 grep --color=auto --exclude-dir=.bzr --exclude-dir=CVS --exclude-dir=.git --exclude-dir=.hg --exclude-dir=.svn nginx ➜ ~ ./nginx -s quit:此方式停止步骤是待nginx进程处理任务完毕进行停止。./nginx -s stop:此方式相当于先查出nginx进程id再使用kill命令强制杀掉进程。 查询nginx进程： ps aux|grep nginx 重启 nginx1.先停止再启动（推荐）：对 nginx 进行重启相当于先停止再启动，即先执行停止命令再执行启动命令。如下： ./nginx -s quit ./nginx 2.重新加载配置文件：当 ngin x的配置文件 nginx.conf 修改后，要想让配置生效需要重启 nginx，使用-s reload不用先停止 ngin x再启动 nginx 即可将配置信息在 nginx 中生效，如下： ./nginx -s reload 启动成功后，在浏览器可以打开页面了 开机自启动即在rc.local增加启动代码就可以了。 vi /etc/rc.local 增加一行 /usr/local/nginx/sbin/nginx设置执行权限： chmod 755 rc.local 到这里，nginx就安装完毕了，启动、停止、重启操作也都完成了，当然，你也可以添加为系统服务。 添加系统服务Centos 6 添加系统服务nginx源码安装完成后默认不会注册为系统服务，所以需要手工添加系统服务脚本。在/etc/init.d目录下新建nginx文件，并更改权限其即可。 新建nginx文件vim /etc/init.d/nginx 填写以下内容(根据自己的实际目录修改): # !/bin/bash # nginx Startup script for the Nginx HTTP Server # this script create it by caffreyxin at 2007.10.15. # it is v.0.0.1 version. # if you find any errors on this scripts, please contact caffreyxin. # and send mail to xinyflove at sina dot com. # # chkconfig: - 85 15 # description: Nginx is a high-performance web and proxy server. # It has a lot of features, but it&#39;s not for everyone. # processname: nginx # pidfile: /usr/local/nginx/logs/nginx.pid # config: /usr/local/nginx/conf/nginx.conf nginxd=/usr/local/nginx/sbin/nginx nginx_config=/usr/local/nginx/conf/nginx.conf nginx_pid=/usr/local/nginx/logs/nginx.pid RETVAL=0 prog=&quot;nginx&quot; # Source function library. . /etc/rc.d/init.d/functions # Source networking configuration. . /etc/sysconfig/network # Check that networking is up. [ ${NETWORKING} = &quot;no&quot; ] &amp;&amp; exit 0 [ -x $nginxd ] || exit 0 # Start nginx daemons functions. start() { if [ -e $nginx_pid ];then echo &quot;nginx already running....&quot; exit 1 fi echo -n $&quot;Starting $prog: &quot; daemon $nginxd -c ${nginx_config} RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; touch /var/lock/subsys/nginx return $RETVAL } # Stop nginx daemons functions. stop() { echo -n $&quot;Stopping $prog: &quot; killproc $nginxd RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; rm -f /var/lock/subsys/nginx /var/run/nginx.pid } # reload nginx service functions. reload() { echo -n $&quot;Reloading $prog: &quot; #kill -HUP `cat ${nginx_pid}` killproc $nginxd -HUP RETVAL=$? echo } # See how we were called. case &quot;$1&quot; in start) start ;; stop) stop ;; reload) reload ;; restart) stop start ;; status) status $prog RETVAL=$? ;; *) echo $&quot;Usage: $prog {start|stop|restart|reload|status|help}&quot; exit 1 esac exit $RETVAL 或https://github.com/xinyflove/MyDocument/blob/master/Nginx/nginxtip:根据自己实际安装目录，修改这两行: nginxd=/usr/local/nginx/sbin/nginx nginx_config=/usr/local/nginx/conf/nginx.conf 修改文件权限chmod 755 /etc/init.d/nginx 设置开机启动chkconfig nginx on 查看开机启动的服务chkconfig --list 命令启动服务：service nginx start 停止服务：service nginx stop 重启服务：service nginx reload CentOS 7 添加系统服务 新建 nginx.server文件 vi /usr/lib/systemd/system/nginx.service 填写以下内容 #nginx服务配置到该文件中 # cat /usr/lib/systemd/system/nginx.service #服务描述性的配置 [Unit] Description=nginx - high performance web server Documentation=http://nginx.org/en/docs/ After=network.target remote-fs.target nss-lookup.target #服务关键配置 [Service] Type=forking #pid文件位置 #要与nginx配置文件中的pid配置路径一致，这个很重要，否则会服务启动失败 PIDFile=/usr/local/nginx/logs/nginx.pid #启动前检测 nginx配置文件 是否正确 ExecStartPre=/usr/local/nginx/sbin/nginx -t -c /usr/local/nginx/conf/nginx.conf #启动 ExecStart=/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf #重启 ExecReload=/bin/kill -s HUP $MAINPID #关闭 ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.target 启动nginx服务 systemctl start nginx.service 设置开机自启动 systemctl enable nginx.service 停止开机自启动 systemctl disable nginx.service 查看服务当前状态 systemctl status nginx.service 重新启动服务 systemctl restart nginx.service 查看所有已启动的服务 systemctl list-units --type=service 如下出现Failed to execute operation: Access denied无权限错误，则需关闭selinux，操作如下： # vi /etc/sysconfig/selinux … SELINUX=disabled … # setenforce 0 # getenforce Permissive 新旧系统服务命令对比 任务 旧指令 新指令 使某服务自动启动 chkconfig –level 3 nignx on systemctl enable nignx.service 使某服务不自动启动 chkconfig –level 3 nignx off systemctl disable nignx.service 检查服务状态 service nignx status systemctl status nignx.service （服务详细信息） systemctl is-active nignx.service （仅显示是否 Active) 显示所有已启动的服务 chkconfig –list systemctl list-units –type=service 启动某服务 service nignx start systemctl start nignx.service 停止某服务 service nignx stop systemctl stop nignx.service 重启某服务 service nignx restart systemctl restart nignx.service]]></content>
      <categories>
        <category>centos</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装 MySQL 5.7]]></title>
    <url>%2FCentOS-7-install-MySQL-5-7%2F</url>
    <content type="text"><![CDATA[CentOS 7 安装MySQL5.7 一、安装包下载下载地址：https://dev.mysql.com/downloads/mysql/5.6.html#downloads 国内可以使用163镜像加速下载：http://mirrors.163.com/mysql/Downloads/MySQL-5.7/ 选择相应的平台和版本下载 二、安装1.将下载好的安装到解压到/usr/local目录下tar -zxvf mysql-5.7.26-linux-glibc2.12-x86_64.tar.gz -C /usr/local/ 2.进入/usr/local目录cd /usr/local/ 3.为mysql安装目录创建软链接ln -s mysql-5.7.26-linux-glibc2.12-x86_64 mysql 4.为centos添加mysql用户组和mysql用户(-s /bin/false参数指定mysql用户仅拥有所有权，而没有登录权限)groupadd mysql useradd -r -g mysql -s /bin/false mysql 5.进入安装mysql软件的目录，命令如下cd /usr/local/mysql 6.修改当前目录拥有者为新建的mysql用户，命令如下：chown -R mysql:mysql ./ 7.安装mysql，命令如下：./bin/mysqld --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data --initialize 可能会出现如下错误 ./bin/mysqld: error while loading shared libraries: libaio.so.1: cannot open shared object file: No such file or directory 解决方法 yum install -y libaio Loaded plugins: fastestmirror Determining fastest mirrors base | 3.6 kB 00:00:00 epel | 5.3 kB 00:00:00 extras | 3.4 kB 00:00:00 updates | 3.4 kB 00:00:00 (1/4): epel/x86_64/updateinfo | 977 kB 00:00:00 (2/4): extras/7/x86_64/primary_db | 200 kB 00:00:00 (3/4): updates/7/x86_64/primary_db | 5.7 MB 00:00:00 (4/4): epel/x86_64/primary_db | 6.7 MB 00:00:00 Resolving Dependencies --&gt; Running transaction check ---&gt; Package libaio.x86_64 0:0.3.109-13.el7 will be installed --&gt; Finished Dependency Resolution Dependencies Resolved ======================================================================================================================================================================================= Package Arch Version Repository Size ======================================================================================================================================================================================= Installing: libaio x86_64 0.3.109-13.el7 base 24 k Transaction Summary ======================================================================================================================================================================================= Install 1 Package Total download size: 24 k Installed size: 38 k Downloading packages: libaio-0.3.109-13.el7.x86_64.rpm | 24 kB 00:00:00 Running transaction check Running transaction test Transaction test succeeded Running transaction Installing : libaio-0.3.109-13.el7.x86_64 1/1 Verifying : libaio-0.3.109-13.el7.x86_64 1/1 Installed: libaio.x86_64 0:0.3.109-13.el7 Complete! 如果出现如下所示则为安装成功 2019-05-20T14:14:00.607305Z 0 [Warning] InnoDB: New log files created, LSN=45790 2019-05-20T14:14:00.643051Z 0 [Warning] InnoDB: Creating foreign key constraint system tables. 2019-05-20T14:14:00.833733Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: 83d6fb34-7b09-11e9-96b7-000c2932f18d. 2019-05-20T14:14:00.892413Z 0 [Warning] Gtid table is not ready to be used. Table &#39;mysql.gtid_executed&#39; cannot be opened. 2019-05-20T14:14:00.893234Z 1 [Note] A temporary password is generated for root@localhost: sBN18?Wq&amp;&gt;&gt;I 2019-05-20T14:14:01.309353Z 1 [Warning] &#39;user&#39; entry &#39;root@localhost&#39; ignored in --skip-name-resolve mode. 2019-05-20T14:14:01.309376Z 1 [Warning] &#39;user&#39; entry &#39;mysql.session@localhost&#39; ignored in --skip-name-resolve mode. 2019-05-20T14:14:01.309382Z 1 [Warning] &#39;user&#39; entry &#39;mysql.sys@localhost&#39; ignored in --skip-name-resolve mode. 2019-05-20T14:14:01.309392Z 1 [Warning] &#39;db&#39; entry &#39;performance_schema mysql.session@localhost&#39; ignored in --skip-name-resolve mode. 2019-05-20T14:14:01.309395Z 1 [Warning] &#39;db&#39; entry &#39;sys mysql.sys@localhost&#39; ignored in --skip-name-resolve mode. 2019-05-20T14:14:01.309400Z 1 [Warning] &#39;proxies_priv&#39; entry &#39;@ root@localhost&#39; ignored in --skip-name-resolve mode. 2019-05-20T14:14:01.309416Z 1 [Warning] &#39;tables_priv&#39; entry &#39;user mysql.session@localhost&#39; ignored in --skip-name-resolve mode. 2019-05-20T14:14:01.309420Z 1 [Warning] &#39;tables_priv&#39; entry &#39;sys_config mysql.sys@localhost&#39; ignored in --skip-name-resolve mode. 其实已经生成了root的临时账号： A temporary password is generated for root@localhost: sBN18?Wq&amp;&gt;&gt;I 8.开启mysql服务，命令如下：./support-files/mysql.server start 如果出现文件不存在错误，则说明mysql配置文件/etc/my.cnf中的路径不对，修改内容如下，datadir和socket都修改成mysql的安装目录下，增加[client]板块，用于命令行连接mysql数据库。 #在etc下新建配置文件my.cnf，并在该文件内添加以下配置 [mysql] # 设置mysql客户端默认字符集 default-character-set=utf8mb4 [mysqld] skip-name-resolve #skip-grant-tables #设置3306端口 port = 3306 # 设置mysql的安装目录 basedir=/usr/local/mysql # 设置mysql数据库的数据的存放目录 datadir=/usr/local/mysql/data # 允许最大连接数 max_connections=200 # 设置忽略大小写 lower_case_table_names = 1 # 服务端使用的字符集默认为8比特编码的latin1字符集 # 指定编码 character-set-client-handshake=FALSE character-set-server=utf8mb4 collation-server=utf8mb4_unicode_ci init_connect=&#39;SET NAMES utf8mb4&#39; # 开启ip绑定 bind-address = 0.0.0.0 # 创建新表时将使用的默认存储引擎 default-storage-engine=INNODB lower_case_table_names=1 max_allowed_packet=16M [mysqld_safe] log-error=/var/log/mysql/mysqld.log pid-file=/var/run/mysql/mysqld.pid #指定客户端连接mysql时的编码设置 [client] default-character-set=utf8mb4 创建相应目录并赋权 mkdir -p /var/log/mysql/ chown -R mysql:mysql /var/log/mysql mkdir -p /var/run/mysql chown -R mysql:mysql /var/run/mysql 9.重新启开启mysql服务，如下所示则开启成功！./support-files/mysql.server start Starting MySQL.. SUCCESS! 10.将mysql进程放入系统进程中，命令如下：cp support-files/mysql.server /etc/init.d/mysqld 11.重新启动mysql服务，命令如下：service mysqld restart Shutting down MySQL.... SUCCESS! Starting MySQL. SUCCESS! 修改文件权限 chmod 755 /etc/rc.d/init.d/mysqld 设置开机启动 chkconfig mysqld on 启动、停止命令 service mysqld start/stop 12.配置mysql环境变量vi /etc/profile export PATH=$PATH:/usr/local/mysql/bin 保存退出，再编译下： source /etc/profile 13.使用随机密码登录mysql数据库，命令如下：mysql -u root -p 输入密码回车可能出现如下错误 mysql -uroot -p Enter password: ERROR 2002 (HY000): Can&#39;t connect to local MySQL server through socket &#39;/usr/local/mysql/mysql.sock&#39; (2) 查看是否系统自带的mariadb rpm -qa|grep mariadb mariadb-libs-5.5.60-1.el7_5.x86_64 卸载系统自动的mariadb yum remove mariadb-libs-5.5.60-1.el7_5.x86_64 可能出现如下错误 mysql -uroot -p mysql: error while loading shared libraries: libncurses.so.5: cannot open shared object file: No such file or directory 安装相关依赖 yum install libncurses.so.5 Last metadata expiration check: 0:11:30 ago on Tue 07 Jan 2020 07:57:07 AM CST. Dependencies resolved. =================================================================================================================================================================================================================== Package Arch Version Repository Size =================================================================================================================================================================================================================== Installing: ncurses-compat-libs i686 6.1-7.20180224.el8 BaseOS 350 k Installing dependencies: glibc32 x86_64 2.28-42.1.el8 AppStream 1.5 M libgcc i686 8.2.1-3.5.el8 BaseOS 84 k libstdc++ i686 8.2.1-3.5.el8 BaseOS 485 k Transaction Summary =================================================================================================================================================================================================================== Install 4 Packages Total download size: 2.4 M Installed size: 8.3 M Is this ok [y/N]: y Downloading Packages: (1/4): libgcc-8.2.1-3.5.el8.i686.rpm 72 kB/s | 84 kB 00:01 (2/4): glibc32-2.28-42.1.el8.x86_64.rpm 596 kB/s | 1.5 MB 00:02 (3/4): libstdc++-8.2.1-3.5.el8.i686.rpm 180 kB/s | 485 kB 00:02 (4/4): ncurses-compat-libs-6.1-7.20180224.el8.i686.rpm 227 kB/s | 350 kB 00:01 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Total 510 kB/s | 2.4 MB 00:04 Running transaction check Transaction check succeeded. Running transaction test Transaction test succeeded. Running transaction Preparing : 1/1 Installing : libgcc-8.2.1-3.5.el8.i686 1/4 Running scriptlet: libgcc-8.2.1-3.5.el8.i686 1/4 Installing : glibc32-2.28-42.1.el8.x86_64 2/4 Running scriptlet: glibc32-2.28-42.1.el8.x86_64 2/4 Installing : libstdc++-8.2.1-3.5.el8.i686 3/4 Running scriptlet: libstdc++-8.2.1-3.5.el8.i686 3/4 Installing : ncurses-compat-libs-6.1-7.20180224.el8.i686 4/4 Running scriptlet: ncurses-compat-libs-6.1-7.20180224.el8.i686 4/4 Verifying : glibc32-2.28-42.1.el8.x86_64 1/4 Verifying : libgcc-8.2.1-3.5.el8.i686 2/4 Verifying : libstdc++-8.2.1-3.5.el8.i686 3/4 Verifying : ncurses-compat-libs-6.1-7.20180224.el8.i686 4/4 Installed: ncurses-compat-libs-6.1-7.20180224.el8.i686 glibc32-2.28-42.1.el8.x86_64 libgcc-8.2.1-3.5.el8.i686 libstdc++-8.2.1-3.5.el8.i686 Complete! 如果是 CentOS 8 还需要执行以下脚本 ln -s /usr/lib64/libncurses.so.6 /usr/lib64/libncurses.so.5 ln -s /usr/lib64/libtinfo.so.6 /usr/lib64/libtinfo.so.5 输入随机密码登录成功： Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 2010 Server version: 5.7.26 MySQL Community Server (GPL) Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement. mysql&gt; 14.进入mysql操作行，为root用户设置新密码（比如设为123456）：在13条已经登录的终端中输入如下命令： alter user &#39;root&#39;@&#39;localhost&#39; identified by &#39;123456&#39;; # 或者 use mysql update user set authentication_string=password(&#39;新密码&#39;) where user=&#39;root&#39;; 15.设置允许远程连接数据库，命令如下：先选择数据库： use mysql update user set user.Host=&#39;%&#39; where user.User=&#39;root&#39;; 查看修改后的值： select user,host from user; 16.刷新权限，命令如下：flush privileges; 17、开启3306防火墙端口，然后即可远程连接mysql（因为我的防火墙是全部关闭，所以省略了这步）18、如果还是无法远程连接，查看/etc/my.cnf找到bind-address = 127.0.0.1这一行 改为bind-address = 0.0.0.0即可 19、添加新的用户并授权CREATE USER &#39;developer&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39;; grant all privileges on *.* to &#39;developer&#39;@&#39;%&#39; identified by &#39;123456&#39;; GRANT Grant Option ON *.* TO &#39;developer&#39;@&#39;%&#39;; flush privileges;]]></content>
      <categories>
        <category>centos</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql配置主从复制]]></title>
    <url>%2FMysql-Master-Slave%2F</url>
    <content type="text"><![CDATA[一、概述Mysql Replication（复制） 即 主从同步（Master/Slave）： 主要用于数据库的备份，负载均衡，读写分离等。 1、数据复制技术有以下一些特点：(1) 数据分布(2) 负载平衡(load balancing)，读写分离，主写从读(3) 备份(4) 高可用性(high availability)和容错 2、复制如何工作从高层来看，复制分成三步：(1) master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）；(2) slave将master的binary log events拷贝到它的中继日志(relay log)；(3) slave重做中继日志中的事件，将改变反映它自己的数据。 二、数据备份还原在做主从同步之前首先需要对主库进行数据备份，恢复到所有的从数据库，数据库备份有冷备和热备，冷备即拷贝所有的数据文件及日志文件到从服务器， 这里使用mysqldump工具做在线热备 步骤:（这里需要备份的数据库为 db_test） 1、Master锁定库，使只能读取不能写入mysql &gt; flush tables with read lock; 2、Master导出备份~$ mysqldump –master-data -uroot -p db_test&gt;db_test.sql 说明：–master-data参数在生成的dump 文件中产生一条 CHANGE MASTER TO 命令，查看可知master当前使用的binlog文件名 3、Slave导入备份~$ mysql -uroot -p db_test&lt;db_test.sql 4、最后配置好同步以后，Master解除写锁定mysql &gt; unlock tables; 三、配置参考1、网络配置1主1从，主从数据库处于同一装有CentOS机器上，使用docker运行，可互相访问。 主数据库master端口：3311 从数据库slave1端口：3312 2、master配置3311.cnf文件mysqld段： [mysqld]server-id=1log-bin=mysql-bin说明：必需配置，server-id指定服务器唯一id，不可重复，log-bin开启binlog日志 运行master docker run --name mysql3311 -v $(PWD)/3311.cnf:/etc/mysql/conf.d/my.cnf -p 3311:3306 -e MYSQL_ROOT_PASSWORD=123456 -tid mysql:5.6 通过mysql客户端连胜主库，设置复制账号： GRANT REPLICATION SLAVE ON *.* TO &#39;test&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39;; FLUSH PRIVILEGES; show master status; 说明：添加一个 test 账号在任何机器上使用 123456 这个密码对任何数据库行使 replication slave 权限 查看Master状态： mysql &gt; show master status; mysql&gt; show master status;+——————+———-+————–+——————+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+——————+———-+————–+——————+| mysql-bin.000022 | 389 | | |+——————+———-+————–+——————+ 3、Slave配置3312.cnf文件配置: [mysqld]server-id=2log-bin=mysql-bin 运行slave docker run --name mysql3312 -v $(PWD)/3312.cnf:/etc/mysql/conf.d/my.cnf -p 3312:3306 -e MYSQL_ROOT_PASSWORD=123456 -tid mysql:5.6 使用mysql客户端连上从库，设置主从复制 stop slave; CHANGE MASTER TO MASTER_HOST = &#39;172.20.8.113&#39;, MASTER_USER = &#39;test&#39;, MASTER_PASSWORD = &#39;123456&#39;, MASTER_PORT = 3311, MASTER_RETRY_COUNT = 0, MASTER_LOG_POS = 389; START SLAVE; SHOW SLAVE STATUS ; 核对host、user、master_log_file是否正确，Slave_IO_Running: YesSlave_SQL_Running: Yes这两项yes，说明配置成功。 最后别忘了，Master解除写锁定： mysql &gt; unlock tables; 注意：如果Master的mysql服务重启会生成新的bin log日志，这时候，Slave也需要重启一下服务或者stop slave - start slave， 如果slave服务不重启，则可以修改 mysql - replication -slave 自动生成的配置文件：/var/lib/mysql/master.info 18mysql-bin.000022398172.20.8.113test123456331160查看第二行 mysq-bin文件名是否跟Master上对应，如果不对应可直接修改； 四、常见错误1、master发生故障，经修复后启动后，slave无法与master同步报错：Got fatal error 1236 from master when reading data from binary log 原因：master重启后，mysql的binlog会重新生成，相应的记录位置会改变 解决方法： -master： mysql &gt; flush logs; mysql &gt; show master status; 记录下File和Position值 -slave： mysql &gt; stop slave; mysql &gt; CHANGE MASTER TO MASTER_LOG_FILE=’mysql-bin.000049’,MASTER_LOG_POS=1359; mysql &gt; start slave; mysql &gt; show slave status\G; 2、slave发生故障，设置正确，但是无法初始化报错：ERROR 1201 (HY000): Could not initialize master 解决方法： -master： mysql &gt; flush logs; mysql &gt; show master status; 记录下File和Position值 -slave： mysql &gt; reset slave; mysql &gt; CHANGE MASTER TO MASTER_HOST = ‘172.20.8.113’, MASTER_USER = ‘test’, MASTER_PASSWORD = ‘123456’, MASTER_PORT = 3311, MASTER_RETRY_COUNT = 0, MASTER_LOG_POS = 389; mysql &gt; start slave; mysql &gt; show slave status\G;]]></content>
      <categories>
        <category>myql</category>
        <category>master</category>
        <category>slave</category>
      </categories>
      <tags>
        <tag>myql</tag>
        <tag>master</tag>
        <tag>slave</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决NVIDIA驱动程序安装和加载问题]]></title>
    <url>%2FHackintosh-Nvidia-Driver%2F</url>
    <content type="text"><![CDATA[问题6：您在菜单栏或Nvidia驱动程序管理器首选项面板中选择了Nvidia Web Drivers，但是当您选择时重启OS X默认图形驱动程序已选中。 当您的主板没有本机NVRAM支持（例如技嘉100系列主板）时会导致这种情况。 修复： 设置模拟NVRAM以在boot-args中存储nvda_drv = 1引导标志。 在 此处 下载最新的Clover安装程序pkg ，启动安装程序并在此处选择自定义： 之后确保您选择了EmuVariableUefi-64： 继续完成Clover升级安装并重新启动。重新启动后打开系统首选项并转到Nvidia驱动程序管理器。确保您拥有最新的驱动程序是个好主意，因此请转到更新选项卡并单击立即检查按钮。如果有更新，请执行更新并在它告诉您时重新启动。你应该在这一点上完成。如果没有更新，请继续执行下一步。 如果没有升级，请单击“图形驱动程序”选项卡，然后选择NVIDIA Web Drive旁边的单选按钮。重启。 重新启动后，应该说您使用的是NVIDIA网络驱动程序。如果它仍然不起作用，那么您可能需要重新运行Clover安装程序并选择“在目标卷上安装RC脚本”。 -————————— 如果您遇到任何其他错误，请告知我们，我将使用解决方案更新此帖子。 nvidia显卡驱动 https://www.tonymacx86.com/nvidia-drivers/https://www.tonymacx86.com/threads/nvidia-releases-alternate-graphics-drivers-for-macos-sierra-10-12-6-378-05-05-25.227494/ 解决NVIDIA驱动程序安装和加载问题 https://www.tonymacx86.com/threads/solving-nvidia-driver-install-loading-problems.161256/]]></content>
      <categories>
        <category>Mac osx</category>
        <category>Hackintosh</category>
        <category>Nvidia</category>
      </categories>
      <tags>
        <tag>Mac osx</tag>
        <tag>Hackintosh</tag>
        <tag>Nvidia</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[黑苹果]]></title>
    <url>%2FHackintosh%2F</url>
    <content type="text"><![CDATA[写在开头 什么是黑苹果？ 自从苹果采用Intel的处理器，OSX被黑客破解后可以安装在Intel CPU与部分AMDCPU的机器上。从而出现了一大批非苹果设备而使用苹果操作系统的机器，被称为黑苹果(Hackintosh)；在Mac苹果机上面安装原版Mac系统的被称为白苹果（Macintosh），与黑苹果相对。 MAC系统 OS X 是全球领先的操作系统。基于坚如磐石的 UNIX ，设计简单直观，让处处充满创新的Mac 安全易用，高度兼容，出类拔萃。UNIX 之威力，iMac 之简单让Mac OS X 既简单易用且功能强大。所有的一切 - 从启动 Mac 后所看到的桌面，到你日常使用的应用程序，都设计得简约精致。无论是浏览网页、查看邮件和与外地朋友视频聊天，所有事情都简单高效、趣味盎然。当然，简化复杂任务要求尖端科技，而 Mac OS X 正拥有这些尖端科技。它不仅使用基础坚实、久经考验的 UNIX 系统提供空前的稳定性，还提供超强性能、超炫图形并支持互联网标准。 参考资料：High Sierra 以及 Mojave 镜像集合贴 http://bbs.pcbeta.com/viewthread-1753062-1-1.html High Sierra 和 Mojave 镜像大全 https://blog.iamzhl.top/High-Sierra-and-Mojave-Images-update.html 笔记本黑果安装向导 http://bbs.pcbeta.com/viewthread-1779539-1-7.html UEFI+GPT+Clover macOS原版单、双系统双版教程(正式版) https://alansachin.github.io/2017/05/07/UEFI+GPT+Clover-macOS%E5%8E%9F%E7%89%88%E5%8D%95-%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%8F%8C%E7%89%88%E6%95%99%E7%A8%8B(%E6%AD%A3%E5%BC%8F%E7%89%88) 黑苹果安装 https://mp.weixin.qq.com/s/oYIrNOy8Co-SbKTPlGOlLw 增强型 macOS 维护系统https://pe.firewolf.app/cn/ 黑苹果EFI https://zhih.me/hackintosh clover-configurator https://mackie100projects.altervista.org/download-clover-configurator/ 7700hq 微星GS63VR 安装10.12，除声卡外基本完美 http://bbs.pcbeta.com/forum.php?mod=viewthread&amp;tid=1736121&amp;highlight=gs63 黑果小兵的部落阁 https://blog.daliansky.net/ 黑苹果安装从0开始—-clover优盘引导改硬盘引导篇 http://bbs.pcbeta.com/viewthread-1683571-1-1.html Mac High Sierra外接显示器设置（解决字体模糊问题，开启high dpi） https://yanke.info/?id=74 一键开启MacOS HiDPI https://zhih.me/one-key-hidpi/ mac 10.14 Mojave 外接屏幕字体发虚 https://www.cnblogs.com/mooniitt/p/9753112.html nvidia显卡驱动 https://www.tonymacx86.com/nvidia-drivers/https://www.tonymacx86.com/threads/nvidia-releases-alternate-graphics-drivers-for-macos-sierra-10-12-6-378-05-05-25.227494/ 黑苹果从sierra升级到high sierra https://www.tonymacx86.com/threads/update-directly-to-macos-high-sierra.232707/ Broadcom BCM94352z/DW1560驱动新姿势[新方法] https://blog.daliansky.net/Broadcom-BCM94352z-DW1560-drive-new-posture.html]]></content>
      <categories>
        <category>Mac osx</category>
        <category>Hackintosh</category>
      </categories>
      <tags>
        <tag>Mac osx</tag>
        <tag>Hackintosh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iOS越狱]]></title>
    <url>%2FiOS-Jailbreaking%2F</url>
    <content type="text"><![CDATA[写在开头 什么是iOS越狱？ iOS越狱（英语：iOS Jailbreaking）是获取iOS设备的Root权限的技术手段。iOS系统的Root用户对除Apple特定私有进程之外的其他进程不开放，使用Root用户运行的进程在进程树中的PID为0。程序员在iOS中挖掘出一些可以将进程提权至PID0的漏洞（例如Task For PID0）。利用Root用户运行的进程意味着可以任意读取设备其中的APFS分区表和内核缓存地址，拥有一个用户可以随意控制的PID0进程还不能称之为一个完整的越狱。之后还需要利用Bypass（旁路）手段绕过Apple在iOS系统中设置的其他安全防护措施，将APFS或HFS+文件系统中的ROOTFS分区重新挂载（Remount）为可读写（R/W），从而达到添加二进制文件和守护进程的目的。通常大众用户认为能够正常使用Cydia才能被称为越狱，但其实这种说法是不正确的。但通过此软件可以完成越狱前不可能进行的动作，例如安装App Store以外未经过签名的应用、修改SpringBoard、运行Shell程序、使有运营商锁的设备利用卡贴解锁后通过替换配置文件形式实现本地化（例如“去除+86”，解锁FaceTime功能）。[1] 越狱软件分发商店Cydia的创始人Jay Freeman在2010年10月估计，全球大概有10%的iPhone曾进行过越狱[2]。 当一台iOS设备越狱之后，用户将能实践很多此前无能以得的各种功能，或是使用很多被Apple认为不安全的软件。比如：虚拟定位、修改iPhone的登录设备、翻越防火墙、修改设备界面字体和主题、快速转换自定义铃声、使用自己编程的软件或插件等。 越狱工具： 挂神团队越狱 https://app.nk8686.xin/ios/ electra越狱 https://coolstar.org/electra/ pp助手越狱 https://pro.25pp.com/ppghost 爱思越狱助手：https://www.i4.cn/ iOS9.2~iOS9.3.3越狱修复 http://jb92.i4.cn/]]></content>
      <categories>
        <category>ios</category>
        <category>Jailbreaking</category>
      </categories>
      <tags>
        <tag>ios</tag>
        <tag>Jailbreaking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Reactor模式的角色构成]]></title>
    <url>%2FReactor%2F</url>
    <content type="text"><![CDATA[Reactor模式的角色构成（Reactor模式一共有5种角色构成）：1. Handle（句柄或是描述符）：本质上表示一种资源，是由操作系统提供的；改资源用于表示一个个的事件，比如说文件描述符，或是针对网络编程过程中的Socket描述符。事件即可以来自于外部，可以来自于内部；外部事件比如说客户端的连接请求，客户端发送过来的数据等；内部事件，比如说操作系统产生的定时器事件等。它本质上就是一个文件描述符。 2. Synchronous Event Demultiplexer（同步事件分离器）：它本身是一个系统调用，用于等待事件的发生（事件可能是一个，也可能是多个）。调用方在调用它的时候会被阻塞，一直阻塞到同步事件分离器上有事件产生为止。对于Linux来说，同步事件分离器指的就是常用的I/O多路复用机制，比如说select、poll、epoll等。在Java NIO领域中，同步事件分离器对应的组件就是Slector；对应的阻塞方法就是select方法。 3. Event Handler（事件处理器）：本身由多个回调方法构成，这些方法构成了与应用相关的对于某个事件的反馈机制。Netty相比于Java NIO来说，在事件处理器这个角色上进行了一个升级，它为我们开发者提供了大量的回调方法，供我们在特定事件产生时实现相应的回调方法进行业务逻辑的处理。 4. Contrete Event Handler（具体事件处理器）：是事件处理器的实现。它本身实现了事件处理器所提供的各个回调方法，从而实现了特定于业务的逻辑。它本质上就是我们所编写的一个个的处理器实现。 5. Initiation Dispatcher（初始分发器）：实际上就是Reactor角色。它本身定义了一些规范，这些规范用于控制事件的调度方式，同时又提供了应用进行事件处理器的注册、删除等设施。它本身是整个事件处理器的核心所在，Initiation Dispatcher会通过同步事件分离器来等待事件的发生。一旦事件发生，Initiation Dispatcher首先会分离出每一个事件，然后调用事件处理器，最后调用相关的回调方法来处理这些事件。 Reactor模式流程 当应用向Initiation Dispatcher注册具体的事件处理器时，应用会标识出该事件处理器希望Initiation Dispatcher在某个事件发生时向其通知该事件，该事件与Handle关联。 Initiation Dispatcher会要求每个事件处理器向其传递内部的Handle。该Handler向操作系统标识了事件处理器。 当所有的事件处理器注册完毕后，应用会调用handle_events方法来启动Initiation Dispatcher的事件循环。这时，Initiation Dispatcher会将每个注册的事件管理的handle合并起来，并使用同步事件分离器等待这些事件的发生。比如说，TCP协议层会使用select同步事件分离器操作来等待客户端发送的数据到达连接的socket handle上。 当与某个事件源对应的Handle变为ready状态时（比如说，TCP socket变为等待读状态时），同步事件分离器就会通知Initiation Dispatcher。 Initiation Dispatcher会触发事件处理器的回调方法，从而响应这个处于ready状态的Handle。当事件发生时，Initiation Dispatcher会将被事件源激活的Handle[key]来寻找并分发恰当的事件处理器回调方法。 Initiation Dispatcher会回调事件处理器的handle_event回调方法来执行特定于应用的功能（开发者自己所编写的功能），从而响应这个事件。所发生的事件类型可以作为该方法参数并被该方法内部使用来执行额外的特定于服务的分类和分发。]]></content>
      <categories>
        <category>reactor</category>
        <category>nio</category>
        <category>netty</category>
      </categories>
      <tags>
        <tag>reactor</tag>
        <tag>nio</tag>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清除Kubernetes环境]]></title>
    <url>%2FClean-Kubernetes-Environment%2F</url>
    <content type="text"><![CDATA[在学习过程中可能有机器加入Kubernetes时设置出错，可以从Kubernetes集群中移除并清理，然后再重新加入 清理kubelet挂载的磁盘和设置df -h|grep kubelet |awk -F % &#39;{print $2}&#39;|xargs umount rm /var/lib/kubelet/* -rf 清理kubernetes设置rm /etc/kubernetes/* -rf 清理rancher设置rm /var/lib/rancher/* -rf 清理etc设置rm /var/lib/etcd/* -rf 清理cni设置rm /var/lib/cni/* -rf 清理iptable设置iptables -F &amp;&amp; iptables -t nat –F 清理flannel设置ip link del flannel.1 清理docker containerdocker ps -a|awk &#39;{print $1}&#39;|xargs docker rm -f 清理docker挂载的磁盘docker volume ls|awk &#39;{print $2}&#39;|xargs docker volume rm 合并在一起df -h|grep kubelet |awk -F % &#39;{print $2}&#39;|xargs umount rm /var/lib/kubelet/* -rf rm /etc/kubernetes/* -rf rm /var/lib/rancher/* -rf rm /var/lib/etcd/* -rf rm /var/lib/cni/* -rf iptables -F &amp;&amp; iptables -t nat –F ip link del flannel.1 docker ps -a|awk &#39;{print $1}&#39;|xargs docker rm -f docker volume ls|awk &#39;{print $2}&#39;|xargs docker volume rm]]></content>
      <categories>
        <category>kubernetes</category>
        <category>docker</category>
        <category>rancher</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>docker</tag>
        <tag>rancher</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 设置DNS服务器]]></title>
    <url>%2FCentOS-7-Seting-DNS-Server%2F</url>
    <content type="text"><![CDATA[CentOS 7需要使用全新的命令行工具 nmcli 来设置 显示当前网络连接[root@bogon ~]# nmcli connection show NAME UUID TYPE DEVICE cni0 b2b8f5f9-acd2-42fd-9ec9-a76282425cd9 bridge cni0 docker0 33ebd49e-fd1b-4a2c-8261-c0463f4f4146 bridge docker0 enp2s0 b6579214-0ba6-4bf0-9319-2e0e4f584afd ethernet enp2s0 virbr0 976717ae-c3ae-4582-aa09-039c26bef80d bridge virbr0 修改当前网络连接对应的DNS服务器，这里的网络连接可以用名称或者UUID来标识[root@bogon ~]# nmcli con mod enp2s0 ipv4.dns &quot;114.114.114.114 8.8.8.8&quot; [root@bogon ~]# 将dns配置生效[root@bogon ~]# nmcli con up enp2s0 Connection successfully activated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/7) 测试网络[root@bogon ~]# ping www.baidu.com PING www.a.shifen.com (14.215.177.39) 56(84) bytes of data. 64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=1 ttl=53 time=5.48 ms 64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=2 ttl=53 time=5.60 ms 64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=3 ttl=53 time=5.48 ms 64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=4 ttl=53 time=8.57 ms 64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=5 ttl=53 time=5.54 ms ^C --- www.a.shifen.com ping statistics --- 5 packets transmitted, 5 received, 0% packet loss, time 4005ms rtt min/avg/max/mdev = 5.485/6.138/8.575/1.222 ms [root@bogon ~]#]]></content>
      <categories>
        <category>centos</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mycat 按月分表]]></title>
    <url>%2Fmycat-single-database-log-table-part-by-month%2F</url>
    <content type="text"><![CDATA[什么是MYCAT• 一个彻底开源的，面向企业应用开发的大数据库集群• 支持事务、ACID、可以替代MySQL的加强版数据库• 一个可以视为MySQL集群的企业级数据库，用来替代昂贵的Oracle集群• 一个融合内存缓存技术、NoSQL技术、HDFS大数据的新型SQL Server• 结合传统数据库和新型分布式数据仓库的新一代企业级数据库产品• 一个新颖的数据库中间件产品 Mycat关键特性• 支持SQL92标准• 支持MySQL、Oracle、DB2、SQL Server、PostgreSQL等DB的常见SQL语法• 遵守Mysql原生协议，跨语言，跨平台，跨数据库的通用中间件代理。• 基于心跳的自动故障切换，支持读写分离，支持MySQL主从，以及galera cluster集群。• 支持Galera for MySQL集群，Percona Cluster或者MariaDB cluster• 基于Nio实现，有效管理线程，解决高并发问题。• 支持数据的多片自动路由与聚合，支持sum,count,max等常用的聚合函数,支持跨库分页。• 支持单库内部任意join，支持跨库2表join，甚至基于caltlet的多表join。• 支持通过全局表，ER关系的分片策略，实现了高效的多表join查询。• 支持多租户方案。• 支持分布式事务（弱xa）。• 支持XA分布式事务（1.6.5）。• 支持全局序列号，解决分布式下的主键生成问题。• 分片规则丰富，插件化开发，易于扩展。• 强大的web，命令行监控。• 支持前端作为MySQL通用代理，后端JDBC方式支持Oracle、DB2、SQL Server 、 mongodb 、巨杉。• 支持密码加密• 支持服务降级• 支持IP白名单• 支持SQL黑名单、sql注入攻击拦截• 支持prepare预编译指令（1.6）• 支持非堆内存(Direct Memory)聚合计算（1.6）• 支持PostgreSQL的native协议（1.6）• 支持mysql和oracle存储过程，out参数、多结果集返回（1.6）• 支持zookeeper协调主从切换、zk序列、配置zk化（1.6）• 支持库内分表（1.6）• 集群基于ZooKeeper管理，在线升级，扩容，智能优化，大数据处理（2.0开发版）。一、分表规则dm_log和dm_opendoor_record表每年数据量两千万左右，平均每个月两百万左右，mysql单表数据量达到800万时性能出现明显下降，此时需要考虑优化。优先方案考虑优化程序以及sql语句，再优化表结构，最后才是分库分表。自然月分表，每个月分一张表，分表规则定义在MYCAT_HOME/conf/rule.xml中具体如下： &lt;tableRule name=&quot;dm_log_sharding-by-date&quot;&gt; &lt;rule&gt; &lt;columns&gt;logtime&lt;/columns&gt; &lt;algorithm&gt;partbymonth&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;tableRule name=&quot;dm_opendoor_record_sharding-by-date&quot;&gt; &lt;rule&gt; &lt;columns&gt;opertime&lt;/columns&gt; &lt;algorithm&gt;partbymonth&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;function name=&quot;partbymonth&quot; class=&quot;io.mycat.route.function.PartitionByMonth&quot;&gt; &lt;property name=&quot;dateFormat&quot;&gt;yyyy-MM-dd HH:mm:ss&lt;/property&gt; &lt;property name=&quot;sBeginDate&quot;&gt;2014-01-01 00:00:00&lt;/property&gt; &lt;property name=&quot;sEndDate&quot;&gt;2014-12-31 00:00:00&lt;/property&gt; &lt;/function&gt; dm_log表按logtime字段根据partbymonth算法分表，dm_opendoor_record表按opertime字段根据partbymonth算法分表，算法partbymonth中的dateFormat定义时间格式，在sql语句增删改查中时间需要按照定义格式传入，才能正常执行分表算法。分表名称定义在MYCAT_HOME/conf/schema.xml &lt;schema name=&quot;mt_pm&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot; dataNode=&quot;mt_pm_dn&quot;&gt; &lt;table name=&quot;dm_log&quot; primaryKey=&quot;logid&quot; autoIncrement=&quot;true&quot; subTables=&quot;dm_log_$1-12&quot; dataNode=&quot;mt_pm_dn&quot; rule=&quot;dm_log_sharding-by-month&quot;/&gt; &lt;table name=&quot;dm_opendoor_record&quot; primaryKey=&quot;id&quot; autoIncrement=&quot;true&quot; subTables=&quot;dm_opendoor_record_$1-12&quot; dataNode=&quot;mt_pm_dn&quot; rule=&quot;dm_opendoor_record_sharding-by-month&quot;/&gt; &lt;/schema&gt; subTables定义了分表的名称：​ dm_log表定义了分表名为dm_log_$1-12，表示分为12张表，表名分别为：dm_log_1、dm_log_2、dm_log_3、dm_log_4、dm_log_5、dm_log_6、dm_log_7、dm_log_8、dm_log_9、dm_log_10、dm_log_11、dm_log_12。logtime为一月份时，根据算法会将数据分配到dm_log_1表，二月份数据插入表dm_log_2，以此类推，到十二月份后的一月份数据又循环插入dm_log_1表。​ dm_opendoor_record表定义了分表名为dm_opendoor_record _$1-12，表示分为12张表，表名分别为：dm_opendoor_record _1、dm_opendoor_record _2、dm_opendoor_record _3、dm_opendoor_record _4、dm_opendoor_record _5、dm_opendoor_record _6、dm_opendoor_record_7、dm_opendoor_record_8、dm_opendoor_record_9、dm_opendoor_record _10、dm_opendoor_record _11、dm_opendoor_record _12。opertime为一月份时，根据算法会将数据分配到dm_opendoor_record _1表，二月份数据插入表dm_opendoor_record_2，以此类推，到十二月份后的一月份数据又循环插入dm_opendoor_record _1表。 二、自增主键原理:​ 在数据库中建立一张表，存放 sequence 名称(name)，sequence 当前值(current_value)，步长(increment) int 类型每次读取多少个 sequence，假设为 K)等信息；Sequence 获取步骤：​ 1).当初次使用该 sequence 时，根据传入的 sequence 名称，从数据库这张表中读取 current_value，和 increment 到 MyCat 中，并将数据库中的 current_value 设置为原 current_value 值+increment 值；​ 2).MyCat 将读取到 current_value+increment 作为本次要使用的 sequence 值，下次使用时，自动加 1，当使用 increment 次后，执行步骤 1)相同的操作.MyCat 负责维护这张表，用到哪些 sequence，只需要在这张表中插入一条记录即可。若某次读取的sequence 没有用完，系统就停掉了，则这次读取的 sequence 剩余值不会再使用。配置方式：MYCAT_HOME/conf/server.xml 配置： &lt;system&gt;&lt;property name=&quot;sequnceHandlerType&quot;&gt;1&lt;/property&gt;&lt;/system&gt; 注：sequnceHandlerType 需要配置为 1，表示使用数据库方式生成 sequence.MYCAT_HOME/conf/schema.xml配置： &lt;schema name=&quot;mt_pm&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot; dataNode=&quot;mt_pm_dn&quot;&gt; &lt;table name=&quot;dm_log&quot; primaryKey=&quot;logid&quot; autoIncrement=&quot;true&quot; subTables=&quot;dm_log_$1-12&quot; dataNode=&quot;mt_pm_dn&quot; rule=&quot;dm_log_sharding-by-month&quot;/&gt; &lt;table name=&quot;dm_opendoor_record&quot; primaryKey=&quot;id&quot; autoIncrement=&quot;true&quot; subTables=&quot;dm_opendoor_record_$1-12&quot; dataNode=&quot;mt_pm_dn&quot; rule=&quot;dm_opendoor_record_sharding-by-month&quot;/&gt; &lt;/schema&gt; 在table节点配置primaryKey和autoIncrement，primaryKey为自增主键，autoIncrement值为ture。 数据库配置：1) 创建 MYCAT_SEQUENCE 表– 创建存放 sequence 的表 DROP TABLE IF EXISTS MYCAT_SEQUENCE; CREATE TABLE MYCAT_SEQUENCE (name VARCHAR(50) NOT NULL,current_value INT NOT NULL,increment INT NOT NULL DEFAULT 100, PRIMARY KEY(name)) ENGINE=InnoDB; name sequence 名称 current_value 当前 value increment 增长步长，可理解为 mycat 在数据库中一次读取多少个 sequence， 当这些用完后, 下次再从数据库中读取。 – 插入sequence INSERT INTO `mycat_sequence` (`name`, `current_value`, `increment`) VALUES (&#39;dm_log&#39;, &#39;152509809922444&#39;, &#39;1000&#39;); INSERT INTO `mycat_sequence` (`name`, `current_value`, `increment`) VALUES (&#39;dm_opendoor_record&#39;, &#39;58733280&#39;, &#39;1000&#39;); 2) 创建相关 function –- 获取当前 sequence 的值 (返回当前值,增量) DROP FUNCTION IF EXISTS mycat_seq_currval; DELIMITER CREATE FUNCTION mycat_seq_currval(seq_name VARCHAR(50)) RETURNS varchar(64) CHARSET utf-8 DETERMINISTIC BEGIN DECLARE retval VARCHAR(64); SET retval=“-999999999,null” ; SELECT concat(CAST(current_value AS CHAR),“,” ,CAST(increment AS CHAR)) INTO retval FROM MYCAT_SEQUENCE WHERE name = seq_name; RETURN retval; END DELIMITER; –- 设置 sequence 值 DROP FUNCTION IF EXISTS mycat_seq_setval; DELIMITER CREATE FUNCTION mycat_seq_setval(seq_name VARCHAR(50),value INTEGER) RETURNS varchar(64) CHARSET utf-8 DETERMINISTIC BEGIN UPDATE MYCAT_SEQUENCE SET current_value = value WHERE name = seq_name; RETURN mycat_seq_currval(seq_name); END DELIMITER; –- 获取下一个 sequence 值 DROP FUNCTION IF EXISTS mycat_seq_nextval; DELIMITER CREATE FUNCTION mycat_seq_nextval(seq_name VARCHAR(50)) RETURNS varchar(64) CHARSET utf-8 DETERMINISTIC BEGIN UPDATE MYCAT_SEQUENCE SET current_value = current_value + increment WHERE name = seq_name; RETURN mycat_seq_currval(seq_name); END DELIMITER; 4) sequence_db_conf.properties 相关配置,指定 sequence 相关配置在哪个节点上：例如： DM_LOG=mt_pm_dn DM_OPENDOOR_RECORD=mt_pm_dn 注意：MYCAT_SEQUENCE 表和以上的 3 个 function，需要放在同一个节点上。 function 请直接在具体节点的数据库上执行，如果执行的时候报：you might want to use the less safe log_bin_trust_function_creators variable需要对数据库做如下设置：windows 下 my.ini[mysqld]加上 log_bin_trust_function_creators=1linux 下/etc/my.cnf 下 my.ini[mysqld]加上 log_bin_trust_function_creators=1修改完后，即可在 mysql 数据库中执行上面的函数.使用示例： INSERT INTO `mt_pm`.`dm_log` (`logid`, `deviceid`, `logtype`, `logtime`, `content`, `picurl`, `id`, `positionid`, `position`, `comid`, `launchposition`, `status`) VALUES (next value for MYCATSEQ_DM_LOG, &#39;af0f69db62-4d31-d4e2-c041-793ed33931&#39;, &#39;unlock&#39;, &#39;2018-01-01 08:01:39&#39;, &#39;3|0e3f6740|1&#39;, NULL, NULL, NULL, NULL, NULL, NULL, NULL); 或者不带主键 INSERT INTO `mt_pm`.`dm_log` (`deviceid`, `logtype`, `logtime`, `content`, `picurl`, `id`, `positionid`, `position`, `comid`, `launchposition`, `status`) VALUES (&#39;af0f69db62-4d31-d4e2-c041-793ed33931&#39;, &#39;unlock&#39;, &#39;2018-01-01 08:01:39&#39;, &#39;3|0e3f6740|1&#39;, NULL, NULL, NULL, NULL, NULL, NULL, NULL); 三、定期备份表数据​ 分为12张表后，每年循环插入数据，最终数据量越来越大，需要定期将历史数据备份或迁移。这里采用修改表名，再新建和原表名结构一样的新表。例如： ALTER TABLE dm_log_1 RENAME TO dm_log201801; CREATE TABLE IF NOT EXISTS dm_log_1 LIKE dm_log201801; ​ 备份dm_log_1的数据，假设dm_log_1存的都是2018年1月份数据，则把表名修改为dm_log201801，然后再吉安一张表名为dm_log_1的表。​ 上述操作在数据库中写成存储过程，通过数据库定时事件调用执行，详细请看附件中相关sql语句。 定时事件调用策略： 每月1日的凌晨3:30执行备份历史数据，例如:2018年7月1日凌晨3:30把表dm_log_1改为dm_log201801并新建表dm_log_1，2018年8月1日凌晨3:30把表dm_log_2改为dm_log201802并新建表dm_log_2，以此类推，保留最近半年的数据供物管系统页面查询，超过半年数据则需通过数据库查询历史数据。 rename_dm_log_history为备份dm_log表数据的存储过程，Event_Rename_dm_log_history为定时事件每月调用rename_dm_log_history备份数据。 每月1日的凌晨3:30执行备份历史数据，例如:2018年7月1日凌晨3:30把表`dm_opendoor_record_1`改为dm_opendoor_record201801并新建表dm_opendoor_record_1，2018年8月1日凌晨3:30把表dm_opendoor_record_2改为dm_opendoor_record201802并新建表dm_opendoor_record_2，以此类推，保留最近半年的数据供物管系统页面查询，超过半年数据则需通过数据库查询历史数据。 rename_dm_opendoor_record_history为备份dm_opendoor_record表数据的存储过程，Event_Rename_dm_opendoor_record_history为定时事件每月调用rename_dm_log_history备份数据。 四、附件1.相关sql语句 2.mycat​五、参考资料Mycat官网：http://www.mycat.io/Mycat权威指南：http://www.mycat.io/document/Mycat_V1.6.0.pdf]]></content>
      <categories>
        <category>mysql</category>
        <category>mycat</category>
        <category>subtable</category>
        <category>partbymonth</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mycat</tag>
        <tag>subtable</tag>
        <tag>partbymonth</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker常用命令]]></title>
    <url>%2FDocker-common%2F</url>
    <content type="text"><![CDATA[Docker使用比较频繁的命令 查看docker 版本# docker version Client: Version: 18.03.1-ce API version: 1.37 Go version: go1.9.5 Git commit: 9ee9f40 Built: Thu Apr 26 07:12:48 2018 OS/Arch: windows/amd64 Experimental: false Orchestrator: swarm Server: Engine: Version: 18.06.1-ce API version: 1.38 (minimum version 1.12) Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17:25:29 2018 OS/Arch: linux/amd64 Experimental: true docker 配置信息# docker info Containers: 128 Running: 62 Paused: 0 Stopped: 66 Images: 256 Server Version: 18.06.1-ce Storage Driver: overlay2 Backing Filesystem: xfs Supports d_type: true Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 468a545b9edcd5932818eb9de8e72413e616e86e runc version: 69663f0bd4b60df09991c08812a60108003fa340 init version: fec3683 Security Options: seccomp Profile: default Kernel Version: 3.10.0-862.el7.x86_64 Operating System: CentOS Linux 7 (Core) OSType: linux Architecture: x86_64 CPUs: 3 Total Memory: 15.02GiB Name: bogon ID: CAI4:PHBY:FKFP:5BI6:LWUG:L3XF:OVU6:OGDF:IS5J:IPF4:3JKZ:KTUZ Docker Root Dir: /var/lib/docker Debug Mode (client): false Debug Mode (server): true File Descriptors: 312 Goroutines: 273 System Time: 2018-12-19T11:26:00.704470694+08:00 EventsListeners: 0 Registry: https://index.docker.io/v1/ Labels: name=docker Experimental: true Insecure Registries: loclhost:5000 172.20.8.5:5000 172.20.8.5:8888 127.0.0.0/8 Registry Mirrors: https://registry.docker-cn.com/ https://container-registry.oracle.com/ https://dhcl9iu5.mirror.aliyuncs.com/ https://docker.mirrors.ustc.edu.cn/ http://29bd46d3.m.daocloud.io/ http://hub-mirror.c.163.com/ Live Restore Enabled: false 拉取镜像# docker pull tomcat Using default tag: latest latest: Pulling from library/tomcat 54f7e8ac135a: Downloading [===========&gt; ] 9.98MB/45.32MB d6341e30912f: Downloading [============================&gt; ] 6.038MB/10.74MB 087a57faf949: Download complete 95065f220961: Download complete 0887630ce576: Download complete c375d1959fab: Download complete e00a5e6055cc: Waiting 8319f5fb56cf: Waiting 258c74eb25ab: Waiting 5c135322994c: Waiting b2cc25ec4861: Waiting 40140bebba00: Waiting d1786b40ed4f: Waiting Digest: sha256:d6f67aacce64010880a1e9ea6f0ace9fe9e20d39aae0489c8e88b4c14effe3a0 Status: Downloaded newer image for tomcat:latest 运行容器# docker run --name tomcat -p 8080:8080 -v /data:/usr/local/tomcat/webapps/data -idt tomcat bf0c6f766a2ceec0cdd06ae1b5556bf53bb14c7a0205d9531b259f72ca6698c1 查看运行中的容器# docker ps | grep tomcat CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES bf0c6f766a2c tomcat &quot;catalina.sh run&quot; 47 seconds ago Up 45 seconds 0.0.0.0:8080-&gt;8080/tcp tomcat 查看容器日志# docker logs tomcat Using CATALINA_BASE: /usr/local/tomcat Using CATALINA_HOME: /usr/local/tomcat Using CATALINA_TMPDIR: /usr/local/tomcat/temp Using JRE_HOME: /docker-java-home/jre Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar 21-Dec-2018 08:39:43.621 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server version: Apache Tomcat/8.5.35 21-Dec-2018 08:39:43.624 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server built: Nov 3 2018 17:39:20 UTC 21-Dec-2018 08:39:43.625 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server number: 8.5.35.0 21-Dec-2018 08:39:43.625 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log OS Name: Linux 21-Dec-2018 08:39:43.625 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log OS Version: 3.10.0-862.el7.x86_64 21-Dec-2018 08:39:43.625 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Architecture: amd64 21-Dec-2018 08:39:43.625 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Java Home: /usr/lib/jvm/java-8-openjdk-amd64/jre 21-Dec-2018 08:39:43.625 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log JVM Version: 1.8.0_181-8u181-b13-2~deb9u1-b13 21-Dec-2018 08:39:43.626 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log JVM Vendor: Oracle Corporation 21-Dec-2018 08:39:43.626 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log CATALINA_BASE: /usr/local/tomcat 21-Dec-2018 08:39:43.626 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log CATALINA_HOME: /usr/local/tomcat 21-Dec-2018 08:39:43.626 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.util.logging.config.file=/usr/local/tomcat/conf/logging.properties 21-Dec-2018 08:39:43.627 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager 21-Dec-2018 08:39:43.627 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djdk.tls.ephemeralDHKeySize=2048 21-Dec-2018 08:39:43.628 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.protocol.handler.pkgs=org.apache.catalina.webresources 21-Dec-2018 08:39:43.629 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 21-Dec-2018 08:39:43.629 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dignore.endorsed.dirs= 21-Dec-2018 08:39:43.629 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dcatalina.base=/usr/local/tomcat 21-Dec-2018 08:39:43.631 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dcatalina.home=/usr/local/tomcat 21-Dec-2018 08:39:43.631 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.io.tmpdir=/usr/local/tomcat/temp 21-Dec-2018 08:39:43.631 INFO [main] org.apache.catalina.core.AprLifecycleListener.lifecycleEvent Loaded APR based Apache Tomcat Native library [1.2.18] using APR version [1.5.2]. 21-Dec-2018 08:39:43.631 INFO [main] org.apache.catalina.core.AprLifecycleListener.lifecycleEvent APR capabilities: IPv6 [true], sendfile [true], accept filters [false], random [true]. 21-Dec-2018 08:39:43.632 INFO [main] org.apache.catalina.core.AprLifecycleListener.lifecycleEvent APR/OpenSSL configuration: useAprConnector [false], useOpenSSL [true] 21-Dec-2018 08:39:43.637 INFO [main] org.apache.catalina.core.AprLifecycleListener.initializeSSL OpenSSL successfully initialized [OpenSSL 1.1.0j 20 Nov 2018] 21-Dec-2018 08:39:43.784 INFO [main] org.apache.coyote.AbstractProtocol.init Initializing ProtocolHandler [&quot;http-nio-8080&quot;] 21-Dec-2018 08:39:43.800 INFO [main] org.apache.tomcat.util.net.NioSelectorPool.getSharedSelector Using a shared selector for servlet write/read 21-Dec-2018 08:39:43.819 INFO [main] org.apache.coyote.AbstractProtocol.init Initializing ProtocolHandler [&quot;ajp-nio-8009&quot;] 21-Dec-2018 08:39:43.821 INFO [main] org.apache.tomcat.util.net.NioSelectorPool.getSharedSelector Using a shared selector for servlet write/read 21-Dec-2018 08:39:43.823 INFO [main] org.apache.catalina.startup.Catalina.load Initialization processed in 858 ms 21-Dec-2018 08:39:43.861 INFO [main] org.apache.catalina.core.StandardService.startInternal Starting service [Catalina] 21-Dec-2018 08:39:43.861 INFO [main] org.apache.catalina.core.StandardEngine.startInternal Starting Servlet Engine: Apache Tomcat/8.5.35 21-Dec-2018 08:39:43.879 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/usr/local/tomcat/webapps/ROOT] 21-Dec-2018 08:39:44.378 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/usr/local/tomcat/webapps/ROOT] has finished in [499] ms 21-Dec-2018 08:39:44.379 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/usr/local/tomcat/webapps/docs] 21-Dec-2018 08:39:44.436 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/usr/local/tomcat/webapps/docs] has finished in [57] ms 21-Dec-2018 08:39:44.436 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/usr/local/tomcat/webapps/examples] 21-Dec-2018 08:39:45.443 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/usr/local/tomcat/webapps/examples] has finished in [1,006] ms 21-Dec-2018 08:39:45.443 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/usr/local/tomcat/webapps/host-manager] 21-Dec-2018 08:39:46.070 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/usr/local/tomcat/webapps/host-manager] has finished in [626] ms 21-Dec-2018 08:39:46.071 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/usr/local/tomcat/webapps/manager] 21-Dec-2018 08:39:46.204 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/usr/local/tomcat/webapps/manager] has finished in [133] ms 21-Dec-2018 08:39:46.207 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/usr/local/tomcat/webapps/data] 21-Dec-2018 08:39:46.282 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/usr/local/tomcat/webapps/data] has finished in [75] ms 21-Dec-2018 08:39:46.289 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;http-nio-8080&quot;] 21-Dec-2018 08:39:46.315 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;ajp-nio-8009&quot;] 21-Dec-2018 08:39:46.345 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 2520 ms 停止运行中的容器# docker stop tomcat tomcat 重新运行停止的容器# docker start tomcat tomcat 重启容器# docker restart tomcat tomcat 强制删除运行中的容器# docker rm tomcat -f tomcat]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用的Shell脚本和Linux命令]]></title>
    <url>%2FCommon-shell-script%2F</url>
    <content type="text"><![CDATA[收集工作中经常用的Linux命令和shell脚本 zip 压缩和解压缩# 压缩文件夹 zip -r data.zip data # 解压缩文件,默认解压到当前路径 unzip data.zip # 解压到指定路径 unzip data.zip -d destDir # 查看帮助 unzip -h tar 压缩和解压缩# 压缩文件夹 tar -czf data.tar.gz data # 解压缩到当前路径 tar -xzf data.tar.gz -C /destDir tail查看和过滤日志文件# 动态输出Tomcat日志到控制台 tail -1000f catalina.out # 按字段过滤日志 tail -1000f catalina.out | grap -A 20 &#39;ERROR&#39; netstat 查看监听端口的进程# 查看监听端口为1600的进程 netstat -tlpn | grep &quot;\b16000\b&quot; kill停止指定进程# 停止当前路径下的应用进程 kill -9 $(ps -ef|grep $(pwd)|grep -v grep|awk &#39;{print $2}&#39;) # 停止监听端口为1600的进程 kill -9 $(netstat -tlpn | grep &quot;\b16000\b&quot; | awk &#39;{print $7}&#39; | cut -d &#39;/&#39; -f 1) sed替换文件内容# 替换Tomcat默认端口 sed -i &quot;s|&lt;Connector port=\&quot;8080\&quot;|&lt;Connector port=\&quot;51000\&quot;|g&quot; server.xml &amp;&amp; \ sed -i &quot;s|&lt;Connector port=\&quot;8009\&quot;|&lt;Connector port=\&quot;51080\&quot;|g&quot; server.xml shell 判断文件夹或文件是否存在文件夹不存在则创建 if [ ! -d &quot;/data/&quot; ];then mkdir /data else echo &quot;文件夹已经存在&quot; fi 文件存在则删除 if [ ! -f &quot;/data/filename&quot; ];then echo &quot;文件不存在&quot; else rm -f /data/filename fi 判断文件夹是否存在 if [ -d &quot;/data/&quot; ];then echo &quot;文件夹存在&quot; else echo &quot;文件夹不存在&quot; fi 判断文件是否存在 if [ -f &quot;/data/filename&quot; ];then echo &quot;文件存在&quot; else echo &quot;文件不存在&quot; fi 文件比较符 -e 判断对象是否存在 -d 判断对象是否存在，并且为目录 -f 判断对象是否存在，并且为常规文件 -L 判断对象是否存在，并且为符号链接 -h 判断对象是否存在，并且为软链接 -s 判断对象是否存在，并且长度不为0 -r 判断对象是否存在，并且可读 -w 判断对象是否存在，并且可写 -x 判断对象是否存在，并且可执行 -O 判断对象是否存在，并且属于当前用户 -G 判断对象是否存在，并且属于当前用户组 -nt 判断file1是否比file2新 [ &quot;/data/file1&quot; -nt &quot;/data/file2&quot; ] -ot 判断file1是否比file2旧 [ &quot;/data/file1&quot; -ot &quot;/data/file2&quot; ] 判断某个变量是否包含字符串/变量的方法尝试了有3种方法： 使用“=~”符号，注意前后必须要有空格！ 可以输出正确结果,被匹配的字符串必须要有引号括起来！ ➜ ~ a1=&#39;hello.world&#39; ➜ ~ a2=&#39;helloworld&#39; ➜ ~ b=&#39;.&#39; ➜ ~ if [[ ${a1} =~ &#39;.&#39; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a2} =~ &#39;.&#39; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a1} =~ &quot;.&quot; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a2} =~ &quot;.&quot; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a1} =~ &quot;${b}&quot; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a2} =~ &quot;${b}&quot; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ 不能输出正确结果 ➜ ~ a1=&#39;hello.world&#39; ➜ ~ &#39; ➜ ~ b=&#39;.&#39; ➜ ~ if [[ ${a1} =~ . ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a2} =~ . ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a1} =~ ${b} ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a2} =~ ${b} ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a1} =~ &#39;${b}&#39; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if [[ ${a2} =~ &#39;${b}&#39; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no 使用”==“加通配符wildcard，注意等号前后必须有空格，注意，通配符跟正则表达式有所区别，*表示匹配 0 或多个字符 可以输出正确结果 ➜ ~ a1=&#39;hello.world&#39; ➜ ~ a2=&#39;helloworld&#39; ➜ ~ if [[ ${a1} == *.* ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if [[ ${a2} == *.* ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no 不能输出正确结果 ，通配符不能用括号括起来！ ➜ ~ a1=&#39;hello.world&#39; ➜ ~ a2=&#39;helloworld&#39; ➜ ~ if [[ ${a2} == &quot;*.*&quot; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if [[ ${a1} == &quot;*.*&quot; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if [[ ${a1} == &#39;*.*&#39; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if [[ ${a2} == &#39;*.*&#39; ]];then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no 使用echo + grep -q 选项 使用这种方法时匹配是否有”.”会不正常，所以我们换成匹配普通字符，有没有括号都可以 ➜ ~ a1=&#39;hello.world&#39; ➜ ~ a2=&#39;helloworld&#39; ➜ ~ a3=&quot;helloworlda&quot; ➜ ~ if ( echo ${a1} |grep -q a );then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if ( echo ${a2} |grep -q a );then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if ( echo ${a3} |grep -q a );then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if ( echo ${a1} |grep -q &#39;a&#39; );then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if ( echo ${a2} |grep -q &#39;a&#39; );then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if ( echo ${a3} |grep -q &#39;a&#39; );then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes ➜ ~ if ( echo ${a1} |grep -q &quot;a&quot; );then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if ( echo ${a2} |grep -q &quot;a&quot; );then echo &quot;yes&quot;;else echo &quot;no&quot;;fi no ➜ ~ if ( echo ${a3} |grep -q &quot;a&quot; );then echo &quot;yes&quot;;else echo &quot;no&quot;;fi yes crontab定时任务crontab -e # 每分钟执行一次monitor.sh脚步 */1 * * * * /usr/java/monitor.sh # 数据库备份 0 3 * * * /bin/sh /data1/script/databak.sh &amp; 0 4 * * * find /data1/databak -type f -mtime +3 -exec rm {} \; databak.sh内容#!/bin/bash /usr/bin/mysqldump -uroot -p123456 test &gt;/data1/databak/`date +%Y%m%d`test.sql 2&gt;/dev/null 监控Tomcat是否正常启动 #!/bin/sh # 定义环境变量（要改成自己的jdk相关地址） PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_191-oraclejdk export CLASSPATH=$JAVA_HOME/lib:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin TomcatHome=/opt/webserver/pf-platform #获取tomcat进程ID（这里注意tomcat7要改成自己的tomcat目录名） TomcatID=$(ps -ef |grep tomcat |grep -w $TomcatHome|grep -v &#39;grep&#39;|awk &#39;{print $2}&#39;) #tomcat启动程序(这里注意要改成自己tomcat实际安装的路径) StartTomcat=$TomcatHome/bin/startup.sh TomcatCache=$TomcatHome/work #自己定义要监控的页面地址，页面越简单越好，比如：页面上写个success即可 WebUrl=http://172.20.8.5:41000/pf-platform/login/login #日志输出 （自己定义地址，用于输出监控日志和监控报错日志） #TomcatMonitorLog=$TomcatHome/TomcatMonitor-$(date &#39;+%Y%m%d%H%M%S&#39;).log TomcatMonitorLog=$TomcatHome/logs/TomcatMonitor-$(date &#39;+%Y-%m-%d&#39;).log GetPageInfo=$TomcatHome/logs/PageInfo-$(date &#39;+%Y-%m-%d&#39;).log if [ ! -d $TomcatHome/logs ]; then mkdir -p $TomcatHome/logs ; fi Monitor() { echo &quot;[info]开始监控tomcat...[$(date +&#39;%F %H:%M:%S&#39;)]&quot; if [[ $TomcatID ]];then # 这里判断TOMCAT进程是否存在 echo &quot;[info]当前tomcat进程ID为:$TomcatID,继续检测页面...&quot; # 检测是否启动成功(成功的话页面会返回状态&quot;302&quot;) TomcatServiceCode=$(curl -s -o $GetPageInfo -m 10 --connect-timeout 10 $WebUrl -w %{http_code}) if [ $TomcatServiceCode -eq 302 ];then echo &quot;[info]页面返回码为$TomcatServiceCode,tomcat启动成功,测试页面正常......&quot; else echo &quot;[error]tomcat页面出错,请注意......状态码为$TomcatServiceCode,错误日志已输出到$GetPageInfo&quot; echo &quot;[error]页面访问出错,开始重启tomcat&quot; kill -9 $TomcatID # 杀掉原tomcat进程 sleep 3 #rm -rf $TomcatCache # 清理tomcat缓存 $StartTomcat fi else echo &quot;[error]tomcat进程不存在!tomcat开始自动重启...&quot; echo &quot;[info]$StartTomcat,请稍候......&quot; #rm -rf $TomcatCache $StartTomcat fi echo &quot;------------------------------&quot; } Monitor&gt;&gt;$TomcatMonitorLog 监控netty服务是否正常开启端口#!/bin/sh # 定义环境变量（要改成自己的jdk相关地址） PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_191-oraclejdk export CLASSPATH=$JAVA_HOME/lib:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin NettyServerHome=/opt/webserver/mtech-cloud-netty-server #获取netty-server进程ID（这里注意netty-server7要改成自己的netty-server目录名） NettyServerID=$(ps -ef |grep netty-server |grep -w $NettyServerHome |grep -w java |grep -v &#39;grep&#39;|awk &#39;{print $2}&#39;) #netty-server启动程序(这里注意要改成自己netty-server实际安装的路径) StartNettyServer=$NettyServerHome/bin/start.sh #netty监听端口 NettyPort=16000 #日志输出 （自己定义地址，用于输出监控日志和监控报错日志） NettyServerMonitorLog=$NettyServerHome/logs/NettyServerMonitor-$(date +&#39;%F&#39;).log GetPageInfo=$NettyServerHome/logs/PortInfo-$(date +&#39;%F&#39;).log if [ ! -d $NettyServerHome/logs ]; then mkdir -p $NettyServerHome/logs ; fi Monitor() { echo &quot;[info]开始监控netty-server...[$(date +&#39;%F %H:%M:%S&#39;)]&quot; if [[ $NettyServerID ]];then # 这里判断netty-server进程是否存在 echo &quot;[info]当前netty-server进程ID为:$NettyServerID,继续检测端口...&quot; # 检测是否启动成功(成功的话会返回端口信息) NettyServerPort=$(checkPort $NettyPort) echo &quot;端口检测结果：$NettyServerPort &quot; if [ $NettyServerPort -eq 0 ];then echo &quot;[info]返回码为$NettyServerPort,netty-server启动成功,测试端口正常......&quot; else echo &quot;[error]netty-server启动出错,请注意......, 错误日志已输出到$GetPageInfo&quot; echo &quot;[error]端口$NettyPort检测出错,开始重启netty-server&quot; kill -9 $NettyServerID # 杀掉原netty-server进程 sleep 3 #rm -rf $netty-serverCache # 清理netty-server缓存 $StartNettyServer &gt;&gt; $NettyServerHome/logs/nohub.out &amp; &gt;&gt; /dev/null fi else echo &quot;[error]netty-server进程不存在!netty-server开始自动重启...&quot; echo &quot;[info]$StartNettyServer,请稍候......&quot; #rm -rf $netty-serverCache # $StartNettyServer &gt;&gt; /dev/null &amp; $StartNettyServer &gt;&gt; $NettyServerHome/logs/nohub.out &amp; &gt;&gt; /dev/null fi echo &quot;------------------------------&quot; } checkPort() { echo &quot;------------------------------&quot; &gt;&gt; $GetPageInfo echo &quot;$(date +&#39;%F %H:%M:%S&#39;) &quot; &gt;&gt; $GetPageInfo echo $(netstat -tlpn | grep &quot;\b$1\b&quot;) &gt;&gt; $GetPageInfo netstat -tlpn | grep &quot;\b$1\b&quot; | awk &#39;{print $2}&#39; } Monitor&gt;&gt;$NettyServerMonitorLog &amp; 部署war包到tomcat➜ web cat start.sh WORKDIR=/data1/webserver/mt_chs/web cd $WORKDIR kill -9 $(netstat -tlpn | grep &quot;\b18080\b&quot; | awk &#39;{print $7}&#39; | cut -d &#39;/&#39; -f 1) echo &#39;&#39; &gt; $WORKDIR/logs/catalina.out $WORKDIR/bin/startup.sh ➜ web cat tailf.sh WORKDIR=/data1/webserver/mt_chs/web tail -f $WORKDIR/logs/catalina.out ➜ web cat stop.sh WORKDIR=/data1/webserver/mt_chs/web cd $WORKDIR kill -9 $(netstat -tlpn | grep &quot;\b18080\b&quot; | awk &#39;{print $7}&#39; | cut -d &#39;/&#39; -f 1) ➜ ~ cat deploy_web.sh WEB_DIR=/data1/webserver/mt_chs/web APP_DIR=$WEB_DIR/webapps/chs_web HOME_DIR=/home/ledmon WAR_FILE=$HOME_DIR/$1 function deploy(){ echo &quot;停止tomcat...&quot; $WEB_DIR/stop.sh mkdir -p $APP_DIR echo &quot;更新应用...&quot; rm -rf $APP_DIR/* unzip $WAR_FILE -d $APP_DIR &gt;&gt; /dev/null echo &quot;启动tomcat...&quot; $WEB_DIR/start.sh echo &quot;查看启动日志&quot; $WEB_DIR/tailf.sh } if [ ! -f &quot;$WAR_FILE&quot; ];then echo &quot;文件不存在，路径: $WAR_FILE&quot; elif (! echo ${WAR_FILE} |grep -q &quot;.war&quot; );then echo &quot;文件不合法，路径：$WAR_FILE&quot; echo &quot;请选择war文件&quot; elif (! echo ${WAR_FILE} |grep -q &quot;web_product&quot; );then echo &quot;文件不合法，路径：$WAR_FILE&quot; echo &quot;请选择web_proeuct*.war文件&quot; else deploy fi 部署springboot的jar包应用➜ appint cat start.sh WORKDIR=/data1/webserver/mt_chs/appint cd $WORKDIR kill -9 $(netstat -tlpn | grep &quot;\b18083\b&quot; | awk &#39;{print $7}&#39; | cut -d &#39;/&#39; -f 1) echo &#39;&#39; &gt; $WORKDIR/out.log nohup java -jar $WORKDIR/appint_*.jar &gt; $WORKDIR/out.log &amp; ➜ appint cat tailf.sh WORKDIR=/data1/webserver/mt_chs/appint tail -f $WORKDIR/out.log ➜ ~ cat deploy_appint.sh APP_DIR=/data1/webserver/mt_chs/appint HOME_DIR=/home/ledmon JAR_FILE=$HOME_DIR/$1 function deploy(){ echo &quot;停止应用...&quot; kill -9 $(netstat -tlpn | grep &quot;\b18083\b&quot; | awk &#39;{print $7}&#39; | cut -d &#39;/&#39; -f 1) mkdir -p $APP_DIR echo &quot;更新应用...&quot; rm -rf $APP_DIR/*.jar cp $JAR_FILE $APP_DIR echo &quot;启动应用...&quot; $APP_DIR/start.sh echo &quot;查看启动日志&quot; $APP_DIR/tailf.sh } if [ ! -f &quot;$JAR_FILE&quot; ];then echo &quot;文件不存在，路径: $JAR_FILE&quot; elif (! echo ${JAR_FILE} |grep -q &quot;.jar&quot; );then echo &quot;文件不合法，路径：$JAR_FILE&quot; echo &quot;请选择*.jar文件&quot; elif (! echo ${JAR_FILE} |grep -q &quot;appint_product&quot; );then echo &quot;文件不合法，路径：$JAR_FILE&quot; echo &quot;请选择appint_product*.jar文件&quot; else deploy fi]]></content>
      <categories>
        <category>linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发问题--乐观锁与悲观锁以及乐观锁的一种实现方式-CAS]]></title>
    <url>%2FJava-Concurrent-Lock%2F</url>
    <content type="text"><![CDATA[原文：https://www.cnblogs.com/qjjazry/p/6581568.html 首先介绍一些乐观锁与悲观锁: 悲观锁：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。再比如Java里面的同步原语synchronized关键字的实现也是悲观锁。 乐观锁：顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。 乐观锁的一种实现方式-CAS(Compare and Swap 比较并交换)： 锁存在的问题: Java在JDK1.5之前都是靠 synchronized关键字保证同步的，这种通过使用一致的锁定协议来协调对共享状态的访问，可以确保无论哪个线程持有共享变量的锁，都采用独占的方式来访问这些变量。这就是一种独占锁，独占锁其实就是一种悲观锁，所以可以说 synchronized 是悲观锁。 悲观锁机制存在以下问题： 1. 在多线程竞争下，加锁、释放锁会导致比较多的上下文切换和调度延时，引起性能问题。 2. 一个线程持有锁会导致其它所有需要此锁的线程挂起。 3. 如果一个优先级高的线程等待一个优先级低的线程释放锁会导致优先级倒置，引起性能风险。 对比于悲观锁的这些问题，另一个更加有效的锁就是乐观锁。其实乐观锁就是：每次不加锁而是假设没有并发冲突而去完成某项操作，如果因为并发冲突失败就重试，直到成功为止。 乐观锁： 乐观锁（ Optimistic Locking ）在上文已经说过了，其实就是一种思想。相对悲观锁而言，乐观锁假设认为数据一般情况下不会产生并发冲突，所以在数据进行提交更新的时候，才会正式对数据是否产生并发冲突进行检测，如果发现并发冲突了，则让返回用户错误的信息，让用户决定如何去做。 上面提到的乐观锁的概念中其实已经阐述了它的具体实现细节：主要就是两个步骤：冲突检测和数据更新。其实现方式有一种比较典型的就是 Compare and Swap ( CAS )。 CAS： CAS是乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。 CAS 操作中包含三个操作数 —— 需要读写的内存位置（V）、进行比较的预期原值（A）和拟写入的新值(B)。如果内存位置V的值与预期原值A相匹配，那么处理器会自动将该位置值更新为新值B。否则处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。（在 CAS 的一些特殊情况下将仅返回 CAS 是否成功，而不提取当前值。）CAS 有效地说明了“ 我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。 ”这其实和乐观锁的冲突检查+数据更新的原理是一样的。 这里再强调一下，乐观锁是一种思想。CAS是这种思想的一种实现方式。 JAVA对CAS的支持： 在JDK1.5 中新增 java.util.concurrent (J.U.C)就是建立在CAS之上的。相对于对于 synchronized 这种阻塞算法，CAS是非阻塞算法的一种常见实现。所以J.U.C在性能上有了很大的提升。 以 java.util.concurrent 中的 AtomicInteger 为例，看一下在不使用锁的情况下是如何保证线程安全的。主要理解 getAndIncrement 方法，该方法的作用相当于 ++i 操作。 public class AtomicInteger extends Number implements java.io.Serializable { private volatile int value; public final int get() { return value; } public final int getAndIncrement() { for (;;) { int current = get(); int next = current + 1; if (compareAndSet(current, next)) return current; } } public final boolean compareAndSet(int expect, int update) { return unsafe.compareAndSwapInt(this, valueOffset, expect, update); } } 在没有锁的机制下,字段value要借助volatile原语，保证线程间的数据是可见性。这样在获取变量的值的时候才能直接读取。然后来看看 ++i 是怎么做到的。 getAndIncrement 采用了CAS操作，每次从内存中读取数据然后将此数据和 +1 后的结果进行CAS操作，如果成功就返回结果，否则重试直到成功为止。 而 compareAndSet 利用JNI（Java Native Interface）来完成CPU指令的操作： public final boolean compareAndSet(int expect, int update) { return unsafe.compareAndSwapInt(this, valueOffset, expect, update); } 其中unsafe.compareAndSwapInt(this, valueOffset, expect, update);类似如下逻辑： if (this == expect) { this = update return true; } else { return false; } 那么比较this == expect，替换this = update，compareAndSwapInt实现这两个步骤的原子性呢？ 参考CAS的原理 CAS原理： CAS通过调用JNI的代码实现的。而compareAndSwapInt就是借助C来调用CPU底层指令实现的。 下面从分析比较常用的CPU（intel x86）来解释CAS的实现原理。 下面是sun.misc.Unsafe类的compareAndSwapInt()方法的源代码： public final native boolean compareAndSwapInt(Object o, long offset, int expected, int x); 可以看到这是个本地方法调用。这个本地方法在JDK中依次调用的C++代码为： #define LOCK_IF_MP(mp) __asm cmp mp, 0 \ __asm je L0 \ __asm _emit 0xF0 \ __asm L0: inline jint Atomic::cmpxchg (jint exchange_value, volatile jint* dest, jint compare_value) { // alternative for InterlockedCompareExchange int mp = os::is_MP(); __asm { mov edx, dest mov ecx, exchange_value mov eax, compare_value LOCK_IF_MP(mp) cmpxchg dword ptr [edx], ecx } } 如上面源代码所示，程序会根据当前处理器的类型来决定是否为cmpxchg指令添加lock前缀。如果程序是在多处理器上运行，就为cmpxchg指令加上lock前缀（lock cmpxchg）。反之，如果程序是在单处理器上运行，就省略lock前缀（单处理器自身会维护单处理器内的顺序一致性，不需要lock前缀提供的内存屏障效果）。 CAS缺点： 1. ABA问题： 比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且two进行了一些操作变成了B，然后two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后one操作成功。尽管线程one的CAS操作成功，但可能存在潜藏的问题。如下所示： 现有一个用单向链表实现的堆栈，栈顶为A，这时线程T1已经知道A.next为B，然后希望用CAS将栈顶替换为B： head.compareAndSet(A,B); 在T1执行上面这条指令之前，线程T2介入，将A、B出栈，再pushD、C、A，此时堆栈结构如下图，而对象B此时处于游离状态： 此时轮到线程T1执行CAS操作，检测发现栈顶仍为A，所以CAS成功，栈顶变为B，但实际上B.next为null，所以此时的情况变为： 其中堆栈中只有B一个元素，C和D组成的链表不再存在于堆栈中，平白无故就把C、D丢掉了。 从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 public boolean compareAndSet( V expectedReference,//预期引用 V newReference,//更新后的引用 int expectedStamp, //预期标志 int newStamp //更新后的标志 ) 实际应用代码： private static AtomicStampedReference&lt;Integer&gt; atomicStampedRef = new AtomicStampedReference&lt;Integer&gt;(100, 0); ........ atomicStampedRef.compareAndSet(100, 101, stamp, stamp + 1); 2. 循环时间长开销大： 自旋CAS（不成功，就一直循环执行，直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。 3. 只能保证一个共享变量的原子操作： 当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量i＝2,j=a，合并一下ij=2a，然后用CAS来操作ij。从Java1.5开始JDK提供了AtomicReference**类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作。** CAS与Synchronized的使用情景： 1、对于资源竞争较少（线程冲突较轻）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。 2、对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。 补充： synchronized在jdk1.6之后，已经改进优化。synchronized的底层实现主要依靠Lock-Free的队列，基本思路是自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。 concurrent包的实现： 由于java的CAS同时具有 volatile 读和volatile写的内存语义，因此Java线程之间的通信现在有了下面四种方式： 1. A线程写volatile变量，随后B线程读这个volatile变量。 2. A线程写volatile变量，随后B线程用CAS更新这个volatile变量。 3. A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量。 4. A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量。 Java的CAS会使用现代处理器上提供的高效机器级别原子指令，这些原子指令以原子方式对内存执行读-改-写操作，这是在多处理器中实现同步的关键（从本质上来说，能够支持原子性读-改-写指令的计算机器，是顺序计算图灵机的异步等价机器，因此任何现代的多处理器都会去支持某种能对内存执行原子性读-改-写操作的原子指令）。同时，volatile变量的读/写和CAS可以实现线程之间的通信。把这些特性整合在一起，就形成了整个concurrent包得以实现的基石。如果我们仔细分析concurrent包的源代码实现，会发现一个通用化的实现模式： 1. 首先，声明共享变量为volatile； 2. 然后，使用CAS的原子条件更新来实现线程之间的同步； 3. 同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。 AQS，非阻塞数据结构和原子变量类（java.util.concurrent.atomic包中的类），这些concurrent包中的基础类都是使用这种模式来实现的，而concurrent包中的高层类又是依赖于这些基础类来实现的。从整体来看，concurrent包的实现示意图如下： JVM中的CAS（堆中对象的分配）： Java调用new object()会创建一个对象，这个对象会被分配到JVM的堆中。那么这个对象到底是怎么在堆中保存的呢？ 首先，new object()执行的时候，这个对象需要多大的空间，其实是已经确定的，因为java中的各种数据类型，占用多大的空间都是固定的（对其原理不清楚的请自行Google）。那么接下来的工作就是在堆中找出那么一块空间用于存放这个对象。 在单线程的情况下，一般有两种分配策略： 1. 指针碰撞：这种一般适用于内存是绝对规整的（内存是否规整取决于内存回收策略），分配空间的工作只是将指针像空闲内存一侧移动对象大小的距离即可。 2. 空闲列表：这种适用于内存非规整的情况，这种情况下JVM会维护一个内存列表，记录哪些内存区域是空闲的，大小是多少。给对象分配空间的时候去空闲列表里查询到合适的区域然后进行分配即可。 但是JVM不可能一直在单线程状态下运行，那样效率太差了。由于再给一个对象分配内存的时候不是原子性的操作，至少需要以下几步：查找空闲列表、分配内存、修改空闲列表等等，这是不安全的。解决并发时的安全问题也有两种策略： 1. CAS：实际上虚拟机采用CAS配合上失败重试的方式保证更新操作的原子性，原理和上面讲的一样。 2. TLAB：如果使用CAS其实对性能还是会有影响的，所以JVM又提出了一种更高级的优化策略：每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲区（TLAB），线程内部需要分配内存时直接在TLAB上分配就行，避免了线程冲突。只有当缓冲区的内存用光需要重新分配内存的时候才会进行CAS操作分配更大的内存空间。 虚拟机是否使用TLAB，可以通过-XX:+/-UseTLAB参数来进行配置（jdk5及以后的版本默认是启用TLAB的）。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>lock</tag>
        <tag>java</tag>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows环境下Vmware中Centos共享文件]]></title>
    <url>%2FWindows-Vmware-Centos-share-Folder%2F</url>
    <content type="text"><![CDATA[先安装包依赖：yum -y install kernel-devel-$(uname -r) net-tools perl gcc gcc-c++ 安装vm tool在home文件夹下新建tmp文件夹：mkdir tmp mount /dev/cdrom /home/tmp cp /home/tmp/VMwareTools-10.2.5-8068393.tar.gz /tmp cd /tmp tar -zxvf VMwareTools-10.2.5-8068393.tar.gz cd vmware-tools-distrib ./vmware-install.pl 根据提示输入或一直回车即 安装挂载工具yum install -y open-vm-tools-devel]]></content>
      <categories>
        <category>linux</category>
        <category>centos</category>
        <category>vmware</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>linux</tag>
        <tag>vmware</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github安装hexo博客]]></title>
    <url>%2FBlog-Hexo-Install%2F</url>
    <content type="text"><![CDATA[写在开头 什么是Hexo？ Hexo是一个轻量级的Node.js博客框架，由一位台湾的在校大学生开发完成！ Hexo的配置文件_config.yml分为两种，一种是站点配置文件，也就是站点根目录下的_config.yml配置文件，另一个是主题配置文件，位于theme文件夹中对应主题的文件夹下的_config.yml。 在后续的网站配置中需要多次使用站点配置文件和主题配置文件，需要注意辨析。 安装node.jsWindows下安装在nodejs官网上下载最新的Windows安装包，直接安装即可。 ubuntu下安装命令行方式安装：sudo apt-get update sudo apt-get install nodejs 编译源码方式安装：在nodejs官网上找到需要下载的源码（不是二进制文件），解压之后进入目录，执行： $ ./configure $ make &amp;&amp; make install 注意如果需要sudo的话， make和make install 要分开，因为sudo不能传递到&amp;&amp;后面的指令。 安装npmsudo apt-get update sudo apt-get install npm 查看node和npm版本 node -v npm -v 安装cnpm 因为防火墙的缘故，很多境外网站被墙了，所以使用node.js的原生工具npm是无法正常安装模块的，建议使用淘宝前端组的国内镜像，使用他们定制的 cnpm (gzip 压缩支持) 命令行工具代替默认的 npm: npm install -g cnpm --registry=https://registry.npm.taobao.org 使用方法如下： 从registry.npm.taobao.org 安装所有模块. 当安装的时候发现安装的模块还没有同步过来, 淘宝 NPM 会自动在后台进行同步, 并且会让你从官方 NPM registry.npmjs.org 进行安装. 下次你再安装这个模块的时候, 就会直接从 淘宝 NPM 安装了. cnpm install [name] Hexo的安装与使用安装Hexo安转了node之后，就可以使用以下命令来安装hexo： npm install -g hexo-cli 使用Hexo安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。 hexo init &lt;folder&gt; cd &lt;folder&gt; npm install 新建完成后，指定文件夹的目录如下： ├── _config.yml├── package.json├── scaffolds├── source | ├── _drafts | └── _posts└── themes _config.yml 网站的 配置 信息 您可以在此配置网站大部分的参数。 package.json 应用程序的信息。EJS, Stylus 和 Markdown renderer 已默认安装，您可以自由移除。 package.json { &quot;name&quot;: &quot;hexo-site&quot;, &quot;version&quot;: &quot;0.0.0&quot;, &quot;private&quot;: true, &quot;hexo&quot;: { &quot;version&quot;: &quot;&quot; }, &quot;dependencies&quot;: { &quot;hexo&quot;: &quot;^3.0.0&quot;, &quot;hexo-generator-archive&quot;: &quot;^0.1.0&quot;, &quot;hexo-generator-category&quot;: &quot;^0.1.0&quot;, &quot;hexo-generator-index&quot;: &quot;^0.1.0&quot;, &quot;hexo-generator-tag&quot;: &quot;^0.1.0&quot;, &quot;hexo-renderer-ejs&quot;: &quot;^0.1.0&quot;, &quot;hexo-renderer-stylus&quot;: &quot;^0.2.0&quot;, &quot;hexo-renderer-marked&quot;: &quot;^0.2.4&quot;, &quot;hexo-server&quot;: &quot;^0.1.2&quot; } } scaffolds模版 文件夹。当您新建文章时，Hexo 会根据 scaffold 来建立文件。 Hexo的模板是指在新建的markdown文件中默认填充的内容。例如，如果您修改scaffold/post.md中的Front-matter内容，那么每次新建一篇文章时都会包含这个修改。 source资源文件夹是存放用户资源的地方。 除 _posts 文件夹之外，开头命名为 _(下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。 themes主题 文件夹。 Hexo 会根据主题来生成静态页面。 安装hexo插件在hexo中实现可视化编辑博客（hexo-admin）hexo-admin-github 安装并使用hexo-adminnpm install --save hexo-admin hexo server -d open http://localhost:4000/admin/ 设置后台密码修改站点配置文件，就是网站根目录下的 _config.yml文件: admin: username: myfavoritename password_hash: be121740bf988b2225a313fa1f107ca1 secret: a secret something username是用户名 password_hash是密码的哈希映射值，由于不同版本的node.js的哈希算法是不一样的，所有用以下方法来产生有效的密码哈希值。 &gt; node &gt; const bcrypt = require(&#39;bcrypt-nodejs&#39;) &gt; bcrypt.hashSync(&#39;your password secret here!&#39;) &gt; //=&gt; &#39;2a10$8f0CO288aEgpb0BQk0mAEOIDwPS.s6nl703xL6PLTVzM.758x8xsi&#39; &gt; secret是用于产生cookie值的。 在站点配置文件中设置好以下三个值之后，登录 http://localhost:4000/admin/ 就会提示输入账号密码。 在hexo中实现RRS功能（ hexo-generator-feed ）安装 npm install hexo-generator-feed --save 配置在网站的根目中的_config.yml文件设置 feed: type: atom path: atom.xml limit: 20 hub: content: type - Feed type. (atom/rss2)path - Feed path. (Default: atom.xml/rss2.xml)limit - Maximum number of posts in the feed (Use 0 or false to show all posts)hub - URL of the PubSubHubbub hubs (Leave it empty if you don’t use it)content - (optional) set to ‘true’ to include the contents of the entire post in the feed. 在hexo中实现本地搜索功能（hexo-generator-searchdb）安装 hexo-generator-searchdb，在站点的根目录下执行以下命令： npm install hexo-generator-searchdb --save 编辑 站点配置文件，新增以下内容到任意位置： search: path: search.xml field: post format: html limit: 10000 除了安装本地搜索，还可以考虑 swiftype 的搜索。 更换hexo主题Hexo有很多主题，可以在 Hexo官网的主题页面 选择自己喜欢。以Next为例，本站使用的就是Next主题。 使用Git来获取主题文件 git clone https://github.com/iissnan/hexo-theme-next themes/next 直接在Next的 GitHub主页 下载主题文件 将Next文件夹放到theme文件夹中，修改站点配置文件，也就是网站根目录下的_config.yml文件中的theme： # Extensions ## Plugins: https://hexo.io/plugins/ ## Themes: https://hexo.io/themes/ theme: next 上传到github如果你一切都配置好了，发布上传很容易，一句hexo d就搞定，当然关键还是你要把所有东西配置好。 首先，ssh key肯定要配置好。 创建SSH在gitbash中输入：ssh-keygen -t rsa -C &quot;youremail@example.com，生成ssh。然后按下面的方式找到id_rsa.pub文件的内容。 $ cd ~/.ssh/ $ ls id_rsa id_rsa.pub known_hosts $ cat id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC0avsgprEOmpE1yVnbU4hjireV3Ozxb5vFLl4KXgkVY9X3O78E5y10rSa9CHs4lFao/Gij3G/VuXAC/id0pY7ti/BD6CmY8etFlZun9Zw+7Z41gRRrFxreXGwFhzfJeu6CVGYSQgPMjgu1TCCO9wM1hwU41T/Nof3F2kDlRn0pxvmIAkGNy/E8dtB9alY7ObNyrMuACZX8k42STttlte6MlelBVckFyks5IwQ+WdBc0giZTlfXbrL455HiEXitN20FQDznFoX96+iBlAa/WTE2fqVlKY22t5rmyU//JQkFG9ttxAOinADzTLskysE3eWaiupvA0gAjRc4rr8Sg83gJ huangkuier@gmail.com 把id_rsa.pub文件的内容添加到github的ssh key中。 其次，配置_config.yml中有关deploy的部分： 正确写法： deploy: type: git repository: git@github.com:hunkier/hunkier.github.io.git branch: master 错误写法： deploy: type: github repository: https://github.com/hunkier/hunkier.github.io.git branch: master 后面一种写法是hexo2.x的写法，现在已经不行了，无论是哪种写法，此时直接执行hexo d的话一般会报如下错误： Deployer not found: github 或者 Deployer not found: git 原因是还需要安装一个插件： npm install hexo-deployer-git --save 其它命令不确定，部署这个命令一定要用git bash，否则会提示Permission denied (publickey). 打开你的git bash，输入hexo d就会将本次有改动的代码全部提交，没有改动的不会： 常用hexo命令常见命令 hexo new &quot;postName&quot; #新建文章 hexo new page &quot;pageName&quot; #新建页面 hexo generate #生成静态页面至public目录 hexo server #开启预览访问端口（默认端口4000，&#39;ctrl + c&#39;关闭server） hexo deploy #部署到GitHub hexo help # 查看帮助 hexo version #查看Hexo的版本 缩写： hexo n == hexo new hexo g == hexo generate hexo s == hexo server hexo d == hexo deploy 组合命令： hexo s -g #生成并本地预览 hexo d -g #生成并上传 使用其他端口命令： hexo s -p 5000 (node:13224) [DEP0061] DeprecationWarning: fs.SyncWriteStream is deprecated. INFO Start processing INFO Hexo is running at http://localhost:5000/. 4.11. _config.yml这里面都是一些全局配置，每个参数的意思都比较简单明了，所以就不作详细介绍了。 需要特别注意的地方是，冒号后面必须有一个空格，否则可能会出问题。 4.12. 写博客定位到我们的hexo根目录，执行命令： hexo new &#39;my-first-blog&#39; hexo会帮我们在_posts下生成相关md文件 当然你也可以直接自己新建md文件，用这个命令的好处是帮我们自动生成了时间。 一般完整格式如下： --- title: postName #文章页面上的显示名称，一般是中文 date: 2013-12-02 15:30:16 #文章生成时间，一般不改，当然也可以任意修改 categories: 默认分类 #分类 tags: [tag1,tag2,tag3] #文章标签，可空，多标签请用格式，注意:后面有个空格 description: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面 --- 以下是正文 那么hexo new page &#39;postName&#39;命令和hexo new &#39;postName&#39;有什么区别呢？ hexo new page &quot;my-second-blog&quot; 最终部署时生成：hexo\public\my-second-blog\index.html，但是它不会作为文章出现在博文目录。 写博客工具那么用什么工具写博客呢？这个我还没去找，以前自己使用editor.md简单弄了个，大家有好用的hexo写博客工具可以推荐个。 https://www.typora.io 如何让博文列表不显示全部内容默认情况下，生成的博文目录会显示全部的文章内容，如何设置文章摘要的长度呢？ 答案是在合适的位置加上&lt;!--more--&gt;即可，例如： # 前言 使用github pages服务搭建博客的好处有： 1. 全是静态文件，访问速度快； 2. 免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台； 3. 可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于github的； &lt;!--more--&gt; 4. 数据绝对安全，基于github的版本管理，想恢复到哪个历史版本都行； 5. 博客内容可以轻松打包、转移、发布到其它平台； 6. 等等；]]></content>
      <categories>
        <category>github</category>
        <category>blog</category>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>blog</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell脚本命令备忘]]></title>
    <url>%2FShell-notes%2F</url>
    <content type="text"><![CDATA[这里收藏工作中用到的脚本，也为了防止做重复的搜索工作，同时分享给大家。 数组 初始化数组name = (value1 value2 ... valuen) $ A=(a b c d) $ echo ${A[@]} # 输出所有元素 数组去重 $ array=($(awk -vRS=&#39; &#39; &#39;!a[$1]++&#39; &lt;&lt;&lt; ${array[@]})) 取得数组元素的个数 $ echo ${#A[@]} 取下标 $ echo ${A[1]} # 从1开始 清除元素 $ unset A $ echo ${A[@]} 循环取元素 $ for a in ${A[@]}; do $ echo &quot;$a&quot; $ done 替换 $ ${A[@]/3/100} date 获取当前日期并格式化成指定格式 $ NOW=$(date +&#39;%Y-%m-%d_%H%M%S&#39;) # 2016-09-07_184914 计算当前时间的时间戳 $ STAMP=$(($(date +%s -d &quot;$(date +&#39;%Y-%m-%d %H:%M:%S&#39;)&quot;))) # 1473245414 计算N天之前的时间 # 十天之前的日期 $ TEN_DAYS_AGO=$(($(date -d &#39;-10 day&#39; &quot;+%Y%m%d%H%M%S&quot;))) #20160828185138 获取xxxx年xx月的天数 # 获取 2016-10 的天数 $ cal 10 2016 | awk &#39;NF{out=$NF;}END{print out}&#39; 输出 31 vim vi/vim修改只读(readonly)文件，使用sudo修改:w !sudo tee % &gt; /dev/null awk 过滤数字 $ echo &quot;123&quot; |awk &#39;{if($0 ~ /^[0-9]+$/) print $0;}&#39; 数字求和 $ cat ${FILE} | awk &#39;{sum += $1};END {printf (&quot;%d\n&quot;, sum)}&#39; 截取字符串 $ echo &quot;123456&quot; | awk &#39;{print substr($1,1,4)}&#39; #1234 获取月份所在季度 $ for q in `seq 1 12`; echo $q | awk &#39;{season_least=$1%3} {season=$1/3} {if(season_least&gt;0) season+=1} {printf(&quot;%d\n&quot;,season)}&#39; 输出 1 1 1 2 2 2 3 3 3 4 4 4 删除所有空格 $ echo &quot;1 2 3 4&quot; | sed -e &#39;s/[[:space:]]//g &#39; 输出 1234 替换所有的.为/ $ echo &quot;com.xiongyingqi.Test&quot; | awk &#39;{gsub(/\./,&quot;/&quot;); print $0}&#39; 输出 com/xiongyingqi/Test sed 去除首尾空格 $ FOO_NO_EXTERNAL_SPACE=&quot;$(echo -e &quot;${FOO}&quot; | sed -e &#39;s/^[[:space:]]*//&#39; -e &#39;s/[[:space:]]*$//&#39;)&quot; 删除空行 $ sed &#39;/^$/d&#39; sources.list uniq 统计重复数$ cat file | uniq -c 文件 寻找有指定内容的文件 $ FOUND=&quot;test&quot; # 需要查找的内容 $ find . | while read file; do if [ -f $file ]; then content=`cat ${file} | grep &quot;${FOUND}&quot;`; if [ -n &quot;$content&quot; ]; then echo ${file} ; fi; fi; done 列举文件并用管道打包 $ find . -name &quot;*.class&quot; | xargs tar cvf classes.tar 变量我们先写一个简单的脚本，执行以后再解释各个变量的意义 $ touch variable $ vi variable 脚本内容如下： #!/bin/sh echo &quot;number:$#&quot; echo &quot;scname:$0&quot; echo &quot;first :$1&quot; echo &quot;second:$2&quot; echo &quot;argume:$@&quot; echo &quot;show parm list:$*&quot; echo &quot;show process id:$$&quot; echo &quot;show precomm stat: $?&quot; 保存退出 赋予脚本执行权限 $ chmod +x variable 执行脚本 $ ./variable aa bb 输出 number:2 scname:./variable first:aa second:bb argume:aa bb show parm list:aa bb show process id:24544 show precomm stat:0 通过显示结果可以看到： $# 是传给脚本的参数个数 $0 是脚本本身的名字 $1 是传递给该shell脚本的第一个参数 $2 是传递给该shell脚本的第二个参数 $@ 是传给脚本的所有参数的列表 $* 是以一个单字符串显示所有向脚本传递的参数，与位置变量不同，参数可超过9个 $$ 是脚本运行的当前进程ID号 $? 是显示最后命令的退出状态，0表示没有错误，其他表示有错误 例子 *amount.txt 下所有文件的第8列数字之和 iconv -fgbk 为转换文件为 gbk ls *amount.txt | while read file; do cat ${file}; done | iconv -fgbk | awk -F &quot;\t&quot; &#39;{print $8}&#39; | awk &#39;{if($0 ~ /^[0-9]+$/) print $0;}&#39; | awk &#39;{sum += $1};END {printf (&quot;%d\n&quot;, sum)}&#39; 将目录下的jar文件转换为maven格式的依赖 #!/bin/bash find . -name &quot;*.jar&quot; | while read jar; do artifact=`echo ${jar} | awk &#39;{print substr($jar,1,length($jar)-4);}&#39;` version=`echo &quot;$artifact&quot; | awk -F &#39;-&#39; &#39; { print $NF } &#39;` if [ $version == $artifact ]; then version=&quot;1.0&quot; else artifact=`echo &quot;$artifact&quot; | awk -v version=&quot;$version&quot; &#39;{print substr($1,1,index($1,version)-2)}&#39;` fi # find group groupDirectory=`jar -tf $jar | grep &quot;.class&quot; | head -n 1` last=`echo &quot;$groupDirectory&quot; | awk -F &#39;/&#39; &#39; { print $NF } &#39;` group=`echo &quot;$groupDirectory&quot; | awk -v last=&quot;$last&quot; &#39;{print substr($1,1,index($1,last)-2)}&#39;` # replace / to . group=`echo $group | awk &#39;{gsub(/\//,&quot;.&quot;); print $0}&#39;` echo &quot; &lt;dependency&gt; &lt;groupId&gt;${group}&lt;/groupId&gt; &lt;artifactId&gt;${artifact}&lt;/artifactId&gt; &lt;version&gt;${version}&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;\${project.basedir}/lib/${jar}&lt;/systemPath&gt; &lt;/dependency&gt;&quot; #&gt;&gt; &quot;dependencies.tmp&quot; done 查找java类所在当前目录内的jar包 $ FOUND=&quot;com.xiongyingqi.Test&quot; &amp;&amp; ls *.jar | while read jar; do jar tf $jar | grep `echo &quot;${FOUND}&quot; | awk &#39;{gsub(/\./,&quot;/&quot;); print $0}&#39;` | awk -v jar=&quot;$jar&quot; &#39;{if (length($1) &gt; 0) print jar}&#39;; done 将目录内的文件转换为classpath需要的参数 ls lib/*.jar | xargs | awk -v d=&quot;${delete}&quot; &#39;{ str=&quot;&quot;; is_in=0; for(i=1;i&lt;=NF;i++){ if($i!=d){ if(is_in == 1){ str=str&quot;:&quot;$i; }else{ str=str&quot;&quot;$i; is_in=1; } } } print str }&#39; 查找某个目录下所有的jar包里面有哪些class是冲突的shell脚本 #!bin/bash echo &quot;Find out conflict class in the given path&quot;; if [ $# != 1 ] ; then echo &quot;Usage: sh findconflictclass.sh $1 ,first param means the path you want to find,eg: sh findconflictclass.sh lib&quot;; exit 1; fifindconflictclass.sh echo &quot;Please wait ...&quot;; jarpath=$1; function unjarclass(){ for i in `find $jarpath -name *.jar`; do jar -tvf &quot;$i&quot; |grep .class$ | awk &#39;{print $8}&#39; ; # if [[ $? == 0 ]]; then echo $i; fi; done } unjarclass 1&gt;temp.txt; echo &#39;unjar class in the given path has done&#39;; sleep 10s function findclassinjar(){ echo -e &quot;\033[47;31m &#39;The class $1 exists in multi-place below:&#39; \033[0m&quot; ; for i in `find $2 -name *.jar`; do jar -tvf &quot;$i&quot; | grep --color -i &quot;$1&quot; ; if [[ $? == 0 ]]; then echo -e &quot;\033[33m &#39;The jar path is: $i&#39; \033[0m&quot; ; fi; done } sort temp.txt | uniq -d | cat | while read line; do a=$line; findclassinjar $a $jarpath;done rm -rf temp.txt 替换字符串 $ data=&quot;a&quot; &amp;&amp; newdata=&quot;c&quot; &amp;&amp; echo &quot;aaabbba&quot;|awk -v var=${1} -v var1=${data} -v var2=${newdata} &#39;$0 ~ var {gsub(var1,var2); print}&#39; 输出 cccbbbc 文件内容替换替换当前目录下的所有文件内容中的hello为helloworld find . -type f | while read file; do sed -i &#39;s/hello/helloworld/g&#39; $file;done 测试curl $ size=1000;i=0; while [ $i -lt $size ];do i=$((i+1)); curl &quot;http://baidu.com&quot; &amp; done 获取从开始日期到结束日期所经历过的季度 FROM_DATE=&quot;$1&quot; TO_DATE=&quot;$2&quot; FROM_SEASON=`echo &quot;${FROM_DATE}&quot; | awk -F &quot;-&quot; &#39;{print $2}&#39;| awk &#39;{season_least=$1%3} {season=$1/3} {if(season_least&gt;0) season+=1} {printf(&quot;%d\n&quot;,season)}&#39;` TO_SEASON=`echo &quot;${TO_DATE}&quot; | awk -F &quot;-&quot; &#39;{print $2}&#39;| awk &#39;{season_least=$1%3} {season=$1/3} {if(season_least&gt;0) season+=1} {printf(&quot;%d\n&quot;,season)}&#39;` echo &quot;FROM_SEASON: ${FROM_SEASON}&quot; echo &quot;TO_SEASON: ${TO_SEASON}&quot; FROM_YEAR=`echo &quot;${FROM_DATE}&quot; | awk -F &quot;-&quot; &#39;{print $1}&#39;` TO_YEAR=`echo &quot;${TO_DATE}&quot; | awk -F &quot;-&quot; &#39;{print $1}&#39;` year_season_file=&quot;year_season.tmp&quot; if [ -f ${year_season_file} ];then echo &quot;delete file: ${year_season_file}&quot; rm -f ${year_season_file} fi if [ ${FROM_YEAR} -eq ${TO_YEAR} ]; then for season in `seq ${FROM_SEASON} ${TO_SEASON}`; do echo &quot;${FROM_YEAR}Q${season}&quot; &gt;&gt; ${year_season_file} done else for season in `seq ${FROM_SEASON} 4`; do echo &quot;${FROM_YEAR}Q${season}&quot; &gt;&gt; ${year_season_file} done #FROM_YEAR if [ $((TO_YEAR-FROM_YEAR)) -ge 2 ]; then for year in `seq $((FROM_YEAR+1)) $((TO_YEAR-1))`; do for season in `seq 1 4`; do echo &quot;${year}Q${season}&quot; &gt;&gt; ${year_season_file} done done fi for season in `seq 1 ${TO_SEASON}`; do echo &quot;${TO_YEAR}Q${season}&quot; &gt;&gt; ${year_season_file} done fi cat ${year_season_file} 多线程访问 for ((i=0;i&lt;10;)); do for j in `seq 1 100`; do curl &quot;http://baidu.com&quot; &amp; done; wait; i=$((i+1)); done 按列合并 cat filtsoort | awk &#39;{sum[$1]+=$2}END{for (i in sum) print i&quot; &quot;sum[i]}&#39; 转换编码 find . -name &quot;*.java&quot; | while read file; do iconv -f gbk -t utf-8 $file &gt; ${file}.bak; mv -f ${file}.bak $file; done word转换为markdown需要先安装w2m: benbalter/word-to-markdown find doc -name &quot;*.doc&quot; | while read file; do folder_tmp=&quot;markdown/$file&quot;; folder=${folder_tmp%/*}; target_file=&quot;${folder_tmp%%.*}&quot;.md mkdir -p $folder; w2m $file &gt; $target_file; done 移除base64图像 sed -i &#39;s-\!\[\](data:image\/\*;base64,.*)--g&#39; $file 判断是否为asccii字符串（英文字符） echo &quot;呵呵&quot; | awk &#39;{ print (length($0)&gt;NF)}&#39; #1 输出带颜色的字符shell脚本中echo显示内容带颜色显示,echo显示带颜色，需要使用参数-e格式如下： echo -e &quot;\033[字背景颜色；文字颜色m字符串\033[0m&quot; 例如： echo -e &quot;\033[41;36m something here \033[0m&quot; 其中41的位置代表底色， 36的位置是代表字的颜色 注：1、字背景颜色和文字颜色之间是英文的””2、文字颜色后面有个m3、字符串前后可以没有空格，如果有的话，输出也是同样有空格 下面是相应的字和背景颜色，可以自己来尝试找出不同颜色搭配例 echo -e &quot;\033[31m 红色字 \033[0m&quot; echo -e &quot;\033[34m 黄色字 \033[0m&quot; echo -e &quot;\033[41;33m 红底黄字 \033[0m&quot; echo -e &quot;\033[41;37m 红底白字 \033[0m&quot; 字颜色：30—–37 echo -e &quot;\033[30m 黑色字 \033[0m&quot; echo -e &quot;\033[31m 红色字 \033[0m&quot; echo -e &quot;\033[32m 绿色字 \033[0m&quot; echo -e &quot;\033[33m 黄色字 \033[0m&quot; echo -e &quot;\033[34m 蓝色字 \033[0m&quot; echo -e &quot;\033[35m 紫色字 \033[0m&quot; echo -e &quot;\033[36m 天蓝字 \033[0m&quot; echo -e &quot;\033[37m 白色字 \033[0m&quot; 字背景颜色范围：40—–47 echo -e &quot;\033[40;37m 黑底白字 \033[0m&quot; echo -e &quot;\033[41;37m 红底白字 \033[0m&quot; echo -e &quot;\033[42;37m 绿底白字 \033[0m&quot; echo -e &quot;\033[43;37m 黄底白字 \033[0m&quot; echo -e &quot;\033[44;37m 蓝底白字 \033[0m&quot; echo -e &quot;\033[45;37m 紫底白字 \033[0m&quot; echo -e &quot;\033[46;37m 天蓝底白字 \033[0m&quot; echo -e &quot;\033[47;30m 白底黑字 \033[0m&quot; 最后面控制选项说明 \33[0m 关闭所有属性 \33[1m 设置高亮度 \33[4m 下划线 \33[5m 闪烁 \33[7m 反显 \33[8m 消隐 \33[30m — \33[37m 设置前景色 \33[40m — \33[47m 设置背景色 \33[nA 光标上移n行 \33[nB 光标下移n行 \33[nC 光标右移n行 \33[nD 光标左移n行 \33[y;xH设置光标位置 \33[2J 清屏 \33[K 清除从光标到行尾的内容 \33[s 保存光标位置 \33[u 恢复光标位置 \33[?25l 隐藏光标 \33[?25h 显示光标 function echoGreen(){ echo -e &quot;\033[32m$1\033[0m&quot; } function echoRed(){ echo -e &quot;\033[31m$1\033[0m&quot; } function echoYellow(){ echo -e &quot;\033[33m$1\033[0m&quot; } 从第二行开始显示cat file | awk &#39;NR&gt;2{print p}{p=$0}&#39;]]></content>
      <tags>
        <tag>shell</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[加微信好友]]></title>
    <url>%2FMy-wechat%2F</url>
    <content type="text"><![CDATA[打开微信，扫一扫加微信好友]]></content>
      <categories>
        <category>github</category>
        <category>hexo</category>
        <category>wechat</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>hexo</tag>
        <tag>wechat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Hosted by Coding Pages Quick StartCreate a new post$ hexo new &quot;My New Post&quot; More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>github</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
