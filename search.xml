<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Centos 7 设置DNS服务器]]></title>
    <url>%2FCentos-7-Seting-DNS-Server%2F</url>
    <content type="text"><![CDATA[CentOS 7需要使用全新的命令行工具 nmcli 来设置 显示当前网络连接[root@bogon ~]# nmcli connection show NAME UUID TYPE DEVICE cni0 b2b8f5f9-acd2-42fd-9ec9-a76282425cd9 bridge cni0 docker0 33ebd49e-fd1b-4a2c-8261-c0463f4f4146 bridge docker0 enp2s0 b6579214-0ba6-4bf0-9319-2e0e4f584afd ethernet enp2s0 virbr0 976717ae-c3ae-4582-aa09-039c26bef80d bridge virbr0 修改当前网络连接对应的DNS服务器，这里的网络连接可以用名称或者UUID来标识[root@bogon ~]# nmcli con mod enp2s0 ipv4.dns &quot;114.114.114.114 8.8.8.8&quot; [root@bogon ~]# 将dns配置生效[root@bogon ~]# nmcli con up enp2s0 Connection successfully activated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/7) 测试网络[root@bogon ~]# ping www.baidu.com PING www.a.shifen.com (14.215.177.39) 56(84) bytes of data. 64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=1 ttl=53 time=5.48 ms 64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=2 ttl=53 time=5.60 ms 64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=3 ttl=53 time=5.48 ms 64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=4 ttl=53 time=8.57 ms 64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=5 ttl=53 time=5.54 ms ^C --- www.a.shifen.com ping statistics --- 5 packets transmitted, 5 received, 0% packet loss, time 4005ms rtt min/avg/max/mdev = 5.485/6.138/8.575/1.222 ms [root@bogon ~]#]]></content>
      <categories>
        <category>centos</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows环境下Vmware中Centos共享文件]]></title>
    <url>%2FWindows-Vmware-Centos-share-Folder%2F</url>
    <content type="text"><![CDATA[先安装包依赖：yum -y install kernel-devel-$(uname -r) net-tools perl gcc gcc-c++ 安装vm tool在home文件夹下新建tmp文件夹：mkdir tmp mount /dev/cdrom /home/tmp cp /home/tmp/VMwareTools-10.2.5-8068393.tar.gz /tmp cd /tmp tar -zxvf VMwareTools-10.2.5-8068393.tar.gz cd vmware-tools-distrib ./vmware-install.pl 根据提示输入或一直回车即 安装挂载工具yum install -y open-vm-tools-devel]]></content>
      <categories>
        <category>linux</category>
        <category>centos</category>
        <category>vmware</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>linux</tag>
        <tag>vmware</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mycat 按月分表]]></title>
    <url>%2Fmycat-single-database-log-table-part-by-month%2F</url>
    <content type="text"><![CDATA[什么是MYCAT• 一个彻底开源的，面向企业应用开发的大数据库集群• 支持事务、ACID、可以替代MySQL的加强版数据库• 一个可以视为MySQL集群的企业级数据库，用来替代昂贵的Oracle集群• 一个融合内存缓存技术、NoSQL技术、HDFS大数据的新型SQL Server• 结合传统数据库和新型分布式数据仓库的新一代企业级数据库产品• 一个新颖的数据库中间件产品 Mycat关键特性• 支持SQL92标准• 支持MySQL、Oracle、DB2、SQL Server、PostgreSQL等DB的常见SQL语法• 遵守Mysql原生协议，跨语言，跨平台，跨数据库的通用中间件代理。• 基于心跳的自动故障切换，支持读写分离，支持MySQL主从，以及galera cluster集群。• 支持Galera for MySQL集群，Percona Cluster或者MariaDB cluster• 基于Nio实现，有效管理线程，解决高并发问题。• 支持数据的多片自动路由与聚合，支持sum,count,max等常用的聚合函数,支持跨库分页。• 支持单库内部任意join，支持跨库2表join，甚至基于caltlet的多表join。• 支持通过全局表，ER关系的分片策略，实现了高效的多表join查询。• 支持多租户方案。• 支持分布式事务（弱xa）。• 支持XA分布式事务（1.6.5）。• 支持全局序列号，解决分布式下的主键生成问题。• 分片规则丰富，插件化开发，易于扩展。• 强大的web，命令行监控。• 支持前端作为MySQL通用代理，后端JDBC方式支持Oracle、DB2、SQL Server 、 mongodb 、巨杉。• 支持密码加密• 支持服务降级• 支持IP白名单• 支持SQL黑名单、sql注入攻击拦截• 支持prepare预编译指令（1.6）• 支持非堆内存(Direct Memory)聚合计算（1.6）• 支持PostgreSQL的native协议（1.6）• 支持mysql和oracle存储过程，out参数、多结果集返回（1.6）• 支持zookeeper协调主从切换、zk序列、配置zk化（1.6）• 支持库内分表（1.6）• 集群基于ZooKeeper管理，在线升级，扩容，智能优化，大数据处理（2.0开发版）。一、分表规则dm_log和dm_opendoor_record表每年数据量两千万左右，平均每个月两百万左右，mysql单表数据量达到800万时性能出现明显下降，此时需要考虑优化。优先方案考虑优化程序以及sql语句，再优化表结构，最后才是分库分表。自然月分表，每个月分一张表，分表规则定义在MYCAT_HOME/conf/rule.xml中具体如下： &lt;tableRule name=&quot;dm_log_sharding-by-date&quot;&gt; &lt;rule&gt; &lt;columns&gt;logtime&lt;/columns&gt; &lt;algorithm&gt;partbymonth&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;tableRule name=&quot;dm_opendoor_record_sharding-by-date&quot;&gt; &lt;rule&gt; &lt;columns&gt;opertime&lt;/columns&gt; &lt;algorithm&gt;partbymonth&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;function name=&quot;partbymonth&quot; class=&quot;io.mycat.route.function.PartitionByMonth&quot;&gt; &lt;property name=&quot;dateFormat&quot;&gt;yyyy-MM-dd HH:mm:ss&lt;/property&gt; &lt;property name=&quot;sBeginDate&quot;&gt;2014-01-01 00:00:00&lt;/property&gt; &lt;property name=&quot;sEndDate&quot;&gt;2014-12-31 00:00:00&lt;/property&gt; &lt;/function&gt; dm_log表按logtime字段根据partbymonth算法分表，dm_opendoor_record表按opertime字段根据partbymonth算法分表，算法partbymonth中的dateFormat定义时间格式，在sql语句增删改查中时间需要按照定义格式传入，才能正常执行分表算法。分表名称定义在MYCAT_HOME/conf/schema.xml &lt;schema name=&quot;mt_pm&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot; dataNode=&quot;mt_pm_dn&quot;&gt; &lt;table name=&quot;dm_log&quot; primaryKey=&quot;logid&quot; autoIncrement=&quot;true&quot; subTables=&quot;dm_log_$1-12&quot; dataNode=&quot;mt_pm_dn&quot; rule=&quot;dm_log_sharding-by-month&quot;/&gt; &lt;table name=&quot;dm_opendoor_record&quot; primaryKey=&quot;id&quot; autoIncrement=&quot;true&quot; subTables=&quot;dm_opendoor_record_$1-12&quot; dataNode=&quot;mt_pm_dn&quot; rule=&quot;dm_opendoor_record_sharding-by-month&quot;/&gt; &lt;/schema&gt; subTables定义了分表的名称：​ dm_log表定义了分表名为dm_log_$1-12，表示分为12张表，表名分别为：dm_log_1、dm_log_2、dm_log_3、dm_log_4、dm_log_5、dm_log_6、dm_log_7、dm_log_8、dm_log_9、dm_log_10、dm_log_11、dm_log_12。logtime为一月份时，根据算法会将数据分配到dm_log_1表，二月份数据插入表dm_log_2，以此类推，到十二月份后的一月份数据又循环插入dm_log_1表。​ dm_opendoor_record表定义了分表名为dm_opendoor_record _$1-12，表示分为12张表，表名分别为：dm_opendoor_record _1、dm_opendoor_record _2、dm_opendoor_record _3、dm_opendoor_record _4、dm_opendoor_record _5、dm_opendoor_record _6、dm_opendoor_record_7、dm_opendoor_record_8、dm_opendoor_record_9、dm_opendoor_record _10、dm_opendoor_record _11、dm_opendoor_record _12。opertime为一月份时，根据算法会将数据分配到dm_opendoor_record _1表，二月份数据插入表dm_opendoor_record_2，以此类推，到十二月份后的一月份数据又循环插入dm_opendoor_record _1表。 二、自增主键原理:​ 在数据库中建立一张表，存放 sequence 名称(name)，sequence 当前值(current_value)，步长(increment) int 类型每次读取多少个 sequence，假设为 K)等信息；Sequence 获取步骤：​ 1).当初次使用该 sequence 时，根据传入的 sequence 名称，从数据库这张表中读取 current_value，和 increment 到 MyCat 中，并将数据库中的 current_value 设置为原 current_value 值+increment 值；​ 2).MyCat 将读取到 current_value+increment 作为本次要使用的 sequence 值，下次使用时，自动加 1，当使用 increment 次后，执行步骤 1)相同的操作.MyCat 负责维护这张表，用到哪些 sequence，只需要在这张表中插入一条记录即可。若某次读取的sequence 没有用完，系统就停掉了，则这次读取的 sequence 剩余值不会再使用。配置方式：MYCAT_HOME/conf/server.xml 配置： &lt;system&gt;&lt;property name=&quot;sequnceHandlerType&quot;&gt;1&lt;/property&gt;&lt;/system&gt; 注：sequnceHandlerType 需要配置为 1，表示使用数据库方式生成 sequence.MYCAT_HOME/conf/schema.xml配置： &lt;schema name=&quot;mt_pm&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot; dataNode=&quot;mt_pm_dn&quot;&gt; &lt;table name=&quot;dm_log&quot; primaryKey=&quot;logid&quot; autoIncrement=&quot;true&quot; subTables=&quot;dm_log_$1-12&quot; dataNode=&quot;mt_pm_dn&quot; rule=&quot;dm_log_sharding-by-month&quot;/&gt; &lt;table name=&quot;dm_opendoor_record&quot; primaryKey=&quot;id&quot; autoIncrement=&quot;true&quot; subTables=&quot;dm_opendoor_record_$1-12&quot; dataNode=&quot;mt_pm_dn&quot; rule=&quot;dm_opendoor_record_sharding-by-month&quot;/&gt; &lt;/schema&gt; 在table节点配置primaryKey和autoIncrement，primaryKey为自增主键，autoIncrement值为ture。 数据库配置：1) 创建 MYCAT_SEQUENCE 表– 创建存放 sequence 的表 DROP TABLE IF EXISTS MYCAT_SEQUENCE; CREATE TABLE MYCAT_SEQUENCE (name VARCHAR(50) NOT NULL,current_value INT NOT NULL,increment INT NOT NULL DEFAULT 100, PRIMARY KEY(name)) ENGINE=InnoDB; name sequence 名称 current_value 当前 value increment 增长步长，可理解为 mycat 在数据库中一次读取多少个 sequence， 当这些用完后, 下次再从数据库中读取。 – 插入sequence INSERT INTO `mycat_sequence` (`name`, `current_value`, `increment`) VALUES (&#39;dm_log&#39;, &#39;152509809922444&#39;, &#39;1000&#39;); INSERT INTO `mycat_sequence` (`name`, `current_value`, `increment`) VALUES (&#39;dm_opendoor_record&#39;, &#39;58733280&#39;, &#39;1000&#39;); 2) 创建相关 function –- 获取当前 sequence 的值 (返回当前值,增量) DROP FUNCTION IF EXISTS mycat_seq_currval; DELIMITER CREATE FUNCTION mycat_seq_currval(seq_name VARCHAR(50)) RETURNS varchar(64) CHARSET utf-8 DETERMINISTIC BEGIN DECLARE retval VARCHAR(64); SET retval=“-999999999,null” ; SELECT concat(CAST(current_value AS CHAR),“,” ,CAST(increment AS CHAR)) INTO retval FROM MYCAT_SEQUENCE WHERE name = seq_name; RETURN retval; END DELIMITER; –- 设置 sequence 值 DROP FUNCTION IF EXISTS mycat_seq_setval; DELIMITER CREATE FUNCTION mycat_seq_setval(seq_name VARCHAR(50),value INTEGER) RETURNS varchar(64) CHARSET utf-8 DETERMINISTIC BEGIN UPDATE MYCAT_SEQUENCE SET current_value = value WHERE name = seq_name; RETURN mycat_seq_currval(seq_name); END DELIMITER; –- 获取下一个 sequence 值 DROP FUNCTION IF EXISTS mycat_seq_nextval; DELIMITER CREATE FUNCTION mycat_seq_nextval(seq_name VARCHAR(50)) RETURNS varchar(64) CHARSET utf-8 DETERMINISTIC BEGIN UPDATE MYCAT_SEQUENCE SET current_value = current_value + increment WHERE name = seq_name; RETURN mycat_seq_currval(seq_name); END DELIMITER; 4) sequence_db_conf.properties 相关配置,指定 sequence 相关配置在哪个节点上：例如： DM_LOG=mt_pm_dn DM_OPENDOOR_RECORD=mt_pm_dn 注意：MYCAT_SEQUENCE 表和以上的 3 个 function，需要放在同一个节点上。 function 请直接在具体节点的数据库上执行，如果执行的时候报：you might want to use the less safe log_bin_trust_function_creators variable需要对数据库做如下设置：windows 下 my.ini[mysqld]加上 log_bin_trust_function_creators=1linux 下/etc/my.cnf 下 my.ini[mysqld]加上 log_bin_trust_function_creators=1修改完后，即可在 mysql 数据库中执行上面的函数.使用示例： INSERT INTO `mt_pm`.`dm_log` (`logid`, `deviceid`, `logtype`, `logtime`, `content`, `picurl`, `id`, `positionid`, `position`, `comid`, `launchposition`, `status`) VALUES (next value for MYCATSEQ_DM_LOG, &#39;af0f69db62-4d31-d4e2-c041-793ed33931&#39;, &#39;unlock&#39;, &#39;2018-01-01 08:01:39&#39;, &#39;3|0e3f6740|1&#39;, NULL, NULL, NULL, NULL, NULL, NULL, NULL); 或者不带主键 INSERT INTO `mt_pm`.`dm_log` (`deviceid`, `logtype`, `logtime`, `content`, `picurl`, `id`, `positionid`, `position`, `comid`, `launchposition`, `status`) VALUES (&#39;af0f69db62-4d31-d4e2-c041-793ed33931&#39;, &#39;unlock&#39;, &#39;2018-01-01 08:01:39&#39;, &#39;3|0e3f6740|1&#39;, NULL, NULL, NULL, NULL, NULL, NULL, NULL); 三、定期备份表数据​ 分为12张表后，每年循环插入数据，最终数据量越来越大，需要定期将历史数据备份或迁移。这里采用修改表名，再新建和原表名结构一样的新表。例如： ALTER TABLE dm_log_1 RENAME TO dm_log201801; CREATE TABLE IF NOT EXISTS dm_log_1 LIKE dm_log201801; ​ 备份dm_log_1的数据，假设dm_log_1存的都是2018年1月份数据，则把表名修改为dm_log201801，然后再吉安一张表名为dm_log_1的表。​ 上述操作在数据库中写成存储过程，通过数据库定时事件调用执行，详细请看附件中相关sql语句。 定时事件调用策略： 每月1日的凌晨3:30执行备份历史数据，例如:2018年7月1日凌晨3:30把表dm_log_1改为dm_log201801并新建表dm_log_1，2018年8月1日凌晨3:30把表dm_log_2改为dm_log201802并新建表dm_log_2，以此类推，保留最近半年的数据供物管系统页面查询，超过半年数据则需通过数据库查询历史数据。 rename_dm_log_history为备份dm_log表数据的存储过程，Event_Rename_dm_log_history为定时事件每月调用rename_dm_log_history备份数据。 每月1日的凌晨3:30执行备份历史数据，例如:2018年7月1日凌晨3:30把表`dm_opendoor_record_1`改为dm_opendoor_record201801并新建表dm_opendoor_record_1，2018年8月1日凌晨3:30把表dm_opendoor_record_2改为dm_opendoor_record201802并新建表dm_opendoor_record_2，以此类推，保留最近半年的数据供物管系统页面查询，超过半年数据则需通过数据库查询历史数据。 rename_dm_opendoor_record_history为备份dm_opendoor_record表数据的存储过程，Event_Rename_dm_opendoor_record_history为定时事件每月调用rename_dm_log_history备份数据。 四、附件1.相关sql语句 2.mycat​五、参考资料Mycat官网：http://www.mycat.io/Mycat权威指南：http://www.mycat.io/document/Mycat_V1.6.0.pdf]]></content>
      <categories>
        <category>mysql</category>
        <category>mycat</category>
        <category>subtable</category>
        <category>partbymonth</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mycat</tag>
        <tag>subtable</tag>
        <tag>partbymonth</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用的Shell脚本和Linux命令]]></title>
    <url>%2FCommon-shell-script%2F</url>
    <content type="text"><![CDATA[收集工作中经常用的Linux命令和shell脚本 zip 压缩和解压缩 # 压缩文件夹 zip -r data.zip data # 解压缩文件,默认解压到当前路径 unzip data.zip # 解压到指定路径 unzip data.zip -d destDir # 查看帮助 unzip -h tar 压缩和解压缩 # 压缩文件夹 tar -czf data.tar.gz data # 解压缩到当前路径 tar -xzf data.tar.gz tail查看和过滤日志文件 # 动态输出Tomcat日志到控制台 tail -1000f catalina.out # 按字段过滤日志 tail -1000f catalina.out | grap -A 20 &#39;ERROR&#39; netstat 查看监听端口的进程 # 查看监听端口为1600的进程 netstat -tlpn | grep &quot;\b16000\b&quot; kill停止指定进程 # 停止当前路径下的应用进程 kill -9 $(ps -ef|grep $(pwd)|grep -v grep|awk &#39;{print $2}&#39;) # 停止监听端口为1600的进程 kill -9 $(netstat -tlpn | grep &quot;\b16000\b&quot; | awk &#39;{print $7}&#39; | cut -d &#39;/&#39; -f 1) sed替换文件内容 # 替换Tomcat默认端口 sed -i &quot;s|&lt;Connector port=\&quot;8080\&quot;|&lt;Connector port=\&quot;51000\&quot;|g&quot; server.xml &amp;&amp; \ sed -i &quot;s|&lt;Connector port=\&quot;8009\&quot;|&lt;Connector port=\&quot;51080\&quot;|g&quot; server.xml crontab定时任务 crontab -e # 每分钟执行一次monitor.sh脚步 */1 * * * * /usr/java/monitor.sh # 数据库备份 0 3 * * * /bin/sh /data1/script/databak.sh &amp; 0 4 * * * find /data1/databak -type f -mtime +3 -exec rm {} \; databak.sh内容 #!/bin/bash /usr/bin/mysqldump -uroot -p123456 test &gt;/data1/databak/`date +%Y%m%d`test.sql 2&gt;/dev/null 监控Tomcat是否正常启动 #!/bin/sh # 定义环境变量（要改成自己的jdk相关地址） PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_191-oraclejdk export CLASSPATH=$JAVA_HOME/lib:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin TomcatHome=/opt/webserver/pf-platform #获取tomcat进程ID（这里注意tomcat7要改成自己的tomcat目录名） TomcatID=$(ps -ef |grep tomcat |grep -w $TomcatHome|grep -v &#39;grep&#39;|awk &#39;{print $2}&#39;) #tomcat启动程序(这里注意要改成自己tomcat实际安装的路径) StartTomcat=$TomcatHome/bin/startup.sh TomcatCache=$TomcatHome/work #自己定义要监控的页面地址，页面越简单越好，比如：页面上写个success即可 WebUrl=http://172.20.8.5:41000/pf-platform/login/login #日志输出 （自己定义地址，用于输出监控日志和监控报错日志） #TomcatMonitorLog=$TomcatHome/TomcatMonitor-$(date &#39;+%Y%m%d%H%M%S&#39;).log TomcatMonitorLog=$TomcatHome/logs/TomcatMonitor-$(date &#39;+%Y-%m-%d&#39;).log GetPageInfo=$TomcatHome/logs/PageInfo-$(date &#39;+%Y-%m-%d&#39;).log if [ ! -d $TomcatHome/logs ]; then mkdir -p $TomcatHome/logs ; fi Monitor() { echo &quot;[info]开始监控tomcat...[$(date +&#39;%F %H:%M:%S&#39;)]&quot; if [[ $TomcatID ]];then # 这里判断TOMCAT进程是否存在 echo &quot;[info]当前tomcat进程ID为:$TomcatID,继续检测页面...&quot; # 检测是否启动成功(成功的话页面会返回状态&quot;302&quot;) TomcatServiceCode=$(curl -s -o $GetPageInfo -m 10 --connect-timeout 10 $WebUrl -w %{http_code}) if [ $TomcatServiceCode -eq 302 ];then echo &quot;[info]页面返回码为$TomcatServiceCode,tomcat启动成功,测试页面正常......&quot; else echo &quot;[error]tomcat页面出错,请注意......状态码为$TomcatServiceCode,错误日志已输出到$GetPageInfo&quot; echo &quot;[error]页面访问出错,开始重启tomcat&quot; kill -9 $TomcatID # 杀掉原tomcat进程 sleep 3 #rm -rf $TomcatCache # 清理tomcat缓存 $StartTomcat fi else echo &quot;[error]tomcat进程不存在!tomcat开始自动重启...&quot; echo &quot;[info]$StartTomcat,请稍候......&quot; #rm -rf $TomcatCache $StartTomcat fi echo &quot;------------------------------&quot; } Monitor&gt;&gt;$TomcatMonitorLog 监控netty服务是否正常开启端口 #!/bin/sh # 定义环境变量（要改成自己的jdk相关地址） PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_191-oraclejdk export CLASSPATH=$JAVA_HOME/lib:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin NettyServerHome=/opt/webserver/mtech-cloud-netty-server #获取netty-server进程ID（这里注意netty-server7要改成自己的netty-server目录名） NettyServerID=$(ps -ef |grep netty-server |grep -w $NettyServerHome |grep -w java |grep -v &#39;grep&#39;|awk &#39;{print $2}&#39;) #netty-server启动程序(这里注意要改成自己netty-server实际安装的路径) StartNettyServer=$NettyServerHome/bin/start.sh #netty监听端口 NettyPort=16000 #日志输出 （自己定义地址，用于输出监控日志和监控报错日志） NettyServerMonitorLog=$NettyServerHome/logs/NettyServerMonitor-$(date +&#39;%F&#39;).log GetPageInfo=$NettyServerHome/logs/PortInfo-$(date +&#39;%F&#39;).log if [ ! -d $NettyServerHome/logs ]; then mkdir -p $NettyServerHome/logs ; fi Monitor() { echo &quot;[info]开始监控netty-server...[$(date +&#39;%F %H:%M:%S&#39;)]&quot; if [[ $NettyServerID ]];then # 这里判断netty-server进程是否存在 echo &quot;[info]当前netty-server进程ID为:$NettyServerID,继续检测端口...&quot; # 检测是否启动成功(成功的话会返回端口信息) NettyServerPort=$(checkPort $NettyPort) echo &quot;端口检测结果：$NettyServerPort &quot; if [ $NettyServerPort -eq 0 ];then echo &quot;[info]返回码为$NettyServerPort,netty-server启动成功,测试端口正常......&quot; else echo &quot;[error]netty-server启动出错,请注意......, 错误日志已输出到$GetPageInfo&quot; echo &quot;[error]端口$NettyPort检测出错,开始重启netty-server&quot; kill -9 $NettyServerID # 杀掉原netty-server进程 sleep 3 #rm -rf $netty-serverCache # 清理netty-server缓存 $StartNettyServer &gt;&gt; $NettyServerHome/logs/nohub.out &amp; &gt;&gt; /dev/null fi else echo &quot;[error]netty-server进程不存在!netty-server开始自动重启...&quot; echo &quot;[info]$StartNettyServer,请稍候......&quot; #rm -rf $netty-serverCache # $StartNettyServer &gt;&gt; /dev/null &amp; $StartNettyServer &gt;&gt; $NettyServerHome/logs/nohub.out &amp; &gt;&gt; /dev/null fi echo &quot;------------------------------&quot; } checkPort() { echo &quot;------------------------------&quot; &gt;&gt; $GetPageInfo echo &quot;$(date +&#39;%F %H:%M:%S&#39;) &quot; &gt;&gt; $GetPageInfo echo $(netstat -tlpn | grep &quot;\b$1\b&quot;) &gt;&gt; $GetPageInfo netstat -tlpn | grep &quot;\b$1\b&quot; | awk &#39;{print $2}&#39; } Monitor&gt;&gt;$NettyServerMonitorLog &amp;]]></content>
      <categories>
        <category>linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发问题--乐观锁与悲观锁以及乐观锁的一种实现方式-CAS]]></title>
    <url>%2FJava-Concurrent-Lock%2F</url>
    <content type="text"><![CDATA[原文：https://www.cnblogs.com/qjjazry/p/6581568.html 首先介绍一些乐观锁与悲观锁: 悲观锁：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。再比如Java里面的同步原语synchronized关键字的实现也是悲观锁。 乐观锁：顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。 乐观锁的一种实现方式-CAS(Compare and Swap 比较并交换)： 锁存在的问题: Java在JDK1.5之前都是靠 synchronized关键字保证同步的，这种通过使用一致的锁定协议来协调对共享状态的访问，可以确保无论哪个线程持有共享变量的锁，都采用独占的方式来访问这些变量。这就是一种独占锁，独占锁其实就是一种悲观锁，所以可以说 synchronized 是悲观锁。 悲观锁机制存在以下问题： 1. 在多线程竞争下，加锁、释放锁会导致比较多的上下文切换和调度延时，引起性能问题。 2. 一个线程持有锁会导致其它所有需要此锁的线程挂起。 3. 如果一个优先级高的线程等待一个优先级低的线程释放锁会导致优先级倒置，引起性能风险。 对比于悲观锁的这些问题，另一个更加有效的锁就是乐观锁。其实乐观锁就是：每次不加锁而是假设没有并发冲突而去完成某项操作，如果因为并发冲突失败就重试，直到成功为止。 乐观锁： 乐观锁（ Optimistic Locking ）在上文已经说过了，其实就是一种思想。相对悲观锁而言，乐观锁假设认为数据一般情况下不会产生并发冲突，所以在数据进行提交更新的时候，才会正式对数据是否产生并发冲突进行检测，如果发现并发冲突了，则让返回用户错误的信息，让用户决定如何去做。 上面提到的乐观锁的概念中其实已经阐述了它的具体实现细节：主要就是两个步骤：冲突检测和数据更新。其实现方式有一种比较典型的就是 Compare and Swap ( CAS )。 CAS： CAS是乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。 CAS 操作中包含三个操作数 —— 需要读写的内存位置（V）、进行比较的预期原值（A）和拟写入的新值(B)。如果内存位置V的值与预期原值A相匹配，那么处理器会自动将该位置值更新为新值B。否则处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。（在 CAS 的一些特殊情况下将仅返回 CAS 是否成功，而不提取当前值。）CAS 有效地说明了“ 我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。 ”这其实和乐观锁的冲突检查+数据更新的原理是一样的。 这里再强调一下，乐观锁是一种思想。CAS是这种思想的一种实现方式。 JAVA对CAS的支持： 在JDK1.5 中新增 java.util.concurrent (J.U.C)就是建立在CAS之上的。相对于对于 synchronized 这种阻塞算法，CAS是非阻塞算法的一种常见实现。所以J.U.C在性能上有了很大的提升。 以 java.util.concurrent 中的 AtomicInteger 为例，看一下在不使用锁的情况下是如何保证线程安全的。主要理解 getAndIncrement 方法，该方法的作用相当于 ++i 操作。 public class AtomicInteger extends Number implements java.io.Serializable { private volatile int value; public final int get() { return value; } public final int getAndIncrement() { for (;;) { int current = get(); int next = current + 1; if (compareAndSet(current, next)) return current; } } public final boolean compareAndSet(int expect, int update) { return unsafe.compareAndSwapInt(this, valueOffset, expect, update); } } 在没有锁的机制下,字段value要借助volatile原语，保证线程间的数据是可见性。这样在获取变量的值的时候才能直接读取。然后来看看 ++i 是怎么做到的。 getAndIncrement 采用了CAS操作，每次从内存中读取数据然后将此数据和 +1 后的结果进行CAS操作，如果成功就返回结果，否则重试直到成功为止。 而 compareAndSet 利用JNI（Java Native Interface）来完成CPU指令的操作： public final boolean compareAndSet(int expect, int update) { return unsafe.compareAndSwapInt(this, valueOffset, expect, update); } 其中unsafe.compareAndSwapInt(this, valueOffset, expect, update);类似如下逻辑： if (this == expect) { this = update return true; } else { return false; } 那么比较this == expect，替换this = update，compareAndSwapInt实现这两个步骤的原子性呢？ 参考CAS的原理 CAS原理： CAS通过调用JNI的代码实现的。而compareAndSwapInt就是借助C来调用CPU底层指令实现的。 下面从分析比较常用的CPU（intel x86）来解释CAS的实现原理。 下面是sun.misc.Unsafe类的compareAndSwapInt()方法的源代码： public final native boolean compareAndSwapInt(Object o, long offset, int expected, int x); 可以看到这是个本地方法调用。这个本地方法在JDK中依次调用的C++代码为： #define LOCK_IF_MP(mp) __asm cmp mp, 0 \ __asm je L0 \ __asm _emit 0xF0 \ __asm L0: inline jint Atomic::cmpxchg (jint exchange_value, volatile jint* dest, jint compare_value) { // alternative for InterlockedCompareExchange int mp = os::is_MP(); __asm { mov edx, dest mov ecx, exchange_value mov eax, compare_value LOCK_IF_MP(mp) cmpxchg dword ptr [edx], ecx } } 如上面源代码所示，程序会根据当前处理器的类型来决定是否为cmpxchg指令添加lock前缀。如果程序是在多处理器上运行，就为cmpxchg指令加上lock前缀（lock cmpxchg）。反之，如果程序是在单处理器上运行，就省略lock前缀（单处理器自身会维护单处理器内的顺序一致性，不需要lock前缀提供的内存屏障效果）。 CAS缺点： 1. ABA问题： 比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且two进行了一些操作变成了B，然后two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后one操作成功。尽管线程one的CAS操作成功，但可能存在潜藏的问题。如下所示： 现有一个用单向链表实现的堆栈，栈顶为A，这时线程T1已经知道A.next为B，然后希望用CAS将栈顶替换为B： head.compareAndSet(A,B); 在T1执行上面这条指令之前，线程T2介入，将A、B出栈，再pushD、C、A，此时堆栈结构如下图，而对象B此时处于游离状态： 此时轮到线程T1执行CAS操作，检测发现栈顶仍为A，所以CAS成功，栈顶变为B，但实际上B.next为null，所以此时的情况变为： 其中堆栈中只有B一个元素，C和D组成的链表不再存在于堆栈中，平白无故就把C、D丢掉了。 从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 public boolean compareAndSet( V expectedReference,//预期引用 V newReference,//更新后的引用 int expectedStamp, //预期标志 int newStamp //更新后的标志 ) 实际应用代码： private static AtomicStampedReference&lt;Integer&gt; atomicStampedRef = new AtomicStampedReference&lt;Integer&gt;(100, 0); ........ atomicStampedRef.compareAndSet(100, 101, stamp, stamp + 1); 2. 循环时间长开销大： 自旋CAS（不成功，就一直循环执行，直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。 3. 只能保证一个共享变量的原子操作： 当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量i＝2,j=a，合并一下ij=2a，然后用CAS来操作ij。从Java1.5开始JDK提供了AtomicReference**类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作。** CAS与Synchronized的使用情景： 1、对于资源竞争较少（线程冲突较轻）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。 2、对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。 补充： synchronized在jdk1.6之后，已经改进优化。synchronized的底层实现主要依靠Lock-Free的队列，基本思路是自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。 concurrent包的实现： 由于java的CAS同时具有 volatile 读和volatile写的内存语义，因此Java线程之间的通信现在有了下面四种方式： 1. A线程写volatile变量，随后B线程读这个volatile变量。 2. A线程写volatile变量，随后B线程用CAS更新这个volatile变量。 3. A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量。 4. A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量。 Java的CAS会使用现代处理器上提供的高效机器级别原子指令，这些原子指令以原子方式对内存执行读-改-写操作，这是在多处理器中实现同步的关键（从本质上来说，能够支持原子性读-改-写指令的计算机器，是顺序计算图灵机的异步等价机器，因此任何现代的多处理器都会去支持某种能对内存执行原子性读-改-写操作的原子指令）。同时，volatile变量的读/写和CAS可以实现线程之间的通信。把这些特性整合在一起，就形成了整个concurrent包得以实现的基石。如果我们仔细分析concurrent包的源代码实现，会发现一个通用化的实现模式： 1. 首先，声明共享变量为volatile； 2. 然后，使用CAS的原子条件更新来实现线程之间的同步； 3. 同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。 AQS，非阻塞数据结构和原子变量类（java.util.concurrent.atomic包中的类），这些concurrent包中的基础类都是使用这种模式来实现的，而concurrent包中的高层类又是依赖于这些基础类来实现的。从整体来看，concurrent包的实现示意图如下： JVM中的CAS（堆中对象的分配）： Java调用new object()会创建一个对象，这个对象会被分配到JVM的堆中。那么这个对象到底是怎么在堆中保存的呢？ 首先，new object()执行的时候，这个对象需要多大的空间，其实是已经确定的，因为java中的各种数据类型，占用多大的空间都是固定的（对其原理不清楚的请自行Google）。那么接下来的工作就是在堆中找出那么一块空间用于存放这个对象。 在单线程的情况下，一般有两种分配策略： 1. 指针碰撞：这种一般适用于内存是绝对规整的（内存是否规整取决于内存回收策略），分配空间的工作只是将指针像空闲内存一侧移动对象大小的距离即可。 2. 空闲列表：这种适用于内存非规整的情况，这种情况下JVM会维护一个内存列表，记录哪些内存区域是空闲的，大小是多少。给对象分配空间的时候去空闲列表里查询到合适的区域然后进行分配即可。 但是JVM不可能一直在单线程状态下运行，那样效率太差了。由于再给一个对象分配内存的时候不是原子性的操作，至少需要以下几步：查找空闲列表、分配内存、修改空闲列表等等，这是不安全的。解决并发时的安全问题也有两种策略： 1. CAS：实际上虚拟机采用CAS配合上失败重试的方式保证更新操作的原子性，原理和上面讲的一样。 2. TLAB：如果使用CAS其实对性能还是会有影响的，所以JVM又提出了一种更高级的优化策略：每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲区（TLAB），线程内部需要分配内存时直接在TLAB上分配就行，避免了线程冲突。只有当缓冲区的内存用光需要重新分配内存的时候才会进行CAS操作分配更大的内存空间。 虚拟机是否使用TLAB，可以通过-XX:+/-UseTLAB参数来进行配置（jdk5及以后的版本默认是启用TLAB的）。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>lock</tag>
        <tag>java</tag>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github安装hexo博客]]></title>
    <url>%2FBlog-Hexo-Install%2F</url>
    <content type="text"><![CDATA[写在开头 什么是Hexo？ Hexo是一个轻量级的Node.js博客框架，由一位台湾的在校大学生开发完成！ Hexo的配置文件_config.yml分为两种，一种是站点配置文件，也就是站点根目录下的_config.yml配置文件，另一个是主题配置文件，位于theme文件夹中对应主题的文件夹下的_config.yml。 在后续的网站配置中需要多次使用站点配置文件和主题配置文件，需要注意辨析。 安装node.jsWindows下安装在nodejs官网上下载最新的Windows安装包，直接安装即可。 ubuntu下安装命令行方式安装：sudo apt-get update sudo apt-get install nodejs 编译源码方式安装：在nodejs官网上找到需要下载的源码（不是二进制文件），解压之后进入目录，执行： $ ./configure $ make &amp;&amp; make install 注意如果需要sudo的话， make和make install 要分开，因为sudo不能传递到&amp;&amp;后面的指令。 安装npmsudo apt-get update sudo apt-get install npm 查看node和npm版本 node -v npm -v 安装cnpm 因为防火墙的缘故，很多境外网站被墙了，所以使用node.js的原生工具npm是无法正常安装模块的，建议使用淘宝前端组的国内镜像，使用他们定制的 cnpm (gzip 压缩支持) 命令行工具代替默认的 npm: npm install -g cnpm --registry=https://registry.npm.taobao.org 使用方法如下： 从registry.npm.taobao.org 安装所有模块. 当安装的时候发现安装的模块还没有同步过来, 淘宝 NPM 会自动在后台进行同步, 并且会让你从官方 NPM registry.npmjs.org 进行安装. 下次你再安装这个模块的时候, 就会直接从 淘宝 NPM 安装了. cnpm install [name] Hexo的安装与使用安装Hexo安转了node之后，就可以使用以下命令来安装hexo： npm install -g hexo-cli 使用Hexo安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。 hexo init &lt;folder&gt; cd &lt;folder&gt; npm install 新建完成后，指定文件夹的目录如下： ├── _config.yml├── package.json├── scaffolds├── source | ├── _drafts | └── _posts└── themes _config.yml 网站的 配置 信息 您可以在此配置网站大部分的参数。 package.json 应用程序的信息。EJS, Stylus 和 Markdown renderer 已默认安装，您可以自由移除。 package.json { &quot;name&quot;: &quot;hexo-site&quot;, &quot;version&quot;: &quot;0.0.0&quot;, &quot;private&quot;: true, &quot;hexo&quot;: { &quot;version&quot;: &quot;&quot; }, &quot;dependencies&quot;: { &quot;hexo&quot;: &quot;^3.0.0&quot;, &quot;hexo-generator-archive&quot;: &quot;^0.1.0&quot;, &quot;hexo-generator-category&quot;: &quot;^0.1.0&quot;, &quot;hexo-generator-index&quot;: &quot;^0.1.0&quot;, &quot;hexo-generator-tag&quot;: &quot;^0.1.0&quot;, &quot;hexo-renderer-ejs&quot;: &quot;^0.1.0&quot;, &quot;hexo-renderer-stylus&quot;: &quot;^0.2.0&quot;, &quot;hexo-renderer-marked&quot;: &quot;^0.2.4&quot;, &quot;hexo-server&quot;: &quot;^0.1.2&quot; } } scaffolds模版 文件夹。当您新建文章时，Hexo 会根据 scaffold 来建立文件。 Hexo的模板是指在新建的markdown文件中默认填充的内容。例如，如果您修改scaffold/post.md中的Front-matter内容，那么每次新建一篇文章时都会包含这个修改。 source资源文件夹是存放用户资源的地方。 除 _posts 文件夹之外，开头命名为 _(下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。 themes主题 文件夹。 Hexo 会根据主题来生成静态页面。 安装hexo插件在hexo中实现可视化编辑博客（hexo-admin）hexo-admin-github 安装并使用hexo-adminnpm install --save hexo-admin hexo server -d open http://localhost:4000/admin/ 设置后台密码修改站点配置文件，就是网站根目录下的 _config.yml文件: admin: username: myfavoritename password_hash: be121740bf988b2225a313fa1f107ca1 secret: a secret something username是用户名 password_hash是密码的哈希映射值，由于不同版本的node.js的哈希算法是不一样的，所有用以下方法来产生有效的密码哈希值。 &gt; node &gt; const bcrypt = require(&#39;bcrypt-nodejs&#39;) &gt; bcrypt.hashSync(&#39;your password secret here!&#39;) &gt; //=&gt; &#39;2a10$8f0CO288aEgpb0BQk0mAEOIDwPS.s6nl703xL6PLTVzM.758x8xsi&#39; &gt; secret是用于产生cookie值的。 在站点配置文件中设置好以下三个值之后，登录 http://localhost:4000/admin/ 就会提示输入账号密码。 在hexo中实现RRS功能（ hexo-generator-feed ）安装 npm install hexo-generator-feed --save 配置在网站的根目中的_config.yml文件设置 feed: type: atom path: atom.xml limit: 20 hub: content: type - Feed type. (atom/rss2)path - Feed path. (Default: atom.xml/rss2.xml)limit - Maximum number of posts in the feed (Use 0 or false to show all posts)hub - URL of the PubSubHubbub hubs (Leave it empty if you don’t use it)content - (optional) set to ‘true’ to include the contents of the entire post in the feed. 在hexo中实现本地搜索功能（hexo-generator-searchdb）安装 hexo-generator-searchdb，在站点的根目录下执行以下命令： npm install hexo-generator-searchdb --save 编辑 站点配置文件，新增以下内容到任意位置： search: path: search.xml field: post format: html limit: 10000 除了安装本地搜索，还可以考虑 swiftype 的搜索。 更换hexo主题Hexo有很多主题，可以在 Hexo官网的主题页面 选择自己喜欢。以Next为例，本站使用的就是Next主题。 使用Git来获取主题文件 git clone https://github.com/iissnan/hexo-theme-next themes/next 直接在Next的 GitHub主页 下载主题文件 将Next文件夹放到theme文件夹中，修改站点配置文件，也就是网站根目录下的_config.yml文件中的theme： # Extensions ## Plugins: https://hexo.io/plugins/ ## Themes: https://hexo.io/themes/ theme: next 上传到github如果你一切都配置好了，发布上传很容易，一句hexo d就搞定，当然关键还是你要把所有东西配置好。 首先，ssh key肯定要配置好。 创建SSH在gitbash中输入：ssh-keygen -t rsa -C &quot;youremail@example.com，生成ssh。然后按下面的方式找到id_rsa.pub文件的内容。 $ cd ~/.ssh/ $ ls id_rsa id_rsa.pub known_hosts $ cat id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC0avsgprEOmpE1yVnbU4hjireV3Ozxb5vFLl4KXgkVY9X3O78E5y10rSa9CHs4lFao/Gij3G/VuXAC/id0pY7ti/BD6CmY8etFlZun9Zw+7Z41gRRrFxreXGwFhzfJeu6CVGYSQgPMjgu1TCCO9wM1hwU41T/Nof3F2kDlRn0pxvmIAkGNy/E8dtB9alY7ObNyrMuACZX8k42STttlte6MlelBVckFyks5IwQ+WdBc0giZTlfXbrL455HiEXitN20FQDznFoX96+iBlAa/WTE2fqVlKY22t5rmyU//JQkFG9ttxAOinADzTLskysE3eWaiupvA0gAjRc4rr8Sg83gJ huangkuier@gmail.com 把id_rsa.pub文件的内容添加到github的ssh key中。 其次，配置_config.yml中有关deploy的部分： 正确写法： deploy: type: git repository: git@github.com:hunkier/hunkier.github.io.git branch: master 错误写法： deploy: type: github repository: https://github.com/hunkier/hunkier.github.io.git branch: master 后面一种写法是hexo2.x的写法，现在已经不行了，无论是哪种写法，此时直接执行hexo d的话一般会报如下错误： Deployer not found: github 或者 Deployer not found: git 原因是还需要安装一个插件： npm install hexo-deployer-git --save 其它命令不确定，部署这个命令一定要用git bash，否则会提示Permission denied (publickey). 打开你的git bash，输入hexo d就会将本次有改动的代码全部提交，没有改动的不会： 常用hexo命令常见命令 hexo new &quot;postName&quot; #新建文章 hexo new page &quot;pageName&quot; #新建页面 hexo generate #生成静态页面至public目录 hexo server #开启预览访问端口（默认端口4000，&#39;ctrl + c&#39;关闭server） hexo deploy #部署到GitHub hexo help # 查看帮助 hexo version #查看Hexo的版本 缩写： hexo n == hexo new hexo g == hexo generate hexo s == hexo server hexo d == hexo deploy 组合命令： hexo s -g #生成并本地预览 hexo d -g #生成并上传 使用其他端口命令： hexo s -p 5000 (node:13224) [DEP0061] DeprecationWarning: fs.SyncWriteStream is deprecated. INFO Start processing INFO Hexo is running at http://localhost:5000/. 4.11. _config.yml这里面都是一些全局配置，每个参数的意思都比较简单明了，所以就不作详细介绍了。 需要特别注意的地方是，冒号后面必须有一个空格，否则可能会出问题。 4.12. 写博客定位到我们的hexo根目录，执行命令： hexo new &#39;my-first-blog&#39; hexo会帮我们在_posts下生成相关md文件 当然你也可以直接自己新建md文件，用这个命令的好处是帮我们自动生成了时间。 一般完整格式如下： --- title: postName #文章页面上的显示名称，一般是中文 date: 2013-12-02 15:30:16 #文章生成时间，一般不改，当然也可以任意修改 categories: 默认分类 #分类 tags: [tag1,tag2,tag3] #文章标签，可空，多标签请用格式，注意:后面有个空格 description: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面 --- 以下是正文 那么hexo new page &#39;postName&#39;命令和hexo new &#39;postName&#39;有什么区别呢？ hexo new page &quot;my-second-blog&quot; 最终部署时生成：hexo\public\my-second-blog\index.html，但是它不会作为文章出现在博文目录。 写博客工具那么用什么工具写博客呢？这个我还没去找，以前自己使用editor.md简单弄了个，大家有好用的hexo写博客工具可以推荐个。 https://www.typora.io 如何让博文列表不显示全部内容默认情况下，生成的博文目录会显示全部的文章内容，如何设置文章摘要的长度呢？ 答案是在合适的位置加上&lt;!--more--&gt;即可，例如： # 前言 使用github pages服务搭建博客的好处有： 1. 全是静态文件，访问速度快； 2. 免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台； 3. 可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于github的； &lt;!--more--&gt; 4. 数据绝对安全，基于github的版本管理，想恢复到哪个历史版本都行； 5. 博客内容可以轻松打包、转移、发布到其它平台； 6. 等等；]]></content>
      <categories>
        <category>github</category>
        <category>blog</category>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>hexo</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Hosted by Coding Pages Quick StartCreate a new post$ hexo new &quot;My New Post&quot; More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>github</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[加微信好友]]></title>
    <url>%2FMy-wechat%2F</url>
    <content type="text"><![CDATA[打开微信，扫一扫加微信好友]]></content>
      <categories>
        <category>github</category>
        <category>hexo</category>
        <category>wechat</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>hexo</tag>
        <tag>wechat</tag>
      </tags>
  </entry>
</search>
